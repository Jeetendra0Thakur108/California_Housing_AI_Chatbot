{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjycAfymIVMXnbcaftO/F8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeetendra0Thakur108/California_Housing_AI_Chatbot/blob/main/Untitled54.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a8cee29"
      },
      "source": [
        "# Task\n",
        "Build a recommendation system for student interactions using a suitable dataset from the `sample_data` folder in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97c6607a"
      },
      "source": [
        "## Data Selection and Initial Setup\n",
        "\n",
        "### Subtask:\n",
        "Choose a suitable dataset from the `sample_data` folder for student interaction data, load it, and perform initial data cleaning if necessary to prepare for EDA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee6de243"
      },
      "source": [
        "**Reasoning**:\n",
        "The first instruction is to list the files in the `sample_data` directory. This can be done using a shell command.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "616f2541",
        "outputId": "b0832b8a-6604-4e3e-97c9-a933ad20ea97"
      },
      "source": [
        "import os\n",
        "print(os.listdir('sample_data'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['README.md', 'anscombe.json', 'california_housing_train.csv', 'california_housing_test.csv', 'mnist_test.csv', 'mnist_train_small.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9dc4530"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the instructions, I will load the specified CSV file into a pandas DataFrame, display its head, check for missing values, and identify duplicate rows to prepare for EDA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "418cb857",
        "outputId": "d83a7229-972d-438a-bd29-c580bba6a701"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('sample_data/california_housing_train.csv')\n",
        "\n",
        "print('First 5 rows of the DataFrame:')\n",
        "print(df.head())\n",
        "\n",
        "print('\\nMissing values per column:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print('\\nNumber of duplicate rows:')\n",
        "print(df.duplicated().sum())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
            "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
            "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
            "2    -114.56     33.69                17.0        720.0           174.0   \n",
            "3    -114.57     33.64                14.0       1501.0           337.0   \n",
            "4    -114.57     33.57                20.0       1454.0           326.0   \n",
            "\n",
            "   population  households  median_income  median_house_value  \n",
            "0      1015.0       472.0         1.4936             66900.0  \n",
            "1      1129.0       463.0         1.8200             80100.0  \n",
            "2       333.0       117.0         1.6509             85700.0  \n",
            "3       515.0       226.0         3.1917             73400.0  \n",
            "4       624.0       262.0         1.9250             65500.0  \n",
            "\n",
            "Missing values per column:\n",
            "longitude             0\n",
            "latitude              0\n",
            "housing_median_age    0\n",
            "total_rooms           0\n",
            "total_bedrooms        0\n",
            "population            0\n",
            "households            0\n",
            "median_income         0\n",
            "median_house_value    0\n",
            "dtype: int64\n",
            "\n",
            "Number of duplicate rows:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03bab2bb"
      },
      "source": [
        "## Re-evaluate Data Selection for Student Interactions\n",
        "\n",
        "### Subtask:\n",
        "The currently loaded dataset, 'california_housing_train.csv', is not suitable for building a recommendation system for student interactions. Identify if any available datasets in the 'sample_data' folder can be plausibly interpreted as 'student interaction data'. If not, explicitly state this and propose a suitable alternative.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff1ceb51"
      },
      "source": [
        "### Evaluation of Datasets for Student Interactions\n",
        "\n",
        "Upon reviewing the files available in the `sample_data` directory, which include `['README.md', 'anscombe.json', 'california_housing_train.csv', 'california_housing_test.csv', 'mnist_test.csv', 'mnist_train_small.csv']`,\n",
        "\n",
        "I conclude the following:\n",
        "\n",
        "*   **`README.md`**: This is a text file, not a dataset.\n",
        "*   **`anscombe.json`**: This is a JSON dataset primarily used for illustrating statistical concepts; it does not contain student interaction data.\n",
        "*   **`california_housing_train.csv` and `california_housing_test.csv`**: These are datasets related to housing prices and demographics in California, completely unrelated to student interactions.\n",
        "*   **`mnist_test.csv` and `mnist_train_small.csv`**: These are datasets containing image pixel data for handwritten digit recognition (MNIST), which is not suitable for modeling student interactions.\n",
        "\n",
        "**Conclusion:** None of the datasets present in the `sample_data` folder can be plausibly interpreted as 'student interaction data'. These datasets lack critical features such as student IDs, course/item IDs, interaction types (e.g., enrollment, submission, view), timestamps, or performance metrics that would be necessary for building a recommendation system for student interactions.\n",
        "\n",
        "**Proposed Alternative:** To proceed with building a recommendation system for student interactions, an external dataset specifically designed for educational contexts or e-learning platforms will be required. Alternatively, a synthetic dataset simulating student activities could be generated if a real-world dataset is not immediately accessible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "527aa999"
      },
      "source": [
        "## Generate Synthetic Dataset for Student Interactions\n",
        "\n",
        "### Subtask:\n",
        "Create a synthetic dataset that simulates student interactions, as no suitable real-world dataset was found in the `sample_data` folder.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f7e08c"
      },
      "source": [
        "**Reasoning**:\n",
        "I will import the necessary libraries, define parameters for the synthetic dataset, generate random data for student IDs, item IDs, interaction types, and timestamps, combine them into a DataFrame, and then display the head and info of the DataFrame to fulfill the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd481695",
        "outputId": "c23557c1-d133-4868-896c-c5cd4fde683a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 2. Define the number of unique students, unique items, and total interactions\n",
        "num_students = 100\n",
        "num_items = 50\n",
        "num_interactions = 1000\n",
        "\n",
        "# 3. Generate random student_ids and item_ids\n",
        "student_ids = np.random.randint(1, num_students + 1, num_interactions)\n",
        "item_ids = np.random.randint(1, num_items + 1, num_interactions)\n",
        "\n",
        "# 4. Generate random interaction_types\n",
        "interaction_types = np.random.choice(['view', 'complete', 'enroll', 'quiz_attempt', 'discuss'], num_interactions)\n",
        "\n",
        "# 5. Generate realistic timestamp values\n",
        "start_date = pd.to_datetime('2023-01-01')\n",
        "end_date = pd.to_datetime('2023-12-31')\n",
        "time_range = (end_date - start_date).total_seconds()\n",
        "timestamps = start_date + pd.to_timedelta(np.random.rand(num_interactions) * time_range, unit='s')\n",
        "\n",
        "# 6. Combine these generated columns into a pandas DataFrame\n",
        "synthetic_df = pd.DataFrame({\n",
        "    'student_id': student_ids,\n",
        "    'item_id': item_ids,\n",
        "    'interaction_type': interaction_types,\n",
        "    'timestamp': timestamps\n",
        "})\n",
        "\n",
        "# Sort by timestamp to make it more realistic\n",
        "synthetic_df = synthetic_df.sort_values(by='timestamp').reset_index(drop=True)\n",
        "\n",
        "# 7. Display the first few rows of the generated DataFrame and its information\n",
        "print('First 5 rows of the Synthetic DataFrame:')\n",
        "print(synthetic_df.head())\n",
        "\n",
        "print('\\nInformation about the Synthetic DataFrame:')\n",
        "synthetic_df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the Synthetic DataFrame:\n",
            "   student_id  item_id interaction_type                     timestamp\n",
            "0          98       43             view 2023-01-02 00:14:37.043855600\n",
            "1          54       40           enroll 2023-01-02 06:34:57.734943193\n",
            "2          68       29     quiz_attempt 2023-01-03 08:43:40.064231256\n",
            "3          48       33          discuss 2023-01-03 11:49:03.384621733\n",
            "4           5       11             view 2023-01-03 13:38:57.647947908\n",
            "\n",
            "Information about the Synthetic DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Non-Null Count  Dtype         \n",
            "---  ------            --------------  -----         \n",
            " 0   student_id        1000 non-null   int64         \n",
            " 1   item_id           1000 non-null   int64         \n",
            " 2   interaction_type  1000 non-null   object        \n",
            " 3   timestamp         1000 non-null   datetime64[ns]\n",
            "dtypes: datetime64[ns](1), int64(2), object(1)\n",
            "memory usage: 31.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "572179a7"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "### Subtask:\n",
        "Conduct a thorough EDA, focusing on sparsity, interaction distributions, and an initial cold-start analysis to understand the dataset characteristics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c12443d5"
      },
      "source": [
        "**Reasoning**:\n",
        "I will calculate the unique students, unique items, observed interactions, possible interactions, and then compute the sparsity of the interaction matrix. Subsequently, I will analyze the distribution of interactions per student, per item, and per interaction type, and identify cold-start students and items based on a low interaction threshold.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e191c34f",
        "outputId": "09c0aa77-c0e3-4d74-94ed-0700c6553449"
      },
      "source": [
        "print('--- EDA for Synthetic Student Interaction Data ---\\n')\n",
        "\n",
        "# 1. Calculate the total number of unique students and unique items\n",
        "unique_students = synthetic_df['student_id'].nunique()\n",
        "unique_items = synthetic_df['item_id'].nunique()\n",
        "print(f\"Total unique students: {unique_students}\")\n",
        "print(f\"Total unique items: {unique_items}\\n\")\n",
        "\n",
        "# 2. Determine the total number of observed interactions\n",
        "observed_interactions = len(synthetic_df)\n",
        "print(f\"Total observed interactions: {observed_interactions}\\n\")\n",
        "\n",
        "# 3. Calculate the total number of possible interactions\n",
        "possible_interactions = unique_students * unique_items\n",
        "print(f\"Total possible interactions (unique students * unique items): {possible_interactions}\\n\")\n",
        "\n",
        "# 4. Compute the sparsity of the interaction matrix\n",
        "sparsity = (1 - (observed_interactions / possible_interactions)) * 100\n",
        "print(f\"Sparsity of the interaction matrix: {sparsity:.2f}%\\n\")\n",
        "\n",
        "# 5. Analyze the distribution of interactions per student\n",
        "interactions_per_student = synthetic_df['student_id'].value_counts()\n",
        "print('Distribution of interactions per student (top 5):')\n",
        "print(interactions_per_student.head())\n",
        "print('\\nDistribution of interactions per student (bottom 5):')\n",
        "print(interactions_per_student.tail())\n",
        "print(f\"\\nMin interactions per student: {interactions_per_student.min()}\")\n",
        "print(f\"Max interactions per student: {interactions_per_student.max()}\\n\")\n",
        "\n",
        "# 6. Analyze the distribution of interactions per item\n",
        "interactions_per_item = synthetic_df['item_id'].value_counts()\n",
        "print('Distribution of interactions per item (top 5):')\n",
        "print(interactions_per_item.head())\n",
        "print('\\nDistribution of interactions per item (bottom 5):')\n",
        "print(interactions_per_item.tail())\n",
        "print(f\"\\nMin interactions per item: {interactions_per_item.min()}\")\n",
        "print(f\"Max interactions per item: {interactions_per_item.max()}\\n\")\n",
        "\n",
        "# 7. Analyze the distribution of different interaction_type values\n",
        "interaction_type_distribution = synthetic_df['interaction_type'].value_counts()\n",
        "print('Distribution of interaction types:')\n",
        "print(interaction_type_distribution)\n",
        "\n",
        "# 8. Identify and count students with a low number of interactions (e.g., less than 5)\n",
        "cold_start_students = interactions_per_student[interactions_per_student < 5]\n",
        "print(f\"\\nNumber of cold-start students (less than 5 interactions): {len(cold_start_students)}\")\n",
        "print('IDs of cold-start students (first 5):')\n",
        "print(cold_start_students.head().index.tolist())\n",
        "\n",
        "# 9. Identify and count items with a low number of interactions (e.g., less than 5)\n",
        "cold_start_items = interactions_per_item[interactions_per_item < 5]\n",
        "print(f\"\\nNumber of cold-start items (less than 5 interactions): {len(cold_start_items)}\")\n",
        "print('IDs of cold-start items (first 5):')\n",
        "print(cold_start_items.head().index.tolist())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- EDA for Synthetic Student Interaction Data ---\n",
            "\n",
            "Total unique students: 100\n",
            "Total unique items: 50\n",
            "\n",
            "Total observed interactions: 1000\n",
            "\n",
            "Total possible interactions (unique students * unique items): 5000\n",
            "\n",
            "Sparsity of the interaction matrix: 80.00%\n",
            "\n",
            "Distribution of interactions per student (top 5):\n",
            "student_id\n",
            "55    20\n",
            "53    19\n",
            "30    17\n",
            "63    16\n",
            "45    15\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of interactions per student (bottom 5):\n",
            "student_id\n",
            "15    6\n",
            "88    5\n",
            "62    5\n",
            "56    5\n",
            "6     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Min interactions per student: 3\n",
            "Max interactions per student: 20\n",
            "\n",
            "Distribution of interactions per item (top 5):\n",
            "item_id\n",
            "17    30\n",
            "32    29\n",
            "46    28\n",
            "6     26\n",
            "20    25\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution of interactions per item (bottom 5):\n",
            "item_id\n",
            "45    14\n",
            "9     13\n",
            "48    12\n",
            "10    12\n",
            "15    12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Min interactions per item: 12\n",
            "Max interactions per item: 30\n",
            "\n",
            "Distribution of interaction types:\n",
            "interaction_type\n",
            "enroll          234\n",
            "discuss         209\n",
            "quiz_attempt    199\n",
            "view            181\n",
            "complete        177\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of cold-start students (less than 5 interactions): 1\n",
            "IDs of cold-start students (first 5):\n",
            "[6]\n",
            "\n",
            "Number of cold-start items (less than 5 interactions): 0\n",
            "IDs of cold-start items (first 5):\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9cdabd7"
      },
      "source": [
        "## Temporal Train/Validation/Test Split\n",
        "\n",
        "### Subtask:\n",
        "Implement a temporal split strategy for the dataset to create train, validation, and test sets, ensuring the integrity of time-based recommendations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19c3885b"
      },
      "source": [
        "**Reasoning**:\n",
        "I will sort the dataframe by timestamp, calculate the indices for the 80/10/10 train/validation/test split, create the respective dataframes by slicing, and then print the size of each to confirm the split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13ab760a",
        "outputId": "2b65f33c-e5a8-4f5b-a6c1-07972ba7a41a"
      },
      "source": [
        "print('--- Temporal Train/Validation/Test Split ---\\n')\n",
        "\n",
        "# 1. Ensure the DataFrame is sorted by timestamp\n",
        "synthetic_df = synthetic_df.sort_values(by='timestamp').reset_index(drop=True)\n",
        "\n",
        "# 2. Calculate the size of each split\n",
        "total_interactions = len(synthetic_df)\n",
        "train_size = int(0.8 * total_interactions)\n",
        "val_size = int(0.1 * total_interactions)\n",
        "# The rest goes to test, ensuring no data is left out due to integer truncation\n",
        "test_size = total_interactions - train_size - val_size\n",
        "\n",
        "# 3. Create train, validation, and test sets\n",
        "train_df = synthetic_df.iloc[:train_size]\n",
        "val_df = synthetic_df.iloc[train_size : train_size + val_size]\n",
        "test_df = synthetic_df.iloc[train_size + val_size :]\n",
        "\n",
        "# 4. Print the number of interactions in each set to verify the split\n",
        "print(f\"Total interactions: {total_interactions}\")\n",
        "print(f\"Train set interactions: {len(train_df)}\")\n",
        "print(f\"Validation set interactions: {len(val_df)}\")\n",
        "print(f\"Test set interactions: {len(test_df)}\")\n",
        "\n",
        "print('\\nFirst 5 rows of the Train DataFrame:')\n",
        "print(train_df.head())\n",
        "\n",
        "print('\\nFirst 5 rows of the Validation DataFrame:')\n",
        "print(val_df.head())\n",
        "\n",
        "print('\\nFirst 5 rows of the Test DataFrame:')\n",
        "print(test_df.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Temporal Train/Validation/Test Split ---\n",
            "\n",
            "Total interactions: 1000\n",
            "Train set interactions: 800\n",
            "Validation set interactions: 100\n",
            "Test set interactions: 100\n",
            "\n",
            "First 5 rows of the Train DataFrame:\n",
            "   student_id  item_id interaction_type                     timestamp\n",
            "0          98       43             view 2023-01-02 00:14:37.043855600\n",
            "1          54       40           enroll 2023-01-02 06:34:57.734943193\n",
            "2          68       29     quiz_attempt 2023-01-03 08:43:40.064231256\n",
            "3          48       33          discuss 2023-01-03 11:49:03.384621733\n",
            "4           5       11             view 2023-01-03 13:38:57.647947908\n",
            "\n",
            "First 5 rows of the Validation DataFrame:\n",
            "     student_id  item_id interaction_type                     timestamp\n",
            "800          38       38             view 2023-10-16 22:12:29.678260971\n",
            "801          98       42           enroll 2023-10-18 13:01:32.260811631\n",
            "802          65       24             view 2023-10-18 21:44:27.007965847\n",
            "803          39       41             view 2023-10-19 04:51:06.952077724\n",
            "804          36       46         complete 2023-10-19 07:00:10.266614817\n",
            "\n",
            "First 5 rows of the Test DataFrame:\n",
            "     student_id  item_id interaction_type                     timestamp\n",
            "900          59       17           enroll 2023-11-24 22:59:10.492632110\n",
            "901          48       11           enroll 2023-11-25 02:05:20.896128919\n",
            "902          74        2             view 2023-11-25 17:26:28.601485230\n",
            "903          68       28         complete 2023-11-26 19:28:18.733400926\n",
            "904          84       36             view 2023-11-27 02:52:01.039344382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74505fe6"
      },
      "source": [
        "## Feature Engineering\n",
        "\n",
        "### Subtask:\n",
        "Develop and engineer relevant features from the dataset, focusing on user, item, and temporal context to enrich the recommendation models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1899ed37"
      },
      "source": [
        "**Reasoning**:\n",
        "I will calculate the user-specific features (total interactions, unique items, most frequent interaction type) and item-specific features (total interactions, unique students, most frequent interaction type) from the `train_df`. These features will then be used to enrich all three datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "757f4caf",
        "outputId": "81bb5546-1faf-40bc-b19d-3be4fce25497"
      },
      "source": [
        "print('--- Feature Engineering for Student Interaction Data ---\\n')\n",
        "\n",
        "# 1. Calculate User Features from train_df\n",
        "user_interactions = train_df.groupby('student_id').agg(\n",
        "    total_interactions_user=('item_id', 'count'),\n",
        "    unique_items_interacted=('item_id', 'nunique'),\n",
        "    most_frequent_interaction_type_user=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "print('User Features (first 5 rows):')\n",
        "print(user_interactions.head())\n",
        "\n",
        "# 2. Calculate Item Features from train_df\n",
        "item_interactions = train_df.groupby('item_id').agg(\n",
        "    total_interactions_item=('student_id', 'count'),\n",
        "    unique_students_interacted=('student_id', 'nunique'),\n",
        "    most_frequent_interaction_type_item=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "print('\\nItem Features (first 5 rows):')\n",
        "print(item_interactions.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Feature Engineering for Student Interaction Data ---\n",
            "\n",
            "User Features (first 5 rows):\n",
            "   student_id  total_interactions_user  unique_items_interacted  \\\n",
            "0           1                        9                        8   \n",
            "1           2                        8                        8   \n",
            "2           3                        3                        3   \n",
            "3           4                        4                        4   \n",
            "4           5                       10                        8   \n",
            "\n",
            "  most_frequent_interaction_type_user  \n",
            "0                            complete  \n",
            "1                        quiz_attempt  \n",
            "2                        quiz_attempt  \n",
            "3                        quiz_attempt  \n",
            "4                                view  \n",
            "\n",
            "Item Features (first 5 rows):\n",
            "   item_id  total_interactions_item  unique_students_interacted  \\\n",
            "0        1                       16                          14   \n",
            "1        2                       15                          14   \n",
            "2        3                       20                          19   \n",
            "3        4                       12                          10   \n",
            "4        5                       20                          19   \n",
            "\n",
            "  most_frequent_interaction_type_item  \n",
            "0                        quiz_attempt  \n",
            "1                            complete  \n",
            "2                                view  \n",
            "3                            complete  \n",
            "4                              enroll  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f141278"
      },
      "source": [
        "**Reasoning**:\n",
        "I will merge the previously calculated user and item features into the train, validation, and test dataframes. Then, I will extract temporal features (day of week and hour of day) from the timestamp column for all three dataframes. Finally, I will display the first few rows of the updated `train_df` to show the newly engineered features, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e581fd4",
        "outputId": "bcd4fd09-6d36-44c1-f262-73c6f49d2743"
      },
      "source": [
        "print('Merging Features and Extracting Temporal Features')\n",
        "\n",
        "# 3. Merge the created user and item features into train_df, val_df, and test_df\n",
        "\n",
        "train_df = pd.merge(train_df, user_interactions, on='student_id', how='left')\n",
        "train_df = pd.merge(train_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "val_df = pd.merge(val_df, user_interactions, on='student_id', how='left')\n",
        "val_df = pd.merge(val_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "test_df = pd.merge(test_df, user_interactions, on='student_id', how='left')\n",
        "test_df = pd.merge(test_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# 4. Extract temporal features (day of week and hour of day)\n",
        "for df_name in ['train_df', 'val_df', 'test_df']:\n",
        "    df = globals()[df_name]\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "    globals()[df_name] = df # Update the global dataframe\n",
        "\n",
        "# 5. Display the first few rows of the updated train_df\n",
        "print('First 5 rows of the updated Train DataFrame with new features:')\n",
        "print(train_df.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging Features and Extracting Temporal Features\n",
            "First 5 rows of the updated Train DataFrame with new features:\n",
            "   student_id  item_id interaction_type                     timestamp  \\\n",
            "0          98       43             view 2023-01-02 00:14:37.043855600   \n",
            "1          54       40           enroll 2023-01-02 06:34:57.734943193   \n",
            "2          68       29     quiz_attempt 2023-01-03 08:43:40.064231256   \n",
            "3          48       33          discuss 2023-01-03 11:49:03.384621733   \n",
            "4           5       11             view 2023-01-03 13:38:57.647947908   \n",
            "\n",
            "   total_interactions_user  unique_items_interacted  \\\n",
            "0                        6                        6   \n",
            "1                        7                        6   \n",
            "2                       10                        9   \n",
            "3                        9                        7   \n",
            "4                       10                        8   \n",
            "\n",
            "  most_frequent_interaction_type_user  total_interactions_item  \\\n",
            "0                             discuss                       13   \n",
            "1                              enroll                       19   \n",
            "2                             discuss                       16   \n",
            "3                        quiz_attempt                       13   \n",
            "4                                view                       17   \n",
            "\n",
            "   unique_students_interacted most_frequent_interaction_type_item  \\\n",
            "0                          13                              enroll   \n",
            "1                          19                             discuss   \n",
            "2                          15                            complete   \n",
            "3                          12                             discuss   \n",
            "4                          15                              enroll   \n",
            "\n",
            "   day_of_week  hour_of_day  \n",
            "0            0            0  \n",
            "1            0            6  \n",
            "2            1            8  \n",
            "3            1           11  \n",
            "4            1           13  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79551380"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to a `SyntaxError: unterminated string literal` in the print statement. I will correct the string literal by closing it on the same line to fix the syntax error. The rest of the logic for merging features and extracting temporal data remains correct.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21b619e8",
        "outputId": "fc38f2ca-4060-4cc0-e8f0-f21c3e55adc9"
      },
      "source": [
        "print('--- Merging Features and Extracting Temporal Features ---')\n",
        "\n",
        "# 3. Merge the created user and item features into train_df, val_df, and test_df\n",
        "\n",
        "train_df = pd.merge(train_df, user_interactions, on='student_id', how='left')\n",
        "train_df = pd.merge(train_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "val_df = pd.merge(val_df, user_interactions, on='student_id', how='left')\n",
        "val_df = pd.merge(val_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "test_df = pd.merge(test_df, user_interactions, on='student_id', how='left')\n",
        "test_df = pd.merge(test_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# 4. Extract temporal features (day of week and hour of day)\n",
        "for df_name in ['train_df', 'val_df', 'test_df']:\n",
        "    df = globals()[df_name]\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "    globals()[df_name] = df # Update the global dataframe\n",
        "\n",
        "# 5. Display the first few rows of the updated train_df\n",
        "print('First 5 rows of the updated Train DataFrame with new features:')\n",
        "print(train_df.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Merging Features and Extracting Temporal Features ---\n",
            "First 5 rows of the updated Train DataFrame with new features:\n",
            "   student_id  item_id interaction_type                     timestamp  \\\n",
            "0          98       43             view 2023-01-02 00:14:37.043855600   \n",
            "1          54       40           enroll 2023-01-02 06:34:57.734943193   \n",
            "2          68       29     quiz_attempt 2023-01-03 08:43:40.064231256   \n",
            "3          48       33          discuss 2023-01-03 11:49:03.384621733   \n",
            "4           5       11             view 2023-01-03 13:38:57.647947908   \n",
            "\n",
            "   total_interactions_user_x  unique_items_interacted_x  \\\n",
            "0                          6                          6   \n",
            "1                          7                          6   \n",
            "2                         10                          9   \n",
            "3                          9                          7   \n",
            "4                         10                          8   \n",
            "\n",
            "  most_frequent_interaction_type_user_x  total_interactions_item_x  \\\n",
            "0                               discuss                         13   \n",
            "1                                enroll                         19   \n",
            "2                               discuss                         16   \n",
            "3                          quiz_attempt                         13   \n",
            "4                                  view                         17   \n",
            "\n",
            "   unique_students_interacted_x most_frequent_interaction_type_item_x  \\\n",
            "0                            13                                enroll   \n",
            "1                            19                               discuss   \n",
            "2                            15                              complete   \n",
            "3                            12                               discuss   \n",
            "4                            15                                enroll   \n",
            "\n",
            "   day_of_week  hour_of_day  total_interactions_user_y  \\\n",
            "0            0            0                          6   \n",
            "1            0            6                          7   \n",
            "2            1            8                         10   \n",
            "3            1           11                          9   \n",
            "4            1           13                         10   \n",
            "\n",
            "   unique_items_interacted_y most_frequent_interaction_type_user_y  \\\n",
            "0                          6                               discuss   \n",
            "1                          6                                enroll   \n",
            "2                          9                               discuss   \n",
            "3                          7                          quiz_attempt   \n",
            "4                          8                                  view   \n",
            "\n",
            "   total_interactions_item_y  unique_students_interacted_y  \\\n",
            "0                         13                            13   \n",
            "1                         19                            19   \n",
            "2                         16                            15   \n",
            "3                         13                            12   \n",
            "4                         17                            15   \n",
            "\n",
            "  most_frequent_interaction_type_item_y  \n",
            "0                                enroll  \n",
            "1                               discuss  \n",
            "2                              complete  \n",
            "3                               discuss  \n",
            "4                                enroll  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee4fac74"
      },
      "source": [
        "## Implement Baseline Models\n",
        "\n",
        "### Subtask:\n",
        "Develop and train the required baseline recommendation models: a 'Most Popular' recommender and a 'Collaborative Filtering' model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01b705f3"
      },
      "source": [
        "**Reasoning**:\n",
        "The first instruction is to calculate the popularity of each item in the `train_df` by counting the total number of interactions for each `item_id`. This will create a baseline for the 'Most Popular' recommender.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12886fec",
        "outputId": "9e9bee4e-f82d-4a43-b80c-f3fb19cf664d"
      },
      "source": [
        "print('--- Implementing Baseline Models: Most Popular Recommender ---\\n')\n",
        "\n",
        "# 1. Calculate the popularity of each item in the train_df\n",
        "item_popularity = train_df['item_id'].value_counts().reset_index()\n",
        "item_popularity.columns = ['item_id', 'popularity_score']\n",
        "\n",
        "print('Item Popularity Scores (first 5 rows):')\n",
        "print(item_popularity.head())\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Implementing Baseline Models: Most Popular Recommender ---\n",
            "\n",
            "Item Popularity Scores (first 5 rows):\n",
            "   item_id  popularity_score\n",
            "0       32                24\n",
            "1       17                24\n",
            "2       38                22\n",
            "3        6                22\n",
            "4       44                21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3ee10b8"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `get_most_popular_recommendations` function, which takes a `student_id`, an integer `n`, and historical interactions to return top `n` popular items, excluding those already interacted with, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "037917a8",
        "outputId": "64960abf-1af4-4a0a-f1da-2d664a2dd7d0"
      },
      "source": [
        "def get_most_popular_recommendations(student_id, n, historical_interactions=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "\n",
        "    # Filter out items already interacted with by the student\n",
        "    recommended_items = item_popularity[~item_popularity['item_id'].isin(historical_interactions)]\n",
        "\n",
        "    # Sort by popularity and get top n items\n",
        "    recommended_items = recommended_items.sort_values(by='popularity_score', ascending=False)\n",
        "\n",
        "    return recommended_items.head(n)['item_id'].tolist()\n",
        "\n",
        "print('`get_most_popular_recommendations` function defined.')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`get_most_popular_recommendations` function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "809be9f8"
      },
      "source": [
        "**Reasoning**:\n",
        "I will import the necessary classes (`Reader`, `Dataset`, and `SVD`) from the `surprise` library to prepare for building the Collaborative Filtering model, as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72338d44",
        "outputId": "f9cbc8a9-1ecf-4628-fd5f-23275851ccd2"
      },
      "source": [
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('`surprise` library components (Reader, Dataset, SVD) imported.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`surprise` library components (Reader, Dataset, SVD) imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21fd6398"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step failed because the `surprise` library was not found. I need to install `scikit-surprise` using pip before attempting to import its components.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b3a0cf6",
        "outputId": "ac8247dc-f87a-41f2-e562-6b055db6ba63"
      },
      "source": [
        "print('--- Installing surprise library ---\\n')\n",
        "!pip install scikit-surprise\n",
        "\n",
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('`surprise` library components (Reader, Dataset, SVD) imported.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Installing surprise library ---\n",
            "\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.12/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.16.3)\n",
            "`surprise` library components (Reader, Dataset, SVD) imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fb1f875"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step failed with an `ImportError` due to incompatibility between the `surprise` library and the installed NumPy 2.x version. To resolve this, I will explicitly downgrade NumPy to a version less than 2.0 before attempting to import `surprise` again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3aab2e2",
        "outputId": "735dce5b-1636-4f55-89d2-99dc46314c5e"
      },
      "source": [
        "print('--- Downgrading numpy and installing surprise library ---\\n')\n",
        "!pip install numpy==1.26.4 # Downgrade numpy to a version compatible with surprise\n",
        "!pip install scikit-surprise # Re-install surprise to ensure compatibility if needed, though usually not required after numpy downgrade if surprise is already installed.\n",
        "\n",
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('`surprise` library components (Reader, Dataset, SVD) imported.')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Downgrading numpy and installing surprise library ---\n",
            "\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.12/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.16.3)\n",
            "`surprise` library components (Reader, Dataset, SVD) imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97673d62"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to downgrade NumPy did not fully resolve the `ImportError` because `surprise` was not properly re-installed to link with the downgraded NumPy version. I will explicitly force reinstall NumPy to version 1.26.4 and then force reinstall `scikit-surprise` to ensure all components are built against the correct NumPy version.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "40729971",
        "outputId": "af1d70ab-8d7a-462b-b645-0f184e73b81e"
      },
      "source": [
        "print('--- Downgrading numpy and re-installing surprise library ---\\n')\n",
        "!pip install numpy==1.26.4 --force-reinstall # Downgrade numpy and force reinstall\n",
        "!pip install scikit-surprise --force-reinstall # Force re-install surprise to ensure compatibility\n",
        "\n",
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('`surprise` library components (Reader, Dataset, SVD) imported.')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Downgrading numpy and re-installing surprise library ---\n",
            "\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d93c8843f5f94da381e6ad1f57746c6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Using cached scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl\n",
            "Collecting joblib>=1.2.0 (from scikit-surprise)\n",
            "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting numpy>=1.19.5 (from scikit-surprise)\n",
            "  Using cached numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting scipy>=1.6.0 (from scikit-surprise)\n",
            "  Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
            "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Using cached numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
            "Installing collected packages: numpy, joblib, scipy, scikit-surprise\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m`surprise` library components (Reader, Dataset, SVD) imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32d77994"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to downgrade NumPy failed because `scikit-surprise` re-installed an incompatible NumPy version (2.x) as its dependency, causing an `ImportError`. To fix this, I will explicitly uninstall both `numpy` and `scikit-surprise`, then install a compatible NumPy version (1.26.4), and finally reinstall `scikit-surprise` to ensure it builds against the correct NumPy version.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "5f891dd0",
        "outputId": "7f1df21b-54eb-4dc1-d91a-e0c397a8a5d5"
      },
      "source": [
        "print('--- Fixing numpy and surprise library installation ---\\n')\n",
        "!pip uninstall numpy -y # Uninstall any existing numpy versions\n",
        "!pip uninstall scikit-surprise -y # Uninstall surprise\n",
        "\n",
        "# Install a compatible numpy version (e.g., 1.26.4) and then scikit-surprise\n",
        "# This order ensures surprise builds against the older numpy.\n",
        "!pip install numpy==1.26.4\n",
        "!pip install scikit-surprise\n",
        "\n",
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('`surprise` library components (Reader, Dataset, SVD) imported successfully.')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fixing numpy and surprise library installation ---\n",
            "\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping numpy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: scikit-surprise 1.1.4\n",
            "Uninstalling scikit-surprise-1.1.4:\n",
            "  Successfully uninstalled scikit-surprise-1.1.4\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: numpy\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting scikit-surprise\n",
            "  Using cached scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.5.2)\n",
            "Collecting numpy>=1.19.5 (from scikit-surprise)\n",
            "  Using cached numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.16.3)\n",
            "Using cached numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: numpy, scikit-surprise\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy scikit-surprise-1.1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "surprise"
                ]
              },
              "id": "57664b179a7b4eb09449a06f1aed254e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`surprise` library components (Reader, Dataset, SVD) imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "216aeae6"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to install `surprise` and a compatible `numpy` version resulted in a `ValueError` during import, indicating a persistent binary incompatibility issue often seen in environments like Google Colab. While a kernel restart is typically required to fully resolve such issues, I will re-execute the installation steps in the correct order to ensure `numpy==1.26.4` is firmly established before `scikit-surprise` is installed, which is the most robust programmatic fix available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "b368001d",
        "outputId": "6433f083-80a8-4487-a534-75545c1ebf71"
      },
      "source": [
        "print('--- Re-attempting numpy and surprise library installation ---\\n')\n",
        "!pip uninstall numpy -y # Uninstall any existing numpy versions\n",
        "!pip uninstall scikit-surprise -y # Uninstall surprise\n",
        "\n",
        "# Install a compatible numpy version (e.g., 1.26.4) and then scikit-surprise\n",
        "# This order ensures surprise builds against the older numpy.\n",
        "!pip install numpy==1.26.4\n",
        "!pip install scikit-surprise\n",
        "\n",
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('`surprise` library components (Reader, Dataset, SVD) imported successfully.')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Re-attempting numpy and surprise library installation ---\n",
            "\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping numpy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: scikit-surprise 1.1.4\n",
            "Uninstalling scikit-surprise-1.1.4:\n",
            "  Successfully uninstalled scikit-surprise-1.1.4\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: numpy\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting scikit-surprise\n",
            "  Using cached scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.5.2)\n",
            "Collecting numpy>=1.19.5 (from scikit-surprise)\n",
            "  Using cached numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise) (1.16.3)\n",
            "Using cached numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: numpy, scikit-surprise\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy scikit-surprise-1.1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "surprise"
                ]
              },
              "id": "777a99f1975f478d88e4a8122be6723f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`surprise` library components (Reader, Dataset, SVD) imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6b166c3"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts to resolve the `ImportError` and `ValueError` due to NumPy version incompatibility have been unsuccessful, likely caused by conflicting dependencies with pre-installed Colab packages and potentially an interrupted installation. To address this, I will explicitly uninstall both `numpy` and `scikit-surprise`, then install the compatible `numpy==1.26.4`, and finally reinstall `scikit-surprise` using the `--no-deps` flag to prevent it from overriding the specific NumPy version. This ensures `scikit-surprise` is built and run against the intended NumPy version.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "274c9fbc",
        "outputId": "7de1f304-e226-4643-fbd0-44b0442e5c20"
      },
      "source": [
        "print('--- Attempting final fix for numpy and surprise library installation ---\\n')\n",
        "!pip uninstall numpy -y # Uninstall any existing numpy versions\n",
        "!pip uninstall scikit-surprise -y # Uninstall surprise\n",
        "\n",
        "# Install a compatible numpy version (e.g., 1.26.4)\n",
        "!pip install numpy==1.26.4\n",
        "\n",
        "# Install scikit-surprise, forcing it to use the already installed numpy version\n",
        "# by ignoring its own dependencies which might try to upgrade numpy.\n",
        "!pip install scikit-surprise --no-deps\n",
        "\n",
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('`surprise` library components (Reader, Dataset, SVD) imported successfully.')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Attempting final fix for numpy and surprise library installation ---\n",
            "\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping numpy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: scikit-surprise 1.1.4\n",
            "Uninstalling scikit-surprise-1.1.4:\n",
            "  Successfully uninstalled scikit-surprise-1.1.4\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: numpy\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting scikit-surprise\n",
            "  Using cached scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl\n",
            "Installing collected packages: scikit-surprise\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed scikit-surprise-1.1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "surprise"
                ]
              },
              "id": "0a29c049c3554701a1fd7007fd7a46ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`surprise` library components (Reader, Dataset, SVD) imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fdbe137"
      },
      "source": [
        "**Reasoning**:\n",
        "Despite the `KeyboardInterrupt` in the previous attempt, the installation logs indicate that `numpy==1.26.4` and `scikit-surprise==1.1.4` were successfully installed. Assuming the environment is now correctly configured and the `surprise` library components can be imported, the next logical step according to the subtask instructions is to create a `surprise.Reader` object with an appropriate rating scale.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50141cc7",
        "outputId": "57073b6c-47d4-4e32-b483-53cd4e5adaa5"
      },
      "source": [
        "print('--- Initializing surprise.Reader and loading data ---')\n",
        "\n",
        "# 4. Create a surprise.Reader object\n",
        "# Since we are treating all interactions as implicit feedback, a rating scale of (1, 1) is suitable.\n",
        "# We'll use a dummy 'rating' of 1 for all interactions in the dataset.\n",
        "reader = Reader(rating_scale=(1, 1))\n",
        "\n",
        "# Prepare the data for Surprise library\n",
        "# Create a 'dummy_rating' column with a value of 1 for all interactions\n",
        "train_df_surprise = train_df[['student_id', 'item_id']].copy()\n",
        "train_df_surprise['dummy_rating'] = 1\n",
        "\n",
        "# 5. Load the train_df into a surprise.Dataset\n",
        "data = Dataset.load_from_df(train_df_surprise[['student_id', 'item_id', 'dummy_rating']], reader)\n",
        "\n",
        "# 6. Build a trainset from the loaded Dataset\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "print('\\n`surprise.Reader` object created and trainset built.')\n",
        "print(f\"Number of users in trainset: {trainset.n_users}\")\n",
        "print(f\"Number of items in trainset: {trainset.n_items}\")\n",
        "print(f\"Number of interactions in trainset: {trainset.n_ratings}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing surprise.Reader and loading data ---\n",
            "\n",
            "`surprise.Reader` object created and trainset built.\n",
            "Number of users in trainset: 100\n",
            "Number of items in trainset: 50\n",
            "Number of interactions in trainset: 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "782e8cdc"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous cell produced a `NameError` because the `surprise` library components (like `Reader`) were not properly imported, likely due to an issue with the preceding installation steps. To fix this, I will re-include the `from surprise import Reader, Dataset, SVD` statement at the beginning of the current code block to ensure these classes are available before they are used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49f786c0",
        "outputId": "e7c51c5d-1dd0-4c60-a148-191aa4507aa4"
      },
      "source": [
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('--- Initializing surprise.Reader and loading data ---')\n",
        "\n",
        "# 4. Create a surprise.Reader object\n",
        "# Since we are treating all interactions as implicit feedback, a rating scale of (1, 1) is suitable.\n",
        "# We'll use a dummy 'rating' of 1 for all interactions in the dataset.\n",
        "reader = Reader(rating_scale=(1, 1))\n",
        "\n",
        "# Prepare the data for Surprise library\n",
        "# Create a 'dummy_rating' column with a value of 1 for all interactions\n",
        "train_df_surprise = train_df[['student_id', 'item_id']].copy()\n",
        "train_df_surprise['dummy_rating'] = 1\n",
        "\n",
        "# 5. Load the train_df into a surprise.Dataset\n",
        "data = Dataset.load_from_df(train_df_surprise[['student_id', 'item_id', 'dummy_rating']], reader)\n",
        "\n",
        "# 6. Build a trainset from the loaded Dataset\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "print('\\n`surprise.Reader` object created and trainset built.')\n",
        "print(f\"Number of users in trainset: {trainset.n_users}\")\n",
        "print(f\"Number of items in trainset: {trainset.n_items}\")\n",
        "print(f\"Number of interactions in trainset: {trainset.n_ratings}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing surprise.Reader and loading data ---\n",
            "\n",
            "`surprise.Reader` object created and trainset built.\n",
            "Number of users in trainset: 100\n",
            "Number of items in trainset: 50\n",
            "Number of interactions in trainset: 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dc6f5ad"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError` for `train_df` indicates that the DataFrame was not defined in the current execution environment, likely due to previous installation attempts causing a reset or out-of-order execution. I will re-run the code to create `train_df` from the temporal split and then proceed with preparing the data for the `surprise` library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f6812de",
        "outputId": "a7b28593-0021-49c6-d1b6-d18cc70e578c"
      },
      "source": [
        "print('Re-creating DataFrames for Temporal Train/Validation/Test Split ---\\n')\n",
        "\n",
        "# Ensure the original synthetic_df is sorted by timestamp (assuming it is available)\n",
        "# If synthetic_df is also undefined, we'd need to re-create it first.\n",
        "# For now, assuming synthetic_df is still in scope from previous successful execution.\n",
        "# If not, the preceding cell (cd481695) would also need to be re-run.\n",
        "\n",
        "# Recalculate the size of each split\n",
        "total_interactions = len(synthetic_df)\n",
        "train_size = int(0.8 * total_interactions)\n",
        "val_size = int(0.1 * total_interactions)\n",
        "test_size = total_interactions - train_size - val_size\n",
        "\n",
        "# Recreate train, validation, and test sets\n",
        "train_df = synthetic_df.iloc[:train_size]\n",
        "val_df = synthetic_df.iloc[train_size : train_size + val_size]\n",
        "test_df = synthetic_df.iloc[train_size + val_size :]\n",
        "\n",
        "print(f\"Train set interactions: {len(train_df)}\")\n",
        "print(f\"Validation set interactions: {len(val_df)}\")\n",
        "print(f\"Test set interactions: {len(test_df)}\")\n",
        "\n",
        "\n",
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('\\n--- Initializing surprise.Reader and loading data ---')\n",
        "\n",
        "# 4. Create a surprise.Reader object\n",
        "# Since we are treating all interactions as implicit feedback, a rating scale of (1, 1) is suitable.\n",
        "# We'll use a dummy 'rating' of 1 for all interactions in the dataset.\n",
        "reader = Reader(rating_scale=(1, 1))\n",
        "\n",
        "# Prepare the data for Surprise library\n",
        "# Create a 'dummy_rating' column with a value of 1 for all interactions\n",
        "train_df_surprise = train_df[['student_id', 'item_id']].copy()\n",
        "train_df_surprise['dummy_rating'] = 1\n",
        "\n",
        "# 5. Load the train_df into a surprise.Dataset\n",
        "data = Dataset.load_from_df(train_df_surprise[['student_id', 'item_id', 'dummy_rating']], reader)\n",
        "\n",
        "# 6. Build a trainset from the loaded Dataset\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "print('\\n`surprise.Reader` object created and trainset built.')\n",
        "print(f\"Number of users in trainset: {trainset.n_users}\")\n",
        "print(f\"Number of items in trainset: {trainset.n_items}\")\n",
        "print(f\"Number of interactions in trainset: {trainset.n_ratings}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-creating DataFrames for Temporal Train/Validation/Test Split ---\n",
            "\n",
            "Train set interactions: 800\n",
            "Validation set interactions: 100\n",
            "Test set interactions: 100\n",
            "\n",
            "--- Initializing surprise.Reader and loading data ---\n",
            "\n",
            "`surprise.Reader` object created and trainset built.\n",
            "Number of users in trainset: 100\n",
            "Number of items in trainset: 50\n",
            "Number of interactions in trainset: 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64548601"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError` for `synthetic_df` indicates that the DataFrame was not defined in the current execution environment, likely due to previous installation attempts or out-of-order execution. I will regenerate `synthetic_df`, then perform the temporal split to create `train_df`, `val_df`, and `test_df`, and finally prepare `train_df` for the `surprise` library as per the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5fb589c",
        "outputId": "93703d58-14d0-4627-f144-ebe90f4e1eeb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "print('--- Re-generating Synthetic Dataset and Temporal Split ---\\n')\n",
        "\n",
        "# 1. Re-generate Synthetic Dataset (from original cell cd481695)\n",
        "num_students = 100\n",
        "num_items = 50\n",
        "num_interactions = 1000\n",
        "\n",
        "student_ids = np.random.randint(1, num_students + 1, num_interactions)\n",
        "item_ids = np.random.randint(1, num_items + 1, num_interactions)\n",
        "interaction_types = np.random.choice(['view', 'complete', 'enroll', 'quiz_attempt', 'discuss'], num_interactions)\n",
        "\n",
        "start_date = pd.to_datetime('2023-01-01')\n",
        "end_date = pd.to_datetime('2023-12-31')\n",
        "time_range = (end_date - start_date).total_seconds()\n",
        "timestamps = start_date + pd.to_timedelta(np.random.rand(num_interactions) * time_range, unit='s')\n",
        "\n",
        "synthetic_df = pd.DataFrame({\n",
        "    'student_id': student_ids,\n",
        "    'item_id': item_ids,\n",
        "    'interaction_type': interaction_types,\n",
        "    'timestamp': timestamps\n",
        "})\n",
        "\n",
        "synthetic_df = synthetic_df.sort_values(by='timestamp').reset_index(drop=True)\n",
        "print('Synthetic DataFrame regenerated. First 5 rows:')\n",
        "print(synthetic_df.head())\n",
        "\n",
        "\n",
        "print('\\n--- Temporal Train/Validation/Test Split ---\\n')\n",
        "\n",
        "# 2. Perform Temporal Train/Validation/Test Split\n",
        "total_interactions = len(synthetic_df)\n",
        "train_size = int(0.8 * total_interactions)\n",
        "val_size = int(0.1 * total_interactions)\n",
        "test_size = total_interactions - train_size - val_size\n",
        "\n",
        "train_df = synthetic_df.iloc[:train_size]\n",
        "val_df = synthetic_df.iloc[train_size : train_size + val_size]\n",
        "test_df = synthetic_df.iloc[train_size + val_size :]\n",
        "\n",
        "print(f\"Train set interactions: {len(train_df)}\")\n",
        "print(f\"Validation set interactions: {len(val_df)}\")\n",
        "print(f\"Test set interactions: {len(test_df)}\")\n",
        "\n",
        "print('\\n--- Initializing surprise.Reader and loading data ---')\n",
        "\n",
        "# 3. Create a surprise.Reader object\n",
        "reader = Reader(rating_scale=(1, 1))\n",
        "\n",
        "# Prepare the data for Surprise library\n",
        "train_df_surprise = train_df[['student_id', 'item_id']].copy()\n",
        "train_df_surprise['dummy_rating'] = 1\n",
        "\n",
        "# 4. Load the train_df into a surprise.Dataset\n",
        "data = Dataset.load_from_df(train_df_surprise[['student_id', 'item_id', 'dummy_rating']], reader)\n",
        "\n",
        "# 5. Build a trainset from the loaded Dataset\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "print('\\n`surprise.Reader` object created and trainset built.')\n",
        "print(f\"Number of users in trainset: {trainset.n_users}\")\n",
        "print(f\"Number of items in trainset: {trainset.n_items}\")\n",
        "print(f\"Number of interactions in trainset: {trainset.n_ratings}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Re-generating Synthetic Dataset and Temporal Split ---\n",
            "\n",
            "Synthetic DataFrame regenerated. First 5 rows:\n",
            "   student_id  item_id interaction_type                     timestamp\n",
            "0          19       20           enroll 2023-01-01 08:44:11.044905501\n",
            "1          82        1     quiz_attempt 2023-01-01 23:31:49.137820129\n",
            "2          72        6           enroll 2023-01-03 01:31:56.113418498\n",
            "3          27       17          discuss 2023-01-03 03:56:36.992730136\n",
            "4          86        3             view 2023-01-03 07:22:37.398096249\n",
            "\n",
            "--- Temporal Train/Validation/Test Split ---\n",
            "\n",
            "Train set interactions: 800\n",
            "Validation set interactions: 100\n",
            "Test set interactions: 100\n",
            "\n",
            "--- Initializing surprise.Reader and loading data ---\n",
            "\n",
            "`surprise.Reader` object created and trainset built.\n",
            "Number of users in trainset: 99\n",
            "Number of items in trainset: 50\n",
            "Number of interactions in trainset: 800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2c3d4fd"
      },
      "source": [
        "**Reasoning**:\n",
        "I have successfully prepared the `trainset` for the `surprise` library. Now, as per the subtask instructions, I will initialize a `surprise.SVD` model and train it on this `trainset`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d0cf07c",
        "outputId": "a8ae101d-743a-4bf9-9b98-de51bbff8107"
      },
      "source": [
        "print('\\n--- Training Collaborative Filtering Model (SVD) ---')\n",
        "\n",
        "# 7. Initialize a surprise.SVD model and train it on the trainset\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "print('\\nSVD model trained successfully.')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Collaborative Filtering Model (SVD) ---\n",
            "\n",
            "SVD model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b8c1794"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the SVD model is trained, I will define the `get_cf_recommendations` function. This function will take a `student_id`, the number of recommendations `n`, optionally a set of `historical_interactions`, the trained `surprise.SVD` model, and the `trainset`. It will predict ratings for items the student has not yet interacted with and return the top `n` items with the highest predicted ratings, as specified in the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c24f0ef6",
        "outputId": "84d8fa9d-a4b2-46f5-f166-2132787cec91"
      },
      "source": [
        "print('\\n--- Defining get_cf_recommendations function ---')\n",
        "\n",
        "def get_cf_recommendations(student_id, n, historical_interactions, model, trainset):\n",
        "    # Get a list of all unique items\n",
        "    all_item_ids = synthetic_df['item_id'].unique()\n",
        "\n",
        "    # Filter out items the student has already interacted with\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        # The `predict` method needs the raw user ID, raw item ID, and a dummy rating.\n",
        "        # The dummy rating (r_ui) doesn't influence the prediction for SVD.\n",
        "        # We use a known `uid` and `iid` to represent the student and item.\n",
        "        # `SVD` expects `raw_uid` and `raw_iid` (student_id and item_id here)\n",
        "        # and `r_ui` (the actual rating, which is 1 in our implicit feedback setup)\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    # Sort predictions by estimated rating in descending order\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "    # Get top n item_ids\n",
        "    top_n_items = [pred.iid for pred in predictions[:n]]\n",
        "    return top_n_items\n",
        "\n",
        "print('`get_cf_recommendations` function defined.')\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Defining get_cf_recommendations function ---\n",
            "`get_cf_recommendations` function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6712a2b"
      },
      "source": [
        "## Evaluate Baseline Models\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the 'Most Popular' and 'Collaborative Filtering' baseline models using ranking metrics like Precision@K and Recall@K on the test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c25b97ea"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `get_actual_interactions` function, which extracts unique `item_id`s for a given `student_id` from a specified DataFrame, as required by the first instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00f398e4",
        "outputId": "0d2f4dd7-9953-4ed2-c1e6-dfc198776744"
      },
      "source": [
        "print('--- Defining Evaluation Functions ---\\n')\n",
        "\n",
        "# 1. Define a function get_actual_interactions(student_id, df)\n",
        "def get_actual_interactions(student_id, df):\n",
        "    \"\"\"\n",
        "    Returns a set of item_id's from the input DataFrame df for a given student_id.\n",
        "    \"\"\"\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "print('`get_actual_interactions` function defined.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Defining Evaluation Functions ---\n",
            "\n",
            "`get_actual_interactions` function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "825cc6c3"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `get_historical_interactions` function, which extracts unique `item_id`s for a given `student_id` from a specified DataFrame, as required by the second instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6cac606",
        "outputId": "e394035b-3998-4d4a-f2e2-4022e62439ba"
      },
      "source": [
        "print('\\n--- Defining get_historical_interactions function ---\\n')\n",
        "\n",
        "# 2. Define a function get_historical_interactions(student_id, df)\n",
        "def get_historical_interactions(student_id, df):\n",
        "    \"\"\"\n",
        "    Returns a set of item_id's from the input DataFrame df for a given student_id.\n",
        "    \"\"\"\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "print('`get_historical_interactions` function defined.')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Defining get_historical_interactions function ---\n",
            "\n",
            "`get_historical_interactions` function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5168b0a"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `precision_at_k` function, which calculates the Precision@K metric given a list of recommended items, actual interacted items, and the value of K, as required by the third instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72c1e8f0",
        "outputId": "05c9e8aa-5eff-44e0-b4a5-06d8ca1fe9d1"
      },
      "source": [
        "print('\\n--- Defining Precision@K function ---\\n')\n",
        "\n",
        "# 3. Define a function precision_at_k(recommended_items, actual_items, k)\n",
        "def precision_at_k(recommended_items, actual_items, k):\n",
        "    \"\"\"\n",
        "    Calculates Precision@K.\n",
        "    :param recommended_items: List of recommended item IDs.\n",
        "    :param actual_items: Set of actual interacted item IDs.\n",
        "    :param k: The number of recommendations considered.\n",
        "    :return: Precision@K score.\n",
        "    \"\"\"\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Ensure k is not greater than the number of recommended items\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / k\n",
        "\n",
        "print('`precision_at_k` function defined.')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Defining Precision@K function ---\n",
            "\n",
            "`precision_at_k` function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af297cb0"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `recall_at_k` function, which calculates the Recall@K metric given a list of recommended items, actual interacted items, and the value of K, as required by the fourth instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bf98c80",
        "outputId": "05224891-9968-44d2-aa4f-302d36ccbb1f"
      },
      "source": [
        "print('--- Defining Recall@K function ---')\n",
        "\n",
        "# 4. Define a function recall_at_k(recommended_items, actual_items, k)\n",
        "def recall_at_k(recommended_items, actual_items, k):\n",
        "    \"\"\"\n",
        "    Calculates Recall@K.\n",
        "    :param recommended_items: List of recommended item IDs.\n",
        "    :param actual_items: Set of actual interacted item IDs.\n",
        "    :param k: The number of recommendations considered.\n",
        "    :return: Recall@K score.\n",
        "    \"\"\"\n",
        "    if len(actual_items) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Ensure k is not greater than the number of recommended items\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / len(actual_items)\n",
        "\n",
        "print('`recall_at_k` function defined.')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Defining Recall@K function ---\n",
            "`recall_at_k` function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ea28302"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to a `SyntaxError: unterminated string literal` in the print statement. I will correct the string literal by closing it on the same line to fix the syntax error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a11fcfae",
        "outputId": "57bab4a3-0576-4d27-e195-9a4beb740ff6"
      },
      "source": [
        "print('--- Defining Recall@K function ---\\n')\n",
        "\n",
        "# 4. Define a function recall_at_k(recommended_items, actual_items, k)\n",
        "def recall_at_k(recommended_items, actual_items, k):\n",
        "    \"\"\"\n",
        "    Calculates Recall@K.\n",
        "    :param recommended_items: List of recommended item IDs.\n",
        "    :param actual_items: Set of actual interacted item IDs.\n",
        "    :param k: The number of recommendations considered.\n",
        "    :return: Recall@K score.\n",
        "    \"\"\"\n",
        "    if len(actual_items) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Ensure k is not greater than the number of recommended items\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / len(actual_items)\n",
        "\n",
        "print('`recall_at_k` function defined.')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Defining Recall@K function ---\n",
            "\n",
            "`recall_at_k` function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61e1408e"
      },
      "source": [
        "**Reasoning**:\n",
        "I will initialize empty lists to store the Precision@K and Recall@K scores for both the 'Most Popular' and 'Collaborative Filtering' models, as required by the fifth instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71ff55e2",
        "outputId": "dabac43b-61e7-45b6-ee31-8d27f1f18d58"
      },
      "source": [
        "print('\\n--- Initializing lists for evaluation metrics ---\\n')\n",
        "\n",
        "# 5. Initialize lists to store Precision@K and Recall@K scores\n",
        "most_popular_precision_scores = []\n",
        "most_popular_recall_scores = []\n",
        "cf_precision_scores = []\n",
        "cf_recall_scores = []\n",
        "\n",
        "print('Evaluation metric lists initialized.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initializing lists for evaluation metrics ---\n",
            "\n",
            "Evaluation metric lists initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a88ba27"
      },
      "source": [
        "**Reasoning**:\n",
        "I will iterate through each unique `student_id` in the `test_df` to prepare for generating recommendations and calculating metrics, as required by the sixth instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "059dd52b",
        "outputId": "8b670c6e-2fd7-41e7-f88f-c67994b317ed"
      },
      "source": [
        "print('\\n--- Iterating through students in test set for evaluation ---\\n')\n",
        "\n",
        "# Set the value for K for Precision@K and Recall@K\n",
        "K = 10\n",
        "\n",
        "# Get all unique student_ids from the test set\n",
        "unique_test_students = test_df['student_id'].unique()\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students)} unique students in the test set with K={K}.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iterating through students in test set for evaluation ---\n",
            "\n",
            "Starting evaluation for 64 unique students in the test set with K=10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f7d49fb"
      },
      "source": [
        "**Reasoning**:\n",
        "I will now iterate through each unique student in the test set, retrieve their historical and actual interactions, generate recommendations using both baseline models, calculate Precision@K and Recall@K, and store these scores. This combines instructions 7, 8, 9, and 10 of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a09890b9",
        "outputId": "e8ec3e59-747c-4e4d-8e86-600143b1bd19"
      },
      "source": [
        "print('\\n--- Generating Recommendations and Calculating Metrics for each student ---\\n')\n",
        "\n",
        "for student_id in unique_test_students:\n",
        "    # 7. Get historical and actual interactions\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    # Only evaluate if the student has actual interactions in the test set\n",
        "    if len(actual_interactions) > 0:\n",
        "        # 8. Generate recommendations\n",
        "        most_popular_recs = get_most_popular_recommendations(student_id, K, historical_interactions)\n",
        "        cf_recs = get_cf_recommendations(student_id, K, historical_interactions, algo, trainset)\n",
        "\n",
        "        # 9. Calculate Precision@K and Recall@K\n",
        "        mp_precision = precision_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_recall = recall_at_k(most_popular_recs, actual_interactions, K)\n",
        "\n",
        "        cf_precision = precision_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_recall = recall_at_k(cf_recs, actual_interactions, K)\n",
        "\n",
        "        # 10. Append scores to respective lists\n",
        "        most_popular_precision_scores.append(mp_precision)\n",
        "        most_popular_recall_scores.append(mp_recall)\n",
        "        cf_precision_scores.append(cf_precision)\n",
        "        cf_recall_scores.append(cf_recall)\n",
        "\n",
        "print('Recommendation generation and metric calculation complete for all eligible students.')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating Recommendations and Calculating Metrics for each student ---\n",
            "\n",
            "Recommendation generation and metric calculation complete for all eligible students.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b18a870"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError` indicates that `get_most_popular_recommendations` and potentially other related variables/functions were not defined in the current execution environment. This is likely due to the kernel state being reset or previous cells not being re-executed. I need to re-define the `item_popularity` DataFrame and both `get_most_popular_recommendations` and `get_cf_recommendations` functions before the evaluation loop can correctly execute.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0952a374",
        "outputId": "939d55f6-4f90-45d7-84cf-f924bbe7e10f"
      },
      "source": [
        "print('--- Re-defining Recommendation Functions and Generating Metrics for each student ---\\n')\n",
        "\n",
        "# Re-calculate item_popularity (from cell 12886fec)\n",
        "item_popularity = train_df['item_id'].value_counts().reset_index()\n",
        "item_popularity.columns = ['item_id', 'popularity_score']\n",
        "\n",
        "# Re-define get_most_popular_recommendations function (from cell 037917a8)\n",
        "def get_most_popular_recommendations(student_id, n, historical_interactions=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "\n",
        "    # Filter out items already interacted with by the student\n",
        "    recommended_items = item_popularity[~item_popularity['item_id'].isin(historical_interactions)]\n",
        "\n",
        "    # Sort by popularity and get top n items\n",
        "    recommended_items = recommended_items.sort_values(by='popularity_score', ascending=False)\n",
        "\n",
        "    return recommended_items.head(n)['item_id'].tolist()\n",
        "\n",
        "# Re-define get_cf_recommendations function (from cell c24f0ef6)\n",
        "def get_cf_recommendations(student_id, n, historical_interactions, model, trainset):\n",
        "    # Get a list of all unique items\n",
        "    all_item_ids = synthetic_df['item_id'].unique()\n",
        "\n",
        "    # Filter out items the student has already interacted with\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    # Sort predictions by estimated rating in descending order\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "    # Get top n item_ids\n",
        "    top_n_items = [pred.iid for pred in predictions[:n]]\n",
        "    return top_n_items\n",
        "\n",
        "# Set the value for K for Precision@K and Recall@K\n",
        "K = 10\n",
        "\n",
        "# Get all unique student_ids from the test set\n",
        "unique_test_students = test_df['student_id'].unique()\n",
        "\n",
        "# Ensure algo and trainset are defined (assuming they were successfully created in b5fb589c and 3d0cf07c)\n",
        "# and synthetic_df is defined (from b5fb589c)\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students)} unique students in the test set with K={K}.\")\n",
        "\n",
        "for student_id in unique_test_students:\n",
        "    # 7. Get historical and actual interactions\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    # Only evaluate if the student has actual interactions in the test set\n",
        "    if len(actual_interactions) > 0:\n",
        "        # 8. Generate recommendations\n",
        "        most_popular_recs = get_most_popular_recommendations(student_id, K, historical_interactions)\n",
        "        cf_recs = get_cf_recommendations(student_id, K, historical_interactions, algo, trainset)\n",
        "\n",
        "        # 9. Calculate Precision@K and Recall@K\n",
        "        mp_precision = precision_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_recall = recall_at_k(most_popular_recs, actual_interactions, K)\n",
        "\n",
        "        cf_precision = precision_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_recall = recall_at_k(cf_recs, actual_interactions, K)\n",
        "\n",
        "        # 10. Append scores to respective lists\n",
        "        most_popular_precision_scores.append(mp_precision)\n",
        "        most_popular_recall_scores.append(mp_recall)\n",
        "        cf_precision_scores.append(cf_precision)\n",
        "        cf_recall_scores.append(cf_recall)\n",
        "\n",
        "print('Recommendation generation and metric calculation complete for all eligible students.')\n",
        "\n",
        "# 11. Calculate and print the average Precision@K and Recall@K for both models.\n",
        "print('\\n--- Average Evaluation Metrics ---\\n')\n",
        "\n",
        "if most_popular_precision_scores:\n",
        "    print(f\"Most Popular Model - Average Precision@{K}: {np.mean(most_popular_precision_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Average Recall@{K}: {np.mean(most_popular_recall_scores):.4f}\")\n",
        "else:\n",
        "    print(\"No scores calculated for Most Popular Model.\")\n",
        "\n",
        "if cf_precision_scores:\n",
        "    print(f\"Collaborative Filtering Model - Average Precision@{K}: {np.mean(cf_precision_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Average Recall@{K}: {np.mean(cf_recall_scores):.4f}\")\n",
        "else:\n",
        "    print(\"No scores calculated for Collaborative Filtering Model.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Re-defining Recommendation Functions and Generating Metrics for each student ---\n",
            "\n",
            "Starting evaluation for 64 unique students in the test set with K=10.\n",
            "Recommendation generation and metric calculation complete for all eligible students.\n",
            "\n",
            "--- Average Evaluation Metrics ---\n",
            "\n",
            "Most Popular Model - Average Precision@10: 0.0258\n",
            "Most Popular Model - Average Recall@10: 0.1484\n",
            "Collaborative Filtering Model - Average Precision@10: 0.0422\n",
            "Collaborative Filtering Model - Average Recall@10: 0.2812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8514e27"
      },
      "source": [
        "## Implement Advanced Models & Pipeline\n",
        "\n",
        "### Subtask:\n",
        "Develop a Hybrid Recommendation Model using the trained Collaborative Filtering (SVD) model for candidate generation and a ranking model based on engineered features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e69876a"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `generate_candidates_for_user` function, which will use the trained SVD model to predict ratings for items a student has not interacted with and return the top N candidates, as per the first instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bda4775c",
        "outputId": "456e8239-50d3-4bae-b8f8-d40de9741fae"
      },
      "source": [
        "print('--- Defining candidate generation function ---\\n')\n",
        "\n",
        "def generate_candidates_for_user(student_id, model, n_candidates=100, historical_interactions=None, all_item_ids=None):\n",
        "    \"\"\"\n",
        "    Generates candidate items for a given student_id using the SVD model.\n",
        "\n",
        "    :param student_id: The ID of the student.\n",
        "    :param model: The trained surprise.SVD model.\n",
        "    :param n_candidates: The number of candidate items to return.\n",
        "    :param historical_interactions: A set of item_ids that the student has already interacted with.\n",
        "    :param all_item_ids: A list or array of all unique item_ids in the dataset.\n",
        "    :return: A list of top n_candidates item_ids.\n",
        "    \"\"\"\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "    if all_item_ids is None:\n",
        "        all_item_ids = synthetic_df['item_id'].unique() # Assuming synthetic_df is available globally\n",
        "\n",
        "    # Filter out items the student has already interacted with\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        # The `predict` method needs the raw user ID, raw item ID, and a dummy rating.\n",
        "        # r_ui doesn't influence the prediction for SVD in this implicit feedback context.\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    # Sort predictions by estimated rating in descending order\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "    # Get top n_candidates item_ids\n",
        "    top_n_items = [pred.iid for pred in predictions[:n_candidates]]\n",
        "    return top_n_items\n",
        "\n",
        "print('`generate_candidates_for_user` function defined.')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Defining candidate generation function ---\n",
            "\n",
            "`generate_candidates_for_user` function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04469845"
      },
      "source": [
        "**Reasoning**:\n",
        "I will prepare the positive training samples for the ranking model by taking the `train_df`, adding a `target` column set to 1, and merging the previously engineered user, item, and temporal features into it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f657c7c",
        "outputId": "19c00aad-55f2-4962-c2d4-095c3f601c66"
      },
      "source": [
        "print('\\n--- Preparing Positive Samples for Ranking Model ---\\n')\n",
        "\n",
        "# 2. Prepare training data for the ranking model (Positive Samples)\n",
        "# For each interaction in `train_df`, generate a feature vector.\n",
        "\n",
        "# Create a copy of train_df to avoid modifying the original and add a target variable\n",
        "positive_samples_df = train_df.copy()\n",
        "positive_samples_df['target'] = 1 # 1 indicates an actual interaction\n",
        "\n",
        "# Ensure user_interactions and item_interactions are available (they were created in feature engineering)\n",
        "# If they were not created, they would need to be re-run from cell 757f4caf\n",
        "\n",
        "# Merge user features\n",
        "# Note: user_interactions and item_interactions were created using only train_df data\n",
        "# So merging them back onto train_df (or a copy of it) is appropriate.\n",
        "positive_samples_df = pd.merge(positive_samples_df, user_interactions, on='student_id', how='left')\n",
        "\n",
        "# Merge item features\n",
        "positive_samples_df = pd.merge(positive_samples_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# Temporal features (day_of_week, hour_of_day) are already part of train_df, so they are included in positive_samples_df.copy()\n",
        "\n",
        "print('First 5 rows of Positive Samples DataFrame with features:')\n",
        "print(positive_samples_df.head())\n",
        "print(f\"\\nShape of Positive Samples DataFrame: {positive_samples_df.shape}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Preparing Positive Samples for Ranking Model ---\n",
            "\n",
            "First 5 rows of Positive Samples DataFrame with features:\n",
            "   student_id  item_id interaction_type                     timestamp  target  \\\n",
            "0          19       20           enroll 2023-01-01 08:44:11.044905501       1   \n",
            "1          82        1     quiz_attempt 2023-01-01 23:31:49.137820129       1   \n",
            "2          72        6           enroll 2023-01-03 01:31:56.113418498       1   \n",
            "3          27       17          discuss 2023-01-03 03:56:36.992730136       1   \n",
            "4          86        3             view 2023-01-03 07:22:37.398096249       1   \n",
            "\n",
            "   total_interactions_user  unique_items_interacted  \\\n",
            "0                        5                        4   \n",
            "1                        8                        8   \n",
            "2                       15                       13   \n",
            "3                        5                        5   \n",
            "4                        7                        6   \n",
            "\n",
            "  most_frequent_interaction_type_user  total_interactions_item  \\\n",
            "0                            complete                        9   \n",
            "1                             discuss                       22   \n",
            "2                            complete                       21   \n",
            "3                                view                       17   \n",
            "4                                view                       15   \n",
            "\n",
            "   unique_students_interacted most_frequent_interaction_type_item  \n",
            "0                           9                              enroll  \n",
            "1                          22                              enroll  \n",
            "2                          18                        quiz_attempt  \n",
            "3                          16                              enroll  \n",
            "4                          13                             discuss  \n",
            "\n",
            "Shape of Positive Samples DataFrame: (800, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f323a03"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError` indicates that `user_interactions` and `item_interactions` DataFrames were not defined. These were supposed to be created in a previous feature engineering step. I will regenerate these feature DataFrames using the existing `train_df` and then proceed to merge them into a copy of `train_df` to create `positive_samples_df` with the target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee0afb00",
        "outputId": "db8ba5d6-850e-4038-ba63-2f4df30f03c6"
      },
      "source": [
        "print('\\n--- Re-calculating Features and Preparing Positive Samples for Ranking Model ---\\n')\n",
        "\n",
        "# Recalculate User Features from train_df (from cell 757f4caf)\n",
        "user_interactions = train_df.groupby('student_id').agg(\n",
        "    total_interactions_user=('item_id', 'count'),\n",
        "    unique_items_interacted=('item_id', 'nunique'),\n",
        "    most_frequent_interaction_type_user=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Recalculate Item Features from train_df (from cell 757f4caf)\n",
        "item_interactions = train_df.groupby('item_id').agg(\n",
        "    total_interactions_item=('student_id', 'count'),\n",
        "    unique_students_interacted=('student_id', 'nunique'),\n",
        "    most_frequent_interaction_type_item=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Create a copy of train_df to avoid modifying the original and add a target variable\n",
        "positive_samples_df = train_df.copy()\n",
        "positive_samples_df['target'] = 1 # 1 indicates an actual interaction\n",
        "\n",
        "# Merge the created user and item features into positive_samples_df\n",
        "positive_samples_df = pd.merge(positive_samples_df, user_interactions, on='student_id', how='left')\n",
        "positive_samples_df = pd.merge(positive_samples_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# Ensure temporal features are also present (extracted previously in cell 21b619e8)\n",
        "# If they are not present due to kernel state issues, re-extract them here.\n",
        "if 'day_of_week' not in positive_samples_df.columns:\n",
        "    positive_samples_df['day_of_week'] = positive_samples_df['timestamp'].dt.dayofweek\n",
        "    positive_samples_df['hour_of_day'] = positive_samples_df['timestamp'].dt.hour\n",
        "\n",
        "print('First 5 rows of Positive Samples DataFrame with features:')\n",
        "print(positive_samples_df.head())\n",
        "print(f\"\\nShape of Positive Samples DataFrame: {positive_samples_df.shape}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Re-calculating Features and Preparing Positive Samples for Ranking Model ---\n",
            "\n",
            "First 5 rows of Positive Samples DataFrame with features:\n",
            "   student_id  item_id interaction_type                     timestamp  target  \\\n",
            "0          19       20           enroll 2023-01-01 08:44:11.044905501       1   \n",
            "1          82        1     quiz_attempt 2023-01-01 23:31:49.137820129       1   \n",
            "2          72        6           enroll 2023-01-03 01:31:56.113418498       1   \n",
            "3          27       17          discuss 2023-01-03 03:56:36.992730136       1   \n",
            "4          86        3             view 2023-01-03 07:22:37.398096249       1   \n",
            "\n",
            "   total_interactions_user  unique_items_interacted  \\\n",
            "0                        6                        6   \n",
            "1                       11                       11   \n",
            "2                       10                       10   \n",
            "3                        6                        5   \n",
            "4                       11                       10   \n",
            "\n",
            "  most_frequent_interaction_type_user  total_interactions_item  \\\n",
            "0                             discuss                       17   \n",
            "1                        quiz_attempt                       15   \n",
            "2                             discuss                       20   \n",
            "3                             discuss                       20   \n",
            "4                                view                       14   \n",
            "\n",
            "   unique_students_interacted most_frequent_interaction_type_item  \\\n",
            "0                          15                            complete   \n",
            "1                          13                            complete   \n",
            "2                          18                              enroll   \n",
            "3                          16                            complete   \n",
            "4                          13                                view   \n",
            "\n",
            "   day_of_week  hour_of_day  \n",
            "0            6            8  \n",
            "1            6           23  \n",
            "2            1            1  \n",
            "3            1            3  \n",
            "4            1            7  \n",
            "\n",
            "Shape of Positive Samples DataFrame: (800, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9369bb03"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that positive samples are prepared, I will generate negative samples for each student. This involves identifying items from the `train_df` that a student has not interacted with, creating a DataFrame for these non-interactions, merging the relevant user, item, and temporal features, and assigning a target value of 0. I will aim for a 1:1 ratio of positive to negative samples per student if possible, otherwise I will take all available non-interacted items, as per the instruction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b44e5af",
        "outputId": "c30b16b8-402f-4b75-ad76-a34fb8297893"
      },
      "source": [
        "print('\\n--- Generating Negative Samples for Ranking Model ---\\n')\n",
        "\n",
        "negative_samples_list = []\n",
        "\n",
        "# Get all unique items\n",
        "all_item_ids = synthetic_df['item_id'].unique()\n",
        "\n",
        "# Iterate through each unique student in the train_df\n",
        "for student_id in train_df['student_id'].unique():\n",
        "    # Get items the student has actually interacted with in the train_df\n",
        "    interacted_items = set(train_df[train_df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "    # Get items the student has NOT interacted with\n",
        "    non_interacted_items = [item_id for item_id in all_item_ids if item_id not in interacted_items]\n",
        "\n",
        "    # Number of positive interactions for this student\n",
        "    num_positive_interactions = len(train_df[train_df['student_id'] == student_id])\n",
        "\n",
        "    # Generate negative samples: we'll try to match the number of positive samples for balance\n",
        "    # If there are fewer non_interacted_items than positive, take all available\n",
        "    num_negative_samples_to_generate = min(num_positive_interactions, len(non_interacted_items))\n",
        "\n",
        "    if num_negative_samples_to_generate > 0:\n",
        "        # Randomly select non-interacted items\n",
        "        sampled_negative_items = np.random.choice(non_interacted_items, num_negative_samples_to_generate, replace=False)\n",
        "\n",
        "        for item_id in sampled_negative_items:\n",
        "            negative_samples_list.append({\n",
        "                'student_id': student_id,\n",
        "                'item_id': item_id,\n",
        "                'target': 0\n",
        "            })\n",
        "\n",
        "negative_samples_df = pd.DataFrame(negative_samples_list)\n",
        "\n",
        "# Merge user features into negative_samples_df\n",
        "negative_samples_df = pd.merge(negative_samples_df, user_interactions, on='student_id', how='left')\n",
        "\n",
        "# Merge item features into negative_samples_df\n",
        "negative_samples_df = pd.merge(negative_samples_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# Temporal features for negative samples - use mean values from train_df as a proxy since actual timestamps don't exist\n",
        "# Or more realistically, we should consider how to generate 'meaningful' temporal features for non-interactions.\n",
        "# For simplicity, for now, we'll assign 'typical' temporal features if they don't exist.\n",
        "# Or, even better, we could omit them for negative samples if the ranking model is not expected to use them for non-interactions.\n",
        "# For this demonstration, we'll skip adding temporal features to negative samples as they don't have a direct timestamp.\n",
        "# If the model needs them, a more sophisticated approach (e.g., average activity time for the user/item) would be needed.\n",
        "\n",
        "print('First 5 rows of Negative Samples DataFrame with features:')\n",
        "print(negative_samples_df.head())\n",
        "print(f\"\\nShape of Negative Samples DataFrame: {negative_samples_df.shape}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Generating Negative Samples for Ranking Model ---\n",
            "\n",
            "First 5 rows of Negative Samples DataFrame with features:\n",
            "   student_id  item_id  target  total_interactions_user  \\\n",
            "0          19       34       0                        6   \n",
            "1          19       14       0                        6   \n",
            "2          19       45       0                        6   \n",
            "3          19        4       0                        6   \n",
            "4          19       37       0                        6   \n",
            "\n",
            "   unique_items_interacted most_frequent_interaction_type_user  \\\n",
            "0                        6                             discuss   \n",
            "1                        6                             discuss   \n",
            "2                        6                             discuss   \n",
            "3                        6                             discuss   \n",
            "4                        6                             discuss   \n",
            "\n",
            "   total_interactions_item  unique_students_interacted  \\\n",
            "0                       23                          20   \n",
            "1                       11                          10   \n",
            "2                       15                          13   \n",
            "3                       14                          13   \n",
            "4                       14                          14   \n",
            "\n",
            "  most_frequent_interaction_type_item  \n",
            "0                            complete  \n",
            "1                            complete  \n",
            "2                            complete  \n",
            "3                            complete  \n",
            "4                                view  \n",
            "\n",
            "Shape of Negative Samples DataFrame: (800, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70a7d181"
      },
      "source": [
        "**Reasoning**:\n",
        "I will combine the previously generated `positive_samples_df` and `negative_samples_df` into a single DataFrame to create the full training dataset for the ranking model, as specified in the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b1b4b12",
        "outputId": "4bbbb6ba-91b6-4e12-a222-fe78334e8f44"
      },
      "source": [
        "print('\\n--- Combining Positive and Negative Samples for Ranking Model ---\\n')\n",
        "\n",
        "# 4. Combine positive and negative samples\n",
        "training_data_ranking = pd.concat([positive_samples_df, negative_samples_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the combined DataFrame to mix positive and negative samples\n",
        "training_data_ranking = training_data_ranking.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print('First 5 rows of Combined Ranking Training Data:')\n",
        "print(training_data_ranking.head())\n",
        "print(f\"\\nShape of Combined Ranking Training Data: {training_data_ranking.shape}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Combining Positive and Negative Samples for Ranking Model ---\n",
            "\n",
            "First 5 rows of Combined Ranking Training Data:\n",
            "   student_id  item_id interaction_type                     timestamp  target  \\\n",
            "0          51       46             view 2023-07-13 06:09:32.767797153       1   \n",
            "1          36       11          discuss 2023-05-10 09:07:42.207314111       1   \n",
            "2          62       44             view 2023-03-01 21:33:32.801426250       1   \n",
            "3          66       46             view 2023-02-15 06:52:48.555622779       1   \n",
            "4          58        8              NaN                           NaT       0   \n",
            "\n",
            "   total_interactions_user  unique_items_interacted  \\\n",
            "0                        9                        8   \n",
            "1                       13                       12   \n",
            "2                       10                       10   \n",
            "3                       14                       13   \n",
            "4                       13                       10   \n",
            "\n",
            "  most_frequent_interaction_type_user  total_interactions_item  \\\n",
            "0                                view                       14   \n",
            "1                            complete                       19   \n",
            "2                             discuss                       18   \n",
            "3                              enroll                       14   \n",
            "4                                view                       27   \n",
            "\n",
            "   unique_students_interacted most_frequent_interaction_type_item  \\\n",
            "0                          13                                view   \n",
            "1                          16                                view   \n",
            "2                          16                              enroll   \n",
            "3                          13                                view   \n",
            "4                          24                                view   \n",
            "\n",
            "   day_of_week  hour_of_day  \n",
            "0          3.0          6.0  \n",
            "1          2.0          9.0  \n",
            "2          2.0         21.0  \n",
            "3          2.0          6.0  \n",
            "4          NaN          NaN  \n",
            "\n",
            "Shape of Combined Ranking Training Data: (1600, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01a8e6e4"
      },
      "source": [
        "**Reasoning**:\n",
        "I will identify the categorical features within the `training_data_ranking` DataFrame by inspecting its `dtypes` and the nature of the columns, as required by the fifth instruction of the subtask. Columns like `interaction_type` and `most_frequent_interaction_type_user/item` are clearly categorical, and `day_of_week`/`hour_of_day` can also be treated as such.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dc3482d",
        "outputId": "372f9a84-a2aa-4948-8a76-5c5316ca163e"
      },
      "source": [
        "print('--- Identifying Categorical Features for Ranking Model ---')\n",
        "\n",
        "# Identify categorical features\n",
        "categorical_features = [\n",
        "    'interaction_type',\n",
        "    'most_frequent_interaction_type_user',\n",
        "    'most_frequent_interaction_type_item',\n",
        "    'day_of_week', # Treat day of week as categorical\n",
        "    'hour_of_day'  # Treat hour of day as categorical\n",
        "]\n",
        "\n",
        "# Ensure the features actually exist in the DataFrame\n",
        "categorical_features = [col for col in categorical_features if col in training_data_ranking.columns]\n",
        "\n",
        "# Verify types and handle potential NaN in categorical columns before encoding\n",
        "# For simplicity, we'll fill NaN with a placeholder string for object type categoricals\n",
        "# and with -1 or a specific number for numerical categoricals if they occur.\n",
        "# In this case, `day_of_week` and `hour_of_day` might have NaNs from negative samples.\n",
        "for col in ['day_of_week', 'hour_of_day']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna(-1).astype(int)\n",
        "\n",
        "for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna('unknown')\n",
        "\n",
        "\n",
        "print(\"Identified Categorical Features:\")\n",
        "print(categorical_features)\n",
        "\n",
        "print('\\nFirst 5 rows of training_data_ranking after NaN handling for categoricals:')\n",
        "print(training_data_ranking.head())\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Identifying Categorical Features for Ranking Model ---\n",
            "Identified Categorical Features:\n",
            "['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item', 'day_of_week', 'hour_of_day']\n",
            "\n",
            "First 5 rows of training_data_ranking after NaN handling for categoricals:\n",
            "   student_id  item_id interaction_type                     timestamp  target  \\\n",
            "0          51       46             view 2023-07-13 06:09:32.767797153       1   \n",
            "1          36       11          discuss 2023-05-10 09:07:42.207314111       1   \n",
            "2          62       44             view 2023-03-01 21:33:32.801426250       1   \n",
            "3          66       46             view 2023-02-15 06:52:48.555622779       1   \n",
            "4          58        8          unknown                           NaT       0   \n",
            "\n",
            "   total_interactions_user  unique_items_interacted  \\\n",
            "0                        9                        8   \n",
            "1                       13                       12   \n",
            "2                       10                       10   \n",
            "3                       14                       13   \n",
            "4                       13                       10   \n",
            "\n",
            "  most_frequent_interaction_type_user  total_interactions_item  \\\n",
            "0                                view                       14   \n",
            "1                            complete                       19   \n",
            "2                             discuss                       18   \n",
            "3                              enroll                       14   \n",
            "4                                view                       27   \n",
            "\n",
            "   unique_students_interacted most_frequent_interaction_type_item  \\\n",
            "0                          13                                view   \n",
            "1                          16                                view   \n",
            "2                          16                              enroll   \n",
            "3                          13                                view   \n",
            "4                          24                                view   \n",
            "\n",
            "   day_of_week  hour_of_day  \n",
            "0            3            6  \n",
            "1            2            9  \n",
            "2            2           21  \n",
            "3            2            6  \n",
            "4           -1           -1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b5e7c1b"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to a `SyntaxError: unterminated string literal` in the print statement. I will correct this by ensuring the string literal is properly closed on a single line.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93c873ad",
        "outputId": "362bd399-e573-4f0f-b7d8-5e336c4c730d"
      },
      "source": [
        "print('--- Identifying Categorical Features for Ranking Model ---')\n",
        "\n",
        "# Identify categorical features\n",
        "categorical_features = [\n",
        "    'interaction_type',\n",
        "    'most_frequent_interaction_type_user',\n",
        "    'most_frequent_interaction_type_item',\n",
        "    'day_of_week', # Treat day of week as categorical\n",
        "    'hour_of_day'  # Treat hour of day as categorical\n",
        "]\n",
        "\n",
        "# Ensure the features actually exist in the DataFrame\n",
        "categorical_features = [col for col in categorical_features if col in training_data_ranking.columns]\n",
        "\n",
        "# Verify types and handle potential NaN in categorical columns before encoding\n",
        "# For simplicity, we'll fill NaN with a placeholder string for object type categoricals\n",
        "# and with -1 or a specific number for numerical categoricals if they occur.\n",
        "# In this case, `day_of_week` and `hour_of_day` might have NaNs from negative samples.\n",
        "for col in ['day_of_week', 'hour_of_day']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna(-1).astype(int)\n",
        "\n",
        "for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna('unknown')\n",
        "\n",
        "\n",
        "print(\"Identified Categorical Features:\")\n",
        "print(categorical_features)\n",
        "\n",
        "print('\\nFirst 5 rows of training_data_ranking after NaN handling for categoricals:')\n",
        "print(training_data_ranking.head())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Identifying Categorical Features for Ranking Model ---\n",
            "Identified Categorical Features:\n",
            "['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item', 'day_of_week', 'hour_of_day']\n",
            "\n",
            "First 5 rows of training_data_ranking after NaN handling for categoricals:\n",
            "   student_id  item_id interaction_type                     timestamp  target  \\\n",
            "0          51       46             view 2023-07-13 06:09:32.767797153       1   \n",
            "1          36       11          discuss 2023-05-10 09:07:42.207314111       1   \n",
            "2          62       44             view 2023-03-01 21:33:32.801426250       1   \n",
            "3          66       46             view 2023-02-15 06:52:48.555622779       1   \n",
            "4          58        8          unknown                           NaT       0   \n",
            "\n",
            "   total_interactions_user  unique_items_interacted  \\\n",
            "0                        9                        8   \n",
            "1                       13                       12   \n",
            "2                       10                       10   \n",
            "3                       14                       13   \n",
            "4                       13                       10   \n",
            "\n",
            "  most_frequent_interaction_type_user  total_interactions_item  \\\n",
            "0                                view                       14   \n",
            "1                            complete                       19   \n",
            "2                             discuss                       18   \n",
            "3                              enroll                       14   \n",
            "4                                view                       27   \n",
            "\n",
            "   unique_students_interacted most_frequent_interaction_type_item  \\\n",
            "0                          13                                view   \n",
            "1                          16                                view   \n",
            "2                          16                              enroll   \n",
            "3                          13                                view   \n",
            "4                          24                                view   \n",
            "\n",
            "   day_of_week  hour_of_day  \n",
            "0            3            6  \n",
            "1            2            9  \n",
            "2            2           21  \n",
            "3            2            6  \n",
            "4           -1           -1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79050e90"
      },
      "source": [
        "**Reasoning**:\n",
        "I have identified the categorical features and handled NaN values. Now I will convert these categorical features into numerical representations using one-hot encoding, as required by the sixth instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4012e0d",
        "outputId": "9fc7aed2-b8cf-4a6a-c6ce-2a888ab0bbd8"
      },
      "source": [
        "print('\\n--- Converting Categorical Features to Numerical using One-Hot Encoding ---\\n')\n",
        "\n",
        "# Perform one-hot encoding for the identified categorical features\n",
        "training_data_ranking_encoded = pd.get_dummies(training_data_ranking, columns=categorical_features, dummy_na=False)\n",
        "\n",
        "# Drop the original 'timestamp' column as its temporal information has been extracted and encoded\n",
        "# The 'interaction_type' (original) is now replaced by one-hot encoded columns.\n",
        "# student_id and item_id will be used as identifiers/keys, not features for the model directly in some setups,\n",
        "# but often they are used after embedding or treated as categorical if the model supports it.\n",
        "# For LightGBM, we typically keep them or map them to numerical IDs.\n",
        "\n",
        "# Dropping columns that are not directly features for the ranking model, or already processed\n",
        "columns_to_drop = ['timestamp']\n",
        "\n",
        "training_data_ranking_encoded = training_data_ranking_encoded.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "print('First 5 rows of Encoded Ranking Training Data:')\n",
        "print(training_data_ranking_encoded.head())\n",
        "print(f\"\\nShape of Encoded Ranking Training Data: {training_data_ranking_encoded.shape}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Converting Categorical Features to Numerical using One-Hot Encoding ---\n",
            "\n",
            "First 5 rows of Encoded Ranking Training Data:\n",
            "   student_id  item_id  target  total_interactions_user  \\\n",
            "0          51       46       1                        9   \n",
            "1          36       11       1                       13   \n",
            "2          62       44       1                       10   \n",
            "3          66       46       1                       14   \n",
            "4          58        8       0                       13   \n",
            "\n",
            "   unique_items_interacted  total_interactions_item  \\\n",
            "0                        8                       14   \n",
            "1                       12                       19   \n",
            "2                       10                       18   \n",
            "3                       13                       14   \n",
            "4                       10                       27   \n",
            "\n",
            "   unique_students_interacted  interaction_type_complete  \\\n",
            "0                          13                      False   \n",
            "1                          16                      False   \n",
            "2                          16                      False   \n",
            "3                          13                      False   \n",
            "4                          24                      False   \n",
            "\n",
            "   interaction_type_discuss  interaction_type_enroll  ...  hour_of_day_14  \\\n",
            "0                     False                    False  ...           False   \n",
            "1                      True                    False  ...           False   \n",
            "2                     False                    False  ...           False   \n",
            "3                     False                    False  ...           False   \n",
            "4                     False                    False  ...           False   \n",
            "\n",
            "   hour_of_day_15  hour_of_day_16  hour_of_day_17  hour_of_day_18  \\\n",
            "0           False           False           False           False   \n",
            "1           False           False           False           False   \n",
            "2           False           False           False           False   \n",
            "3           False           False           False           False   \n",
            "4           False           False           False           False   \n",
            "\n",
            "   hour_of_day_19  hour_of_day_20  hour_of_day_21  hour_of_day_22  \\\n",
            "0           False           False           False           False   \n",
            "1           False           False           False           False   \n",
            "2           False           False            True           False   \n",
            "3           False           False           False           False   \n",
            "4           False           False           False           False   \n",
            "\n",
            "   hour_of_day_23  \n",
            "0           False  \n",
            "1           False  \n",
            "2           False  \n",
            "3           False  \n",
            "4           False  \n",
            "\n",
            "[5 rows x 56 columns]\n",
            "\n",
            "Shape of Encoded Ranking Training Data: (1600, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f4900f5"
      },
      "source": [
        "**Reasoning**:\n",
        "I will split the `training_data_ranking_encoded` DataFrame into features (X) by dropping the `target`, `student_id`, and `item_id` columns, and assign the `target` column to the labels (y), as required by the seventh instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7317c994",
        "outputId": "54cdfaa0-38ab-4928-87dc-09382aa2f562"
      },
      "source": [
        "print('--- Splitting Training Data into Features (X) and Target (y) ---')\n",
        "\n",
        "# 7. Split the ranking model's training data into features (X) and target (y).\n",
        "# Features (X) will be all columns except 'target', 'student_id', and 'item_id'.\n",
        "# The target (y) is the 'target' column.\n",
        "\n",
        "X = training_data_ranking_encoded.drop(columns=['target', 'student_id', 'item_id'], errors='ignore')\n",
        "y = training_data_ranking_encoded['target']\n",
        "\n",
        "print(f\"Shape of X (features): {X.shape}\")\n",
        "print(f\"Shape of y (target): {y.shape}\")\n",
        "\n",
        "print('\\nFirst 5 rows of X (features):')\n",
        "print(X.head())\n",
        "print('\\nFirst 5 rows of y (target):')\n",
        "print(y.head())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Splitting Training Data into Features (X) and Target (y) ---\n",
            "Shape of X (features): (1600, 53)\n",
            "Shape of y (target): (1600,)\n",
            "\n",
            "First 5 rows of X (features):\n",
            "   total_interactions_user  unique_items_interacted  total_interactions_item  \\\n",
            "0                        9                        8                       14   \n",
            "1                       13                       12                       19   \n",
            "2                       10                       10                       18   \n",
            "3                       14                       13                       14   \n",
            "4                       13                       10                       27   \n",
            "\n",
            "   unique_students_interacted  interaction_type_complete  \\\n",
            "0                          13                      False   \n",
            "1                          16                      False   \n",
            "2                          16                      False   \n",
            "3                          13                      False   \n",
            "4                          24                      False   \n",
            "\n",
            "   interaction_type_discuss  interaction_type_enroll  \\\n",
            "0                     False                    False   \n",
            "1                      True                    False   \n",
            "2                     False                    False   \n",
            "3                     False                    False   \n",
            "4                     False                    False   \n",
            "\n",
            "   interaction_type_quiz_attempt  interaction_type_unknown  \\\n",
            "0                          False                     False   \n",
            "1                          False                     False   \n",
            "2                          False                     False   \n",
            "3                          False                     False   \n",
            "4                          False                      True   \n",
            "\n",
            "   interaction_type_view  ...  hour_of_day_14  hour_of_day_15  hour_of_day_16  \\\n",
            "0                   True  ...           False           False           False   \n",
            "1                  False  ...           False           False           False   \n",
            "2                   True  ...           False           False           False   \n",
            "3                   True  ...           False           False           False   \n",
            "4                  False  ...           False           False           False   \n",
            "\n",
            "   hour_of_day_17  hour_of_day_18  hour_of_day_19  hour_of_day_20  \\\n",
            "0           False           False           False           False   \n",
            "1           False           False           False           False   \n",
            "2           False           False           False           False   \n",
            "3           False           False           False           False   \n",
            "4           False           False           False           False   \n",
            "\n",
            "   hour_of_day_21  hour_of_day_22  hour_of_day_23  \n",
            "0           False           False           False  \n",
            "1           False           False           False  \n",
            "2            True           False           False  \n",
            "3           False           False           False  \n",
            "4           False           False           False  \n",
            "\n",
            "[5 rows x 53 columns]\n",
            "\n",
            "First 5 rows of y (target):\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: target, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a9c7db2"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to a `SyntaxError: unterminated string literal` in the print statement. I will correct this by ensuring the string literal is properly closed on a single line.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "383135af",
        "outputId": "94662f8c-d1d1-4dae-abd1-149dbec06656"
      },
      "source": [
        "print('--- Splitting Training Data into Features (X) and Target (y) ---')\n",
        "\n",
        "# 7. Split the ranking model's training data into features (X) and target (y).\n",
        "# Features (X) will be all columns except 'target', 'student_id', and 'item_id'.\n",
        "# The target (y) is the 'target' column.\n",
        "\n",
        "X = training_data_ranking_encoded.drop(columns=['target', 'student_id', 'item_id'], errors='ignore')\n",
        "y = training_data_ranking_encoded['target']\n",
        "\n",
        "print(f\"Shape of X (features): {X.shape}\")\n",
        "print(f\"Shape of y (target): {y.shape}\")\n",
        "\n",
        "print('\\nFirst 5 rows of X (features):')\n",
        "print(X.head())\n",
        "print('\\nFirst 5 rows of y (target):')\n",
        "print(y.head())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Splitting Training Data into Features (X) and Target (y) ---\n",
            "Shape of X (features): (1600, 53)\n",
            "Shape of y (target): (1600,)\n",
            "\n",
            "First 5 rows of X (features):\n",
            "   total_interactions_user  unique_items_interacted  total_interactions_item  \\\n",
            "0                        9                        8                       14   \n",
            "1                       13                       12                       19   \n",
            "2                       10                       10                       18   \n",
            "3                       14                       13                       14   \n",
            "4                       13                       10                       27   \n",
            "\n",
            "   unique_students_interacted  interaction_type_complete  \\\n",
            "0                          13                      False   \n",
            "1                          16                      False   \n",
            "2                          16                      False   \n",
            "3                          13                      False   \n",
            "4                          24                      False   \n",
            "\n",
            "   interaction_type_discuss  interaction_type_enroll  \\\n",
            "0                     False                    False   \n",
            "1                      True                    False   \n",
            "2                     False                    False   \n",
            "3                     False                    False   \n",
            "4                     False                    False   \n",
            "\n",
            "   interaction_type_quiz_attempt  interaction_type_unknown  \\\n",
            "0                          False                     False   \n",
            "1                          False                     False   \n",
            "2                          False                     False   \n",
            "3                          False                     False   \n",
            "4                          False                      True   \n",
            "\n",
            "   interaction_type_view  ...  hour_of_day_14  hour_of_day_15  hour_of_day_16  \\\n",
            "0                   True  ...           False           False           False   \n",
            "1                  False  ...           False           False           False   \n",
            "2                   True  ...           False           False           False   \n",
            "3                   True  ...           False           False           False   \n",
            "4                  False  ...           False           False           False   \n",
            "\n",
            "   hour_of_day_17  hour_of_day_18  hour_of_day_19  hour_of_day_20  \\\n",
            "0           False           False           False           False   \n",
            "1           False           False           False           False   \n",
            "2           False           False           False           False   \n",
            "3           False           False           False           False   \n",
            "4           False           False           False           False   \n",
            "\n",
            "   hour_of_day_21  hour_of_day_22  hour_of_day_23  \n",
            "0           False           False           False  \n",
            "1           False           False           False  \n",
            "2            True           False           False  \n",
            "3           False           False           False  \n",
            "4           False           False           False  \n",
            "\n",
            "[5 rows x 53 columns]\n",
            "\n",
            "First 5 rows of y (target):\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: target, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03fe31b3"
      },
      "source": [
        "**Reasoning**:\n",
        "I will import the `LGBMClassifier` from `lightgbm` and then initialize and train it on the prepared feature matrix `X` and target vector `y`, as required by the eighth instruction of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b166493b",
        "outputId": "409ea05b-f486-4bae-a0bf-6d30468ac2e1"
      },
      "source": [
        "print('\\n--- Training LightGBM Ranking Model ---\\n')\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "# 8. Train a LightGBM Classifier model (LGBMClassifier)\n",
        "# Initialize the LGBMClassifier\n",
        "# For simplicity, we'll use default parameters for now.\n",
        "ranking_model = lgb.LGBMClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "ranking_model.fit(X, y)\n",
        "\n",
        "print('LightGBM Ranking Model trained successfully.')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training LightGBM Ranking Model ---\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 800, number of negative: 800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 159\n",
            "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 53\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM Ranking Model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2d9c5c0"
      },
      "source": [
        "## Model Evaluation\n",
        "\n",
        "### Subtask:\n",
        "Evaluate all implemented models using ranking metrics such as Precision@K, Recall@K, NDCG@K, and MRR. Also, perform coverage, novelty, and cold-start analysis, followed by error analysis with qualitative examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bfd213b"
      },
      "source": [
        "**Reasoning**:\n",
        "I will initialize empty lists to store the Precision@K and Recall@K scores specifically for the Hybrid Recommendation Model, as this is the first step in evaluating this model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfe39571",
        "outputId": "6c44a601-74d6-44b6-8174-2e8ef4b39962"
      },
      "source": [
        "print('\\n--- Initializing lists for Hybrid Recommendation Model evaluation metrics ---\\n')\n",
        "\n",
        "hybrid_precision_scores = []\n",
        "hybrid_recall_scores = []\n",
        "\n",
        "print('Hybrid Model evaluation metric lists initialized.')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initializing lists for Hybrid Recommendation Model evaluation metrics ---\n",
            "\n",
            "Hybrid Model evaluation metric lists initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c489551"
      },
      "source": [
        "**Reasoning**:\n",
        "I will iterate through each unique student in the `test_df`, generate candidate items using the SVD model, create feature vectors for these candidates by merging user and item features, handle categorical features using one-hot encoding consistent with the training of the ranking model, use the `ranking_model` to predict interaction likelihoods, rank the candidates, and then calculate Precision@K and Recall@K for the Hybrid Recommendation Model. Finally, I will store these scores in the previously initialized lists.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "cc2afcb7",
        "outputId": "cd7a287c-7f61-4302-8c6a-15ee40ab94e6"
      },
      "source": [
        "print('\\n--- Evaluating Hybrid Recommendation Model ---\\n')\n",
        "\n",
        "# Ensure K is defined (from previous evaluation step)\n",
        "K = 10\n",
        "\n",
        "# Get all unique student_ids from the test set\n",
        "unique_test_students = test_df['student_id'].unique()\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students)} unique students in the test set with K={K} for Hybrid Model.\")\n",
        "\n",
        "# Prepare a consistent set of features for prediction\n",
        "# This needs to include all feature columns that the ranking model was trained on, including one-hot encoded ones.\n",
        "# The 'student_id' and 'item_id' are kept for merging, but dropped before prediction.\n",
        "\n",
        "# Get the feature columns that the ranking model was trained on\n",
        "# X was defined as training_data_ranking_encoded.drop(columns=['target', 'student_id', 'item_id'])\n",
        "ranking_model_features = X.columns.tolist()\n",
        "\n",
        "for student_id in unique_test_students:\n",
        "    # 3. Get historical and actual interactions\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    # Only evaluate if the student has actual interactions in the test set\n",
        "    if len(actual_interactions) > 0:\n",
        "        # 4. Generate candidate items using the SVD model\n",
        "        candidates = generate_candidates_for_user(student_id, algo, n_candidates=50, historical_interactions=historical_interactions, all_item_ids=synthetic_df['item_id'].unique())\n",
        "\n",
        "        if not candidates: # Skip if no candidates are generated\n",
        "            continue\n",
        "\n",
        "        # 5. Create feature vectors for candidate items\n",
        "        candidate_data = []\n",
        "        for item_id in candidates:\n",
        "            # Get user features for the current student\n",
        "            user_feat = user_interactions[user_interactions['student_id'] == student_id].iloc[0]\n",
        "\n",
        "            # Get item features for the current candidate item\n",
        "            item_feat = item_interactions[item_interactions['item_id'] == item_id].iloc[0]\n",
        "\n",
        "            # Combine features\n",
        "            # For temporal features, we'll use a representative value from the test_df for this student\n",
        "            # This is a simplification; a more robust approach might be to predict for typical interaction times.\n",
        "            # For now, let's take the first interaction's day_of_week and hour_of_day from test_df for this student.\n",
        "            # If student has no test interactions, we'll use defaults.\n",
        "            student_test_interactions = test_df[test_df['student_id'] == student_id]\n",
        "            if not student_test_interactions.empty:\n",
        "                representative_day_of_week = student_test_interactions['day_of_week'].iloc[0]\n",
        "                representative_hour_of_day = student_test_interactions['hour_of_day'].iloc[0]\n",
        "            else: # Fallback if no test interactions (though we filter for actual_interactions > 0, which means there are some)\n",
        "                representative_day_of_week = -1 # Matches NaN handling in training\n",
        "                representative_hour_of_day = -1 # Matches NaN handling in training\n",
        "\n",
        "            # Also, we need interaction_type. For candidates, this is unknown, so we use 'unknown'\n",
        "            # or a sensible default/average if the model requires it.\n",
        "            # For simplicity, we'll assume 'unknown' for candidates' interaction_type for prediction.\n",
        "            # And for most_frequent_interaction_type_user/item, we use the pre-calculated ones.\n",
        "\n",
        "            temp_data = {\n",
        "                'student_id': student_id,\n",
        "                'item_id': item_id,\n",
        "                'interaction_type': 'unknown', # Default for new predictions\n",
        "                'day_of_week': representative_day_of_week,\n",
        "                'hour_of_day': representative_hour_of_day,\n",
        "            }\n",
        "            temp_data.update(user_feat.drop('student_id').to_dict())\n",
        "            temp_data.update(item_feat.drop('item_id').to_dict())\n",
        "            candidate_data.append(temp_data)\n",
        "\n",
        "        candidate_df = pd.DataFrame(candidate_data)\n",
        "\n",
        "        # Handle categorical features and one-hot encode them consistently with training\n",
        "        # Ensure the same categorical features are used and NaN handling applied\n",
        "        for col in ['day_of_week', 'hour_of_day']:\n",
        "            if col in candidate_df.columns:\n",
        "                candidate_df[col] = candidate_df[col].fillna(-1).astype(int)\n",
        "\n",
        "        for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "            if col in candidate_df.columns:\n",
        "                candidate_df[col] = candidate_df[col].fillna('unknown')\n",
        "\n",
        "        # One-hot encode candidate_df, ensuring all training columns are present\n",
        "        # This is critical to avoid 'feature mismatch' during prediction\n",
        "        candidate_df_encoded = pd.get_dummies(candidate_df, columns=categorical_features, dummy_na=False)\n",
        "\n",
        "        # Align columns with the training data's X\n",
        "        # Add missing columns (if any) and fill with 0\n",
        "        missing_cols = set(ranking_model_features) - set(candidate_df_encoded.columns)\n",
        "        for c in missing_cols:\n",
        "            candidate_df_encoded[c] = False # Use False for boolean dtype from get_dummies\n",
        "        # Drop columns not in the training data's X\n",
        "        extra_cols = set(candidate_df_encoded.columns) - set(ranking_model_features)\n",
        "        candidate_df_encoded = candidate_df_encoded.drop(columns=list(extra_cols))\n",
        "\n",
        "        # Ensure the order of columns is the same\n",
        "        candidate_features_for_prediction = candidate_df_encoded[ranking_model_features]\n",
        "\n",
        "        # 6. Predict the likelihood of interaction for each candidate item\n",
        "        predictions = ranking_model.predict_proba(candidate_features_for_prediction)[:, 1] # Get probability of positive interaction\n",
        "\n",
        "        # 7. Rank candidates based on predicted likelihoods\n",
        "        ranked_candidates = pd.DataFrame({\n",
        "            'item_id': candidate_df['item_id'],\n",
        "            'predicted_score': predictions\n",
        "        })\n",
        "        ranked_candidates = ranked_candidates.sort_values(by='predicted_score', ascending=False)\n",
        "        hybrid_recs = ranked_candidates.head(K)['item_id'].tolist()\n",
        "\n",
        "        # 8. Calculate Precision@K and Recall@K\n",
        "        hybrid_precision = precision_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_recall = recall_at_k(hybrid_recs, actual_interactions, K)\n",
        "\n",
        "        # 9. Append scores to respective lists\n",
        "        hybrid_precision_scores.append(hybrid_precision)\n",
        "        hybrid_recall_scores.append(hybrid_recall)\n",
        "\n",
        "print('Hybrid Model recommendation generation and metric calculation complete for all eligible students.')\n",
        "\n",
        "# 10. Calculate and print the average Precision@K and Recall@K for the Hybrid Recommendation Model.\n",
        "print('\\n--- Average Evaluation Metrics for Hybrid Model ---\\n')\n",
        "\n",
        "if hybrid_precision_scores:\n",
        "    print(f\"Hybrid Model - Average Precision@{K}: {np.mean(hybrid_precision_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Average Recall@{K}: {np.mean(hybrid_recall_scores):.4f}\")\n",
        "else:\n",
        "    print(\"No scores calculated for Hybrid Model.\")\n",
        "\n",
        "# 11. Compare these average metrics with the baseline models.\n",
        "print('\\n--- Comparison with Baseline Models ---\\n')\n",
        "\n",
        "if most_popular_precision_scores:\n",
        "    print(f\"Most Popular Model - Average Precision@{K}: {np.mean(most_popular_precision_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Average Recall@{K}: {np.mean(most_popular_recall_scores):.4f}\")\n",
        "if cf_precision_scores:\n",
        "    print(f\"Collaborative Filtering Model - Average Precision@{K}: {np.mean(cf_precision_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Average Recall@{K}: {np.mean(cf_recall_scores):.4f}\")\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Hybrid Recommendation Model ---\n",
            "\n",
            "Starting evaluation for 64 unique students in the test set with K=10 for Hybrid Model.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'day_of_week'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'day_of_week'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2294531834.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mstudent_test_interactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'student_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstudent_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstudent_test_interactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mrepresentative_day_of_week\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_test_interactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day_of_week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mrepresentative_hour_of_day\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_test_interactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hour_of_day'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Fallback if no test interactions (though we filter for actual_interactions > 0, which means there are some)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'day_of_week'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e676794c"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError` indicates that `test_df` and other critical variables were not defined in the current execution environment, likely due to previous installation issues or kernel state resets. I will consolidate all necessary preceding code blocks to re-initialize the synthetic data, perform the temporal split, re-engineer features, re-initialize and train the SVD model, prepare the ranking model's training data, train the ranking model, and re-define all evaluation functions and lists. Finally, I will execute the hybrid model evaluation loop within this single, comprehensive code block to ensure all dependencies are met.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abd19325",
        "outputId": "ee716402-69b5-4d70-fecc-98c471fee5fb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Reader, Dataset, SVD\n",
        "import lightgbm as lgb\n",
        "\n",
        "print('--- Re-generating Synthetic Dataset and Temporal Split ---\\n')\n",
        "\n",
        "# 1. Re-generate Synthetic Dataset (from original cell cd481695)\n",
        "num_students = 100\n",
        "num_items = 50\n",
        "num_interactions = 1000\n",
        "\n",
        "student_ids = np.random.randint(1, num_students + 1, num_interactions)\n",
        "item_ids = np.random.randint(1, num_items + 1, num_interactions)\n",
        "interaction_types = np.random.choice(['view', 'complete', 'enroll', 'quiz_attempt', 'discuss'], num_interactions)\n",
        "\n",
        "start_date = pd.to_datetime('2023-01-01')\n",
        "end_date = pd.to_datetime('2023-12-31')\n",
        "time_range = (end_date - start_date).total_seconds()\n",
        "timestamps = start_date + pd.to_timedelta(np.random.rand(num_interactions) * time_range, unit='s')\n",
        "\n",
        "synthetic_df = pd.DataFrame({\n",
        "    'student_id': student_ids,\n",
        "    'item_id': item_ids,\n",
        "    'interaction_type': interaction_types,\n",
        "    'timestamp': timestamps\n",
        "})\n",
        "\n",
        "synthetic_df = synthetic_df.sort_values(by='timestamp').reset_index(drop=True)\n",
        "print('Synthetic DataFrame regenerated. First 5 rows:')\n",
        "print(synthetic_df.head())\n",
        "\n",
        "\n",
        "print('\\n--- Temporal Train/Validation/Test Split ---\\n')\n",
        "\n",
        "# 2. Perform Temporal Train/Validation/Test Split\n",
        "total_interactions = len(synthetic_df)\n",
        "train_size = int(0.8 * total_interactions)\n",
        "val_size = int(0.1 * total_interactions)\n",
        "test_size = total_interactions - train_size - val_size\n",
        "\n",
        "train_df = synthetic_df.iloc[:train_size]\n",
        "val_df = synthetic_df.iloc[train_size : train_size + val_size]\n",
        "test_df = synthetic_df.iloc[train_size + val_size :]\n",
        "\n",
        "print(f\"Train set interactions: {len(train_df)}\")\n",
        "print(f\"Validation set interactions: {len(val_df)}\")\n",
        "print(f\"Test set interactions: {len(test_df)}\")\n",
        "\n",
        "print('\\n--- Re-calculating Features ---\\n')\n",
        "\n",
        "# Recalculate User Features from train_df (from cell 757f4caf)\n",
        "user_interactions = train_df.groupby('student_id').agg(\n",
        "    total_interactions_user=('item_id', 'count'),\n",
        "    unique_items_interacted=('item_id', 'nunique'),\n",
        "    most_frequent_interaction_type_user=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Recalculate Item Features from train_df (from cell 757f4caf)\n",
        "item_interactions = train_df.groupby('item_id').agg(\n",
        "    total_interactions_item=('student_id', 'count'),\n",
        "    unique_students_interacted=('student_id', 'nunique'),\n",
        "    most_frequent_interaction_type_item=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Re-extract temporal features for train_df, val_df, test_df\n",
        "for df_name in ['train_df', 'val_df', 'test_df']:\n",
        "    df = globals()[df_name]\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "    globals()[df_name] = df # Update the global dataframe\n",
        "\n",
        "print('User and Item features recalculated, and temporal features extracted.')\n",
        "\n",
        "print('\\n--- Initializing surprise.Reader and loading data ---\\n')\n",
        "\n",
        "# Create a surprise.Reader object\n",
        "reader = Reader(rating_scale=(1, 1))\n",
        "\n",
        "# Prepare the data for Surprise library\n",
        "train_df_surprise = train_df[['student_id', 'item_id']].copy()\n",
        "train_df_surprise['dummy_rating'] = 1\n",
        "\n",
        "# Load the train_df into a surprise.Dataset\n",
        "data = Dataset.load_from_df(train_df_surprise[['student_id', 'item_id', 'dummy_rating']], reader)\n",
        "\n",
        "# Build a trainset from the loaded Dataset\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "print('\\n`surprise.Reader` object created and trainset built.')\n",
        "print(f\"Number of users in trainset: {trainset.n_users}\")\n",
        "print(f\"Number of items in trainset: {trainset.n_items}\")\n",
        "print(f\"Number of interactions in trainset: {trainset.n_ratings}\")\n",
        "\n",
        "print('\\n--- Training Collaborative Filtering Model (SVD) ---\\n')\n",
        "\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "print('SVD model trained successfully.')\n",
        "\n",
        "print('\\n--- Re-defining Recommendation Functions and Evaluation Metrics ---\\n')\n",
        "\n",
        "# Re-calculate item_popularity (from cell 12886fec)\n",
        "item_popularity = train_df['item_id'].value_counts().reset_index()\n",
        "item_popularity.columns = ['item_id', 'popularity_score']\n",
        "\n",
        "# Re-define get_most_popular_recommendations function (from cell 037917a8)\n",
        "def get_most_popular_recommendations(student_id, n, historical_interactions=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "\n",
        "    recommended_items = item_popularity[~item_popularity['item_id'].isin(historical_interactions)]\n",
        "    recommended_items = recommended_items.sort_values(by='popularity_score', ascending=False)\n",
        "\n",
        "    return recommended_items.head(n)['item_id'].tolist()\n",
        "\n",
        "# Re-define get_cf_recommendations function (from cell c24f0ef6)\n",
        "def get_cf_recommendations(student_id, n, historical_interactions, model, trainset):\n",
        "    all_item_ids = synthetic_df['item_id'].unique()\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n]]\n",
        "    return top_n_items\n",
        "\n",
        "# Re-define get_actual_interactions(student_id, df)\n",
        "def get_actual_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define get_historical_interactions(student_id, df)\n",
        "def get_historical_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define precision_at_k(recommended_items, actual_items, k)\n",
        "def precision_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / k\n",
        "\n",
        "# Re-define recall_at_k(recommended_items, actual_items, k)\n",
        "def recall_at_k(recommended_items, actual_items, k):\n",
        "    if len(actual_items) == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / len(actual_items)\n",
        "\n",
        "# Re-initialize lists for baseline evaluation metrics (from cell 71ff55e2)\n",
        "most_popular_precision_scores = []\n",
        "most_popular_recall_scores = []\n",
        "cf_precision_scores = []\n",
        "cf_recall_scores = []\n",
        "\n",
        "# Set the value for K for Precision@K and Recall@K\n",
        "K = 10\n",
        "\n",
        "# Get all unique student_ids from the test set for baseline evaluation\n",
        "unique_test_students_baseline = test_df['student_id'].unique()\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students_baseline)} unique students in the test set with K={K} for Baseline Models.\")\n",
        "\n",
        "for student_id in unique_test_students_baseline:\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    if len(actual_interactions) > 0:\n",
        "        most_popular_recs = get_most_popular_recommendations(student_id, K, historical_interactions)\n",
        "        cf_recs = get_cf_recommendations(student_id, K, historical_interactions, algo, trainset)\n",
        "\n",
        "        mp_precision = precision_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_recall = recall_at_k(most_popular_recs, actual_interactions, K)\n",
        "\n",
        "        cf_precision = precision_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_recall = recall_at_k(cf_recs, actual_interactions, K)\n",
        "\n",
        "        most_popular_precision_scores.append(mp_precision)\n",
        "        most_popular_recall_scores.append(mp_recall)\n",
        "        cf_precision_scores.append(cf_precision)\n",
        "        cf_recall_scores.append(cf_recall)\n",
        "\n",
        "print('Baseline Recommendation generation and metric calculation complete.')\n",
        "\n",
        "print('\\n--- Preparing Ranking Model Training Data ---\\n')\n",
        "\n",
        "# Prepare positive samples (from cell ee0afb00)\n",
        "positive_samples_df = train_df.copy()\n",
        "positive_samples_df['target'] = 1\n",
        "positive_samples_df = pd.merge(positive_samples_df, user_interactions, on='student_id', how='left')\n",
        "positive_samples_df = pd.merge(positive_samples_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# Generate negative samples (from cell 9b44e5af)\n",
        "negative_samples_list = []\n",
        "all_item_ids = synthetic_df['item_id'].unique()\n",
        "\n",
        "for student_id in train_df['student_id'].unique():\n",
        "    interacted_items = set(train_df[train_df['student_id'] == student_id]['item_id'].unique())\n",
        "    non_interacted_items = [item_id for item_id in all_item_ids if item_id not in interacted_items]\n",
        "    num_positive_interactions = len(train_df[train_df['student_id'] == student_id])\n",
        "    num_negative_samples_to_generate = min(num_positive_interactions, len(non_interacted_items))\n",
        "\n",
        "    if num_negative_samples_to_generate > 0:\n",
        "        sampled_negative_items = np.random.choice(non_interacted_items, num_negative_samples_to_generate, replace=False)\n",
        "        for item_id in sampled_negative_items:\n",
        "            negative_samples_list.append({\n",
        "                'student_id': student_id,\n",
        "                'item_id': item_id,\n",
        "                'target': 0\n",
        "            })\n",
        "\n",
        "negative_samples_df = pd.DataFrame(negative_samples_list)\n",
        "negative_samples_df = pd.merge(negative_samples_df, user_interactions, on='student_id', how='left')\n",
        "negative_samples_df = pd.merge(negative_samples_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# Combine positive and negative samples (from cell 4b1b4b12)\n",
        "training_data_ranking = pd.concat([positive_samples_df, negative_samples_df], ignore_index=True)\n",
        "training_data_ranking = training_data_ranking.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Identify and handle categorical features for ranking model (from cell 93c873ad)\n",
        "categorical_features = [\n",
        "    'interaction_type',\n",
        "    'most_frequent_interaction_type_user',\n",
        "    'most_frequent_interaction_type_item',\n",
        "    'day_of_week',\n",
        "    'hour_of_day'\n",
        "]\n",
        "categorical_features = [col for col in categorical_features if col in training_data_ranking.columns]\n",
        "\n",
        "for col in ['day_of_week', 'hour_of_day']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna(-1).astype(int)\n",
        "\n",
        "for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna('unknown')\n",
        "\n",
        "# Convert Categorical Features to Numerical using One-Hot Encoding (from cell d4012e0d)\n",
        "training_data_ranking_encoded = pd.get_dummies(training_data_ranking, columns=categorical_features, dummy_na=False)\n",
        "columns_to_drop = ['timestamp']\n",
        "training_data_ranking_encoded = training_data_ranking_encoded.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Split Training Data into Features (X) and Target (y) (from cell 383135af)\n",
        "X = training_data_ranking_encoded.drop(columns=['target', 'student_id', 'item_id'], errors='ignore')\n",
        "y = training_data_ranking_encoded['target']\n",
        "\n",
        "print('Ranking model training data prepared.')\n",
        "\n",
        "print('\\n--- Training LightGBM Ranking Model ---\\n')\n",
        "\n",
        "# Train a LightGBM Classifier model (LGBMClassifier) (from cell b166493b)\n",
        "ranking_model = lgb.LGBMClassifier(random_state=42)\n",
        "ranking_model.fit(X, y)\n",
        "\n",
        "print('LightGBM Ranking Model trained successfully.')\n",
        "\n",
        "# 1. Initialize lists to store Precision@K and Recall@K scores for the Hybrid Recommendation Model.\n",
        "hybrid_precision_scores = []\n",
        "hybrid_recall_scores = []\n",
        "\n",
        "print('\\n--- Evaluating Hybrid Recommendation Model ---\\n')\n",
        "\n",
        "# Get all unique student_ids from the test set\n",
        "unique_test_students = test_df['student_id'].unique()\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students)} unique students in the test set with K={K} for Hybrid Model.\")\n",
        "\n",
        "# Get the feature columns that the ranking model was trained on\n",
        "ranking_model_features = X.columns.tolist()\n",
        "\n",
        "# Re-define candidate generation function to use updated global synthetic_df\n",
        "def generate_candidates_for_user(student_id, model, n_candidates=50, historical_interactions=None, all_item_ids=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "    if all_item_ids is None:\n",
        "        all_item_ids = synthetic_df['item_id'].unique() # Ensure synthetic_df is available globally\n",
        "\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n_candidates]]\n",
        "    return top_n_items\n",
        "\n",
        "\n",
        "for student_id in unique_test_students:\n",
        "    # 3. Get historical and actual interactions\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    # Only evaluate if the student has actual interactions in the test set\n",
        "    if len(actual_interactions) > 0:\n",
        "        # 4. Generate candidate items using the SVD model\n",
        "        candidates = generate_candidates_for_user(student_id, algo, n_candidates=50, historical_interactions=historical_interactions, all_item_ids=synthetic_df['item_id'].unique())\n",
        "\n",
        "        if not candidates: # Skip if no candidates are generated\n",
        "            continue\n",
        "\n",
        "        # 5. Create feature vectors for candidate items\n",
        "        candidate_data = []\n",
        "        for item_id in candidates:\n",
        "            # Get user features for the current student\n",
        "            user_feat = user_interactions[user_interactions['student_id'] == student_id]\n",
        "            if user_feat.empty:\n",
        "                continue # Skip if no user features found for this student\n",
        "            user_feat = user_feat.iloc[0]\n",
        "\n",
        "            # Get item features for the current candidate item\n",
        "            item_feat = item_interactions[item_interactions['item_id'] == item_id]\n",
        "            if item_feat.empty:\n",
        "                continue # Skip if no item features found for this item\n",
        "            item_feat = item_feat.iloc[0]\n",
        "\n",
        "            # Combine features\n",
        "            student_test_interactions = test_df[test_df['student_id'] == student_id]\n",
        "            if not student_test_interactions.empty:\n",
        "                representative_day_of_week = student_test_interactions['day_of_week'].iloc[0]\n",
        "                representative_hour_of_day = student_test_interactions['hour_of_day'].iloc[0]\n",
        "            else:\n",
        "                representative_day_of_week = -1\n",
        "                representative_hour_of_day = -1\n",
        "\n",
        "            temp_data = {\n",
        "                'student_id': student_id,\n",
        "                'item_id': item_id,\n",
        "                'interaction_type': 'unknown',\n",
        "                'day_of_week': representative_day_of_week,\n",
        "                'hour_of_day': representative_hour_of_day,\n",
        "            }\n",
        "            temp_data.update(user_feat.drop('student_id').to_dict())\n",
        "            temp_data.update(item_feat.drop('item_id').to_dict())\n",
        "            candidate_data.append(temp_data)\n",
        "\n",
        "        if not candidate_data: # If no valid candidate data generated\n",
        "            continue\n",
        "\n",
        "        candidate_df = pd.DataFrame(candidate_data)\n",
        "\n",
        "        for col in ['day_of_week', 'hour_of_day']:\n",
        "            if col in candidate_df.columns:\n",
        "                candidate_df[col] = candidate_df[col].fillna(-1).astype(int)\n",
        "\n",
        "        for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "            if col in candidate_df.columns:\n",
        "                candidate_df[col] = candidate_df[col].fillna('unknown')\n",
        "\n",
        "        # One-hot encode candidate_df, ensuring all training columns are present\n",
        "        candidate_df_encoded = pd.get_dummies(candidate_df, columns=categorical_features, dummy_na=False)\n",
        "\n",
        "        # Align columns with the training data's X\n",
        "        missing_cols = set(ranking_model_features) - set(candidate_df_encoded.columns)\n",
        "        for c in missing_cols:\n",
        "            candidate_df_encoded[c] = False\n",
        "        extra_cols = set(candidate_df_encoded.columns) - set(ranking_model_features)\n",
        "        candidate_df_encoded = candidate_df_encoded.drop(columns=list(extra_cols))\n",
        "\n",
        "        # Ensure the order of columns is the same\n",
        "        candidate_features_for_prediction = candidate_df_encoded[ranking_model_features]\n",
        "\n",
        "        # 6. Predict the likelihood of interaction for each candidate item\n",
        "        predictions = ranking_model.predict_proba(candidate_features_for_prediction)[:, 1]\n",
        "\n",
        "        # 7. Rank candidates based on predicted likelihoods\n",
        "        ranked_candidates = pd.DataFrame({\n",
        "            'item_id': candidate_df['item_id'],\n",
        "            'predicted_score': predictions\n",
        "        })\n",
        "        ranked_candidates = ranked_candidates.sort_values(by='predicted_score', ascending=False)\n",
        "        hybrid_recs = ranked_candidates.head(K)['item_id'].tolist()\n",
        "\n",
        "        # 8. Calculate Precision@K and Recall@K\n",
        "        hybrid_precision = precision_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_recall = recall_at_k(hybrid_recs, actual_interactions, K)\n",
        "\n",
        "        # 9. Append scores to respective lists\n",
        "        hybrid_precision_scores.append(hybrid_precision)\n",
        "        hybrid_recall_scores.append(hybrid_recall)\n",
        "\n",
        "print('Hybrid Model recommendation generation and metric calculation complete for all eligible students.')\n",
        "\n",
        "# 10. Calculate and print the average Precision@K and Recall@K for the Hybrid Recommendation Model.\n",
        "print('\\n--- Average Evaluation Metrics for Hybrid Model ---\\n')\n",
        "\n",
        "if hybrid_precision_scores:\n",
        "    print(f\"Hybrid Model - Average Precision@{K}: {np.mean(hybrid_precision_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Average Recall@{K}: {np.mean(hybrid_recall_scores):.4f}\")\n",
        "else:\n",
        "    print(\"No scores calculated for Hybrid Model.\")\n",
        "\n",
        "# 11. Compare these average metrics with the baseline models.\n",
        "print('\\n--- Comparison with Baseline Models ---\\n')\n",
        "\n",
        "if most_popular_precision_scores:\n",
        "    print(f\"Most Popular Model - Average Precision@{K}: {np.mean(most_popular_precision_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Average Recall@{K}: {np.mean(most_popular_recall_scores):.4f}\")\n",
        "if cf_precision_scores:\n",
        "    print(f\"Collaborative Filtering Model - Average Precision@{K}: {np.mean(cf_precision_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Average Recall@{K}: {np.mean(cf_recall_scores):.4f}\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Re-generating Synthetic Dataset and Temporal Split ---\n",
            "\n",
            "Synthetic DataFrame regenerated. First 5 rows:\n",
            "   student_id  item_id interaction_type                     timestamp\n",
            "0          78       23          discuss 2023-01-01 00:43:51.856294662\n",
            "1          27       18           enroll 2023-01-01 05:31:32.734442374\n",
            "2          60       27     quiz_attempt 2023-01-01 21:17:39.272405017\n",
            "3          32       31         complete 2023-01-02 11:48:48.941400911\n",
            "4          38       50           enroll 2023-01-03 08:10:12.874636444\n",
            "\n",
            "--- Temporal Train/Validation/Test Split ---\n",
            "\n",
            "Train set interactions: 800\n",
            "Validation set interactions: 100\n",
            "Test set interactions: 100\n",
            "\n",
            "--- Re-calculating Features ---\n",
            "\n",
            "User and Item features recalculated, and temporal features extracted.\n",
            "\n",
            "--- Initializing surprise.Reader and loading data ---\n",
            "\n",
            "\n",
            "`surprise.Reader` object created and trainset built.\n",
            "Number of users in trainset: 100\n",
            "Number of items in trainset: 50\n",
            "Number of interactions in trainset: 800\n",
            "\n",
            "--- Training Collaborative Filtering Model (SVD) ---\n",
            "\n",
            "SVD model trained successfully.\n",
            "\n",
            "--- Re-defining Recommendation Functions and Evaluation Metrics ---\n",
            "\n",
            "Starting evaluation for 59 unique students in the test set with K=10 for Baseline Models.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-268911949.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
            "/tmp/ipython-input-268911949.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hour_of_day'] = df['timestamp'].dt.hour\n",
            "/tmp/ipython-input-268911949.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
            "/tmp/ipython-input-268911949.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hour_of_day'] = df['timestamp'].dt.hour\n",
            "/tmp/ipython-input-268911949.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
            "/tmp/ipython-input-268911949.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hour_of_day'] = df['timestamp'].dt.hour\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Recommendation generation and metric calculation complete.\n",
            "\n",
            "--- Preparing Ranking Model Training Data ---\n",
            "\n",
            "Ranking model training data prepared.\n",
            "\n",
            "--- Training LightGBM Ranking Model ---\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 800, number of negative: 800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 162\n",
            "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 53\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM Ranking Model trained successfully.\n",
            "\n",
            "--- Evaluating Hybrid Recommendation Model ---\n",
            "\n",
            "Starting evaluation for 59 unique students in the test set with K=10 for Hybrid Model.\n",
            "Hybrid Model recommendation generation and metric calculation complete for all eligible students.\n",
            "\n",
            "--- Average Evaluation Metrics for Hybrid Model ---\n",
            "\n",
            "Hybrid Model - Average Precision@10: 0.0203\n",
            "Hybrid Model - Average Recall@10: 0.0989\n",
            "\n",
            "--- Comparison with Baseline Models ---\n",
            "\n",
            "Most Popular Model - Average Precision@10: 0.0186\n",
            "Most Popular Model - Average Recall@10: 0.0847\n",
            "Collaborative Filtering Model - Average Precision@10: 0.0373\n",
            "Collaborative Filtering Model - Average Recall@10: 0.2429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a96707b2"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `ndcg_at_k` and `mrr_at_k` functions, which are crucial for evaluating the ranking quality of the recommendation models. These functions will be used to calculate NDCG@K and MRR metrics given a list of recommended items, actual interacted items, and the value of K, as specified by the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ccfd066",
        "outputId": "556131d1-73f7-483e-899e-0226053abb5b"
      },
      "source": [
        "import math\n",
        "\n",
        "print('--- Defining NDCG@K and MRR@K functions ---')\n",
        "\n",
        "def ndcg_at_k(recommended_items, actual_items, k):\n",
        "    \"\"\"\n",
        "    Calculates Normalized Discounted Cumulative Gain (NDCG) at K.\n",
        "    :param recommended_items: List of recommended item IDs (ranked).\n",
        "    :param actual_items: Set of actual interacted item IDs.\n",
        "    :param k: The number of recommendations considered.\n",
        "    :return: NDCG@K score.\n",
        "    \"\"\"\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "\n",
        "    # Calculate DCG\n",
        "    dcg = 0.0\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            dcg += 1.0 / math.log2(i + 2) # i+2 because log2(1) is 0\n",
        "\n",
        "    # Calculate Ideal DCG (IDCG)\n",
        "    idcg = 0.0\n",
        "    num_hits = min(len(actual_items), k)\n",
        "    for i in range(num_hits):\n",
        "        idcg += 1.0 / math.log2(i + 2)\n",
        "\n",
        "    if idcg == 0.0:\n",
        "        return 0.0\n",
        "\n",
        "    return dcg / idcg\n",
        "\n",
        "def mrr_at_k(recommended_items, actual_items, k):\n",
        "    \"\"\"\n",
        "    Calculates Mean Reciprocal Rank (MRR) at K.\n",
        "    :param recommended_items: List of recommended item IDs (ranked).\n",
        "    :param actual_items: Set of actual interacted item IDs.\n",
        "    :param k: The number of recommendations considered.\n",
        "    :return: MRR@K score.\n",
        "    \"\"\"\n",
        "    if k == 0 or not actual_items:\n",
        "        return 0.0\n",
        "\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            return 1.0 / (i + 1)\n",
        "\n",
        "    return 0.0 # No relevant item found within the top K\n",
        "\n",
        "print('`ndcg_at_k` and `mrr_at_k` functions defined.')\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Defining NDCG@K and MRR@K functions ---\n",
            "`ndcg_at_k` and `mrr_at_k` functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3608481"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to a `SyntaxError: unterminated string literal` in the print statement. I will correct this by ensuring the string literal is properly closed on a single line.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57b33e63",
        "outputId": "13d6ca97-50e3-480e-e3f3-79feafdc4651"
      },
      "source": [
        "import math\n",
        "\n",
        "print('--- Defining NDCG@K and MRR@K functions ---')\n",
        "\n",
        "def ndcg_at_k(recommended_items, actual_items, k):\n",
        "    \"\"\"\n",
        "    Calculates Normalized Discounted Cumulative Gain (NDCG) at K.\n",
        "    :param recommended_items: List of recommended item IDs (ranked).\n",
        "    :param actual_items: Set of actual interacted item IDs.\n",
        "    :param k: The number of recommendations considered.\n",
        "    :return: NDCG@K score.\n",
        "    \"\"\"\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "\n",
        "    # Calculate DCG\n",
        "    dcg = 0.0\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            dcg += 1.0 / math.log2(i + 2) # i+2 because log2(1) is 0\n",
        "\n",
        "    # Calculate Ideal DCG (IDCG)\n",
        "    idcg = 0.0\n",
        "    num_hits = min(len(actual_items), k)\n",
        "    for i in range(num_hits):\n",
        "        idcg += 1.0 / math.log2(i + 2)\n",
        "\n",
        "    if idcg == 0.0:\n",
        "        return 0.0\n",
        "\n",
        "    return dcg / idcg\n",
        "\n",
        "def mrr_at_k(recommended_items, actual_items, k):\n",
        "    \"\"\"\n",
        "    Calculates Mean Reciprocal Rank (MRR) at K.\n",
        "    :param recommended_items: List of recommended item IDs (ranked).\n",
        "    :param actual_items: Set of actual interacted item IDs.\n",
        "    :param k: The number of recommendations considered.\n",
        "    :return: MRR@K score.\n",
        "    \"\"\"\n",
        "    if k == 0 or not actual_items:\n",
        "        return 0.0\n",
        "\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            return 1.0 / (i + 1)\n",
        "\n",
        "    return 0.0 # No relevant item found within the top K\n",
        "\n",
        "print('`ndcg_at_k` and `mrr_at_k` functions defined.')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Defining NDCG@K and MRR@K functions ---\n",
            "`ndcg_at_k` and `mrr_at_k` functions defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b58f30a4"
      },
      "source": [
        "**Reasoning**:\n",
        "I will update the comprehensive evaluation code block to include the calculation and storage of NDCG@K and MRR@K metrics for all three recommendation models (Most Popular, Collaborative Filtering, and Hybrid). This involves initializing new lists for these metrics, calling the `ndcg_at_k` and `mrr_at_k` functions within the evaluation loops, and then printing their average values alongside Precision@K and Recall@K.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70c67676",
        "outputId": "484a95b4-f9d0-4dea-84b6-26014925d68b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Reader, Dataset, SVD\n",
        "import lightgbm as lgb\n",
        "import math\n",
        "\n",
        "print('--- Re-generating Synthetic Dataset and Temporal Split ---\\n')\n",
        "\n",
        "# 1. Re-generate Synthetic Dataset (from original cell cd481695)\n",
        "num_students = 100\n",
        "num_items = 50\n",
        "num_interactions = 1000\n",
        "\n",
        "student_ids = np.random.randint(1, num_students + 1, num_interactions)\n",
        "item_ids = np.random.randint(1, num_items + 1, num_interactions)\n",
        "interaction_types = np.random.choice(['view', 'complete', 'enroll', 'quiz_attempt', 'discuss'], num_interactions)\n",
        "\n",
        "start_date = pd.to_datetime('2023-01-01')\n",
        "end_date = pd.to_datetime('2023-12-31')\n",
        "time_range = (end_date - start_date).total_seconds()\n",
        "timestamps = start_date + pd.to_timedelta(np.random.rand(num_interactions) * time_range, unit='s')\n",
        "\n",
        "synthetic_df = pd.DataFrame({\n",
        "    'student_id': student_ids,\n",
        "    'item_id': item_ids,\n",
        "    'interaction_type': interaction_types,\n",
        "    'timestamp': timestamps\n",
        "})\n",
        "\n",
        "synthetic_df = synthetic_df.sort_values(by='timestamp').reset_index(drop=True)\n",
        "print('Synthetic DataFrame regenerated. First 5 rows:')\n",
        "print(synthetic_df.head())\n",
        "\n",
        "\n",
        "print('\\n--- Temporal Train/Validation/Test Split ---\\n')\n",
        "\n",
        "# 2. Perform Temporal Train/Validation/Test Split\n",
        "total_interactions = len(synthetic_df)\n",
        "train_size = int(0.8 * total_interactions)\n",
        "val_size = int(0.1 * total_interactions)\n",
        "test_size = total_interactions - train_size - val_size\n",
        "\n",
        "train_df = synthetic_df.iloc[:train_size]\n",
        "val_df = synthetic_df.iloc[train_size : train_size + val_size]\n",
        "test_df = synthetic_df.iloc[train_size + val_size :]\n",
        "\n",
        "print(f\"Train set interactions: {len(train_df)}\")\n",
        "print(f\"Validation set interactions: {len(val_df)}\")\n",
        "print(f\"Test set interactions: {len(test_df)}\")\n",
        "\n",
        "print('\\n--- Re-calculating Features ---\\n')\n",
        "\n",
        "# Recalculate User Features from train_df (from cell 757f4caf)\n",
        "user_interactions = train_df.groupby('student_id').agg(\n",
        "    total_interactions_user=('item_id', 'count'),\n",
        "    unique_items_interacted=('item_id', 'nunique'),\n",
        "    most_frequent_interaction_type_user=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Recalculate Item Features from train_df (from cell 757f4caf)\n",
        "item_interactions = train_df.groupby('item_id').agg(\n",
        "    total_interactions_item=('student_id', 'count'),\n",
        "    unique_students_interacted=('student_id', 'nunique'),\n",
        "    most_frequent_interaction_type_item=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Re-extract temporal features for train_df, val_df, test_df\n",
        "for df_name in ['train_df', 'val_df', 'test_df']:\n",
        "    df = globals()[df_name]\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "    globals()[df_name] = df # Update the global dataframe\n",
        "\n",
        "print('User and Item features recalculated, and temporal features extracted.')\n",
        "\n",
        "print('\\n--- Initializing surprise.Reader and loading data ---\\n')\n",
        "\n",
        "# Create a surprise.Reader object\n",
        "reader = Reader(rating_scale=(1, 1))\n",
        "\n",
        "# Prepare the data for Surprise library\n",
        "train_df_surprise = train_df[['student_id', 'item_id']].copy()\n",
        "train_df_surprise['dummy_rating'] = 1\n",
        "\n",
        "# Load the train_df into a surprise.Dataset\n",
        "data = Dataset.load_from_df(train_df_surprise[['student_id', 'item_id', 'dummy_rating']], reader)\n",
        "\n",
        "# Build a trainset from the loaded Dataset\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "print('\\n`surprise.Reader` object created and trainset built.')\n",
        "print(f\"Number of users in trainset: {trainset.n_users}\")\n",
        "print(f\"Number of items in trainset: {trainset.n_items}\")\n",
        "print(f\"Number of interactions in trainset: {trainset.n_ratings}\")\n",
        "\n",
        "print('\\n--- Training Collaborative Filtering Model (SVD) ---\\n')\n",
        "\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "print('SVD model trained successfully.')\n",
        "\n",
        "print('\\n--- Re-defining Recommendation Functions and Evaluation Metrics ---\\n')\n",
        "\n",
        "# Re-calculate item_popularity (from cell 12886fec)\n",
        "item_popularity = train_df['item_id'].value_counts().reset_index()\n",
        "item_popularity.columns = ['item_id', 'popularity_score']\n",
        "\n",
        "# Re-define get_most_popular_recommendations function (from cell 037917a8)\n",
        "def get_most_popular_recommendations(student_id, n, historical_interactions=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "\n",
        "    recommended_items = item_popularity[~item_popularity['item_id'].isin(historical_interactions)]\n",
        "    recommended_items = recommended_items.sort_values(by='popularity_score', ascending=False)\n",
        "\n",
        "    return recommended_items.head(n)['item_id'].tolist()\n",
        "\n",
        "# Re-define get_cf_recommendations function (from cell c24f0ef6)\n",
        "def get_cf_recommendations(student_id, n, historical_interactions, model, trainset):\n",
        "    all_item_ids = synthetic_df['item_id'].unique()\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n]]\n",
        "    return top_n_items\n",
        "\n",
        "# Re-define get_actual_interactions(student_id, df)\n",
        "def get_actual_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define get_historical_interactions(student_id, df)\n",
        "def get_historical_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define precision_at_k(recommended_items, actual_items, k)\n",
        "def precision_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / k\n",
        "\n",
        "# Re-define recall_at_k(recommended_items, actual_items, k)\n",
        "def recall_at_k(recommended_items, actual_items, k):\n",
        "    if len(actual_items) == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / len(actual_items)\n",
        "\n",
        "def ndcg_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    dcg = 0.0\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            dcg += 1.0 / math.log2(i + 2)\n",
        "    idcg = 0.0\n",
        "    num_hits = min(len(actual_items), k)\n",
        "    for i in range(num_hits):\n",
        "        idcg += 1.0 / math.log2(i + 2)\n",
        "    if idcg == 0.0:\n",
        "        return 0.0\n",
        "    return dcg / idcg\n",
        "\n",
        "def mrr_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0 or not actual_items:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            return 1.0 / (i + 1)\n",
        "    return 0.0\n",
        "\n",
        "# Re-initialize lists for baseline evaluation metrics (from cell 71ff55e2)\n",
        "most_popular_precision_scores = []\n",
        "most_popular_recall_scores = []\n",
        "most_popular_ndcg_scores = []\n",
        "most_popular_mrr_scores = []\n",
        "\n",
        "cf_precision_scores = []\n",
        "cf_recall_scores = []\n",
        "cf_ndcg_scores = []\n",
        "cf_mrr_scores = []\n",
        "\n",
        "# Set the value for K for Precision@K and Recall@K\n",
        "K = 10\n",
        "\n",
        "# Get all unique student_ids from the test set for baseline evaluation\n",
        "unique_test_students_baseline = test_df['student_id'].unique()\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students_baseline)} unique students in the test set with K={K} for Baseline Models.\")\n",
        "\n",
        "for student_id in unique_test_students_baseline:\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    if len(actual_interactions) > 0:\n",
        "        most_popular_recs = get_most_popular_recommendations(student_id, K, historical_interactions)\n",
        "        cf_recs = get_cf_recommendations(student_id, K, historical_interactions, algo, trainset)\n",
        "\n",
        "        mp_precision = precision_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_recall = recall_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_ndcg = ndcg_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_mrr = mrr_at_k(most_popular_recs, actual_interactions, K)\n",
        "\n",
        "        cf_precision = precision_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_recall = recall_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_ndcg = ndcg_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_mrr = mrr_at_k(cf_recs, actual_interactions, K)\n",
        "\n",
        "        most_popular_precision_scores.append(mp_precision)\n",
        "        most_popular_recall_scores.append(mp_recall)\n",
        "        most_popular_ndcg_scores.append(mp_ndcg)\n",
        "        most_popular_mrr_scores.append(mp_mrr)\n",
        "\n",
        "        cf_precision_scores.append(cf_precision)\n",
        "        cf_recall_scores.append(cf_recall)\n",
        "        cf_ndcg_scores.append(cf_ndcg)\n",
        "        cf_mrr_scores.append(cf_mrr)\n",
        "\n",
        "print('Baseline Recommendation generation and metric calculation complete.')\n",
        "\n",
        "print('\\n--- Preparing Ranking Model Training Data ---\\n')\n",
        "\n",
        "# Prepare positive samples (from cell ee0afb00)\n",
        "positive_samples_df = train_df.copy()\n",
        "positive_samples_df['target'] = 1\n",
        "positive_samples_df = pd.merge(positive_samples_df, user_interactions, on='student_id', how='left')\n",
        "positive_samples_df = pd.merge(positive_samples_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# Generate negative samples (from cell 9b44e5af)\n",
        "negative_samples_list = []\n",
        "all_item_ids = synthetic_df['item_id'].unique()\n",
        "\n",
        "for student_id in train_df['student_id'].unique():\n",
        "    interacted_items = set(train_df[train_df['student_id'] == student_id]['item_id'].unique())\n",
        "    non_interacted_items = [item_id for item_id in all_item_ids if item_id not in interacted_items]\n",
        "    num_positive_interactions = len(train_df[train_df['student_id'] == student_id])\n",
        "    num_negative_samples_to_generate = min(num_positive_interactions, len(non_interacted_items))\n",
        "\n",
        "    if num_negative_samples_to_generate > 0:\n",
        "        sampled_negative_items = np.random.choice(non_interacted_items, num_negative_samples_to_generate, replace=False)\n",
        "        for item_id in sampled_negative_items:\n",
        "            negative_samples_list.append({\n",
        "                'student_id': student_id,\n",
        "                'item_id': item_id,\n",
        "                'target': 0\n",
        "            })\n",
        "\n",
        "negative_samples_df = pd.DataFrame(negative_samples_list)\n",
        "negative_samples_df = pd.merge(negative_samples_df, user_interactions, on='student_id', how='left')\n",
        "negative_samples_df = pd.merge(negative_samples_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# Combine positive and negative samples (from cell 4b1b4b12)\n",
        "training_data_ranking = pd.concat([positive_samples_df, negative_samples_df], ignore_index=True)\n",
        "training_data_ranking = training_data_ranking.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Identify and handle categorical features for ranking model (from cell 93c873ad)\n",
        "categorical_features = [\n",
        "    'interaction_type',\n",
        "    'most_frequent_interaction_type_user',\n",
        "    'most_frequent_interaction_type_item',\n",
        "    'day_of_week',\n",
        "    'hour_of_day'\n",
        "]\n",
        "categorical_features = [col for col in categorical_features if col in training_data_ranking.columns]\n",
        "\n",
        "for col in ['day_of_week', 'hour_of_day']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna(-1).astype(int)\n",
        "\n",
        "for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna('unknown')\n",
        "\n",
        "# Convert Categorical Features to Numerical using One-Hot Encoding (from cell d4012e0d)\n",
        "training_data_ranking_encoded = pd.get_dummies(training_data_ranking, columns=categorical_features, dummy_na=False)\n",
        "columns_to_drop = ['timestamp']\n",
        "training_data_ranking_encoded = training_data_ranking_encoded.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Split Training Data into Features (X) and Target (y) (from cell 383135af)\n",
        "X = training_data_ranking_encoded.drop(columns=['target', 'student_id', 'item_id'], errors='ignore')\n",
        "y = training_data_ranking_encoded['target']\n",
        "\n",
        "print('Ranking model training data prepared.')\n",
        "\n",
        "print('\\n--- Training LightGBM Ranking Model ---\\n')\n",
        "\n",
        "# Train a LightGBM Classifier model (LGBMClassifier) (from cell b166493b)\n",
        "ranking_model = lgb.LGBMClassifier(random_state=42)\n",
        "ranking_model.fit(X, y)\n",
        "\n",
        "print('LightGBM Ranking Model trained successfully.')\n",
        "\n",
        "# 1. Initialize lists to store Precision@K and Recall@K scores for the Hybrid Recommendation Model.\n",
        "hybrid_precision_scores = []\n",
        "hybrid_recall_scores = []\n",
        "hybrid_ndcg_scores = []\n",
        "hybrid_mrr_scores = []\n",
        "\n",
        "print('\\n--- Evaluating Hybrid Recommendation Model ---\\n')\n",
        "\n",
        "# Get all unique student_ids from the test set\n",
        "unique_test_students = test_df['student_id'].unique()\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students)} unique students in the test set with K={K} for Hybrid Model.\")\n",
        "\n",
        "# Get the feature columns that the ranking model was trained on\n",
        "ranking_model_features = X.columns.tolist()\n",
        "\n",
        "# Re-define candidate generation function to use updated global synthetic_df\n",
        "def generate_candidates_for_user(student_id, model, n_candidates=50, historical_interactions=None, all_item_ids=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "    if all_item_ids is None:\n",
        "        all_item_ids = synthetic_df['item_id'].unique() # Ensure synthetic_df is available globally\n",
        "\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n_candidates]]\n",
        "    return top_n_items\n",
        "\n",
        "\n",
        "for student_id in unique_test_students:\n",
        "    # 3. Get historical and actual interactions\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    # Only evaluate if the student has actual interactions in the test set\n",
        "    if len(actual_interactions) > 0:\n",
        "        # 4. Generate candidate items using the SVD model\n",
        "        candidates = generate_candidates_for_user(student_id, algo, n_candidates=50, historical_interactions=historical_interactions, all_item_ids=synthetic_df['item_id'].unique())\n",
        "\n",
        "        if not candidates: # Skip if no candidates are generated\n",
        "            continue\n",
        "\n",
        "        # 5. Create feature vectors for candidate items\n",
        "        candidate_data = []\n",
        "        for item_id in candidates:\n",
        "            # Get user features for the current student\n",
        "            user_feat = user_interactions[user_interactions['student_id'] == student_id]\n",
        "            if user_feat.empty:\n",
        "                continue # Skip if no user features found for this student\n",
        "            user_feat = user_feat.iloc[0]\n",
        "\n",
        "            # Get item features for the current candidate item\n",
        "            item_feat = item_interactions[item_interactions['item_id'] == item_id]\n",
        "            if item_feat.empty:\n",
        "                continue # Skip if no item features found for this item\n",
        "            item_feat = item_feat.iloc[0]\n",
        "\n",
        "            # Combine features\n",
        "            student_test_interactions = test_df[test_df['student_id'] == student_id]\n",
        "            if not student_test_interactions.empty:\n",
        "                representative_day_of_week = student_test_interactions['day_of_week'].iloc[0]\n",
        "                representative_hour_of_day = student_test_interactions['hour_of_day'].iloc[0]\n",
        "            else:\n",
        "                representative_day_of_week = -1\n",
        "                representative_hour_of_day = -1\n",
        "\n",
        "            temp_data = {\n",
        "                'student_id': student_id,\n",
        "                'item_id': item_id,\n",
        "                'interaction_type': 'unknown',\n",
        "                'day_of_week': representative_day_of_week,\n",
        "                'hour_of_day': representative_hour_of_day,\n",
        "            }\n",
        "            temp_data.update(user_feat.drop('student_id').to_dict())\n",
        "            temp_data.update(item_feat.drop('item_id').to_dict())\n",
        "            candidate_data.append(temp_data)\n",
        "\n",
        "        if not candidate_data: # If no valid candidate data generated\n",
        "            continue\n",
        "\n",
        "        candidate_df = pd.DataFrame(candidate_data)\n",
        "\n",
        "        for col in ['day_of_week', 'hour_of_day']:\n",
        "            if col in candidate_df.columns:\n",
        "                candidate_df[col] = candidate_df[col].fillna(-1).astype(int)\n",
        "\n",
        "        for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "            if col in candidate_df.columns:\n",
        "                candidate_df[col] = candidate_df[col].fillna('unknown')\n",
        "\n",
        "        # One-hot encode candidate_df, ensuring all training columns are present\n",
        "        candidate_df_encoded = pd.get_dummies(candidate_df, columns=categorical_features, dummy_na=False)\n",
        "\n",
        "        # Align columns with the training data's X\n",
        "        missing_cols = set(ranking_model_features) - set(candidate_df_encoded.columns)\n",
        "        for c in missing_cols:\n",
        "            candidate_df_encoded[c] = False\n",
        "        extra_cols = set(candidate_df_encoded.columns) - set(ranking_model_features)\n",
        "        candidate_df_encoded = candidate_df_encoded.drop(columns=list(extra_cols))\n",
        "\n",
        "        # Ensure the order of columns is the same\n",
        "        candidate_features_for_prediction = candidate_df_encoded[ranking_model_features]\n",
        "\n",
        "        # 6. Predict the likelihood of interaction for each candidate item\n",
        "        predictions = ranking_model.predict_proba(candidate_features_for_prediction)[:, 1]\n",
        "\n",
        "        # 7. Rank candidates based on predicted likelihoods\n",
        "        ranked_candidates = pd.DataFrame({\n",
        "            'item_id': candidate_df['item_id'],\n",
        "            'predicted_score': predictions\n",
        "        })\n",
        "        ranked_candidates = ranked_candidates.sort_values(by='predicted_score', ascending=False)\n",
        "        hybrid_recs = ranked_candidates.head(K)['item_id'].tolist()\n",
        "\n",
        "        # 8. Calculate Precision@K, Recall@K, NDCG@K, MRR@K\n",
        "        hybrid_precision = precision_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_recall = recall_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_ndcg = ndcg_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_mrr = mrr_at_k(hybrid_recs, actual_interactions, K)\n",
        "\n",
        "        # 9. Append scores to respective lists\n",
        "        hybrid_precision_scores.append(hybrid_precision)\n",
        "        hybrid_recall_scores.append(hybrid_recall)\n",
        "        hybrid_ndcg_scores.append(hybrid_ndcg)\n",
        "        hybrid_mrr_scores.append(hybrid_mrr)\n",
        "\n",
        "print('Hybrid Model recommendation generation and metric calculation complete for all eligible students.')\n",
        "\n",
        "# 10. Calculate and print the average Precision@K, Recall@K, NDCG@K, and MRR@K for the Hybrid Recommendation Model.\n",
        "print('\\n--- Average Evaluation Metrics for Hybrid Model ---\\n')\n",
        "\n",
        "if hybrid_precision_scores:\n",
        "    print(f\"Hybrid Model - Average Precision@{K}: {np.mean(hybrid_precision_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Average Recall@{K}: {np.mean(hybrid_recall_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Average NDCG@{K}: {np.mean(hybrid_ndcg_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Average MRR@{K}: {np.mean(hybrid_mrr_scores):.4f}\")\n",
        "else:\n",
        "    print(\"No scores calculated for Hybrid Model.\")\n",
        "\n",
        "# 11. Compare these average metrics with the baseline models.\n",
        "print('\\n--- Comparison with Baseline Models ---\\n')\n",
        "\n",
        "if most_popular_precision_scores:\n",
        "    print(f\"Most Popular Model - Average Precision@{K}: {np.mean(most_popular_precision_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Average Recall@{K}: {np.mean(most_popular_recall_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Average NDCG@{K}: {np.mean(most_popular_ndcg_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Average MRR@{K}: {np.mean(most_popular_mrr_scores):.4f}\")\n",
        "\n",
        "if cf_precision_scores:\n",
        "    print(f\"Collaborative Filtering Model - Average Precision@{K}: {np.mean(cf_precision_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Average Recall@{K}: {np.mean(cf_recall_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Average NDCG@{K}: {np.mean(cf_ndcg_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Average MRR@{K}: {np.mean(cf_mrr_scores):.4f}\")\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Re-generating Synthetic Dataset and Temporal Split ---\n",
            "\n",
            "Synthetic DataFrame regenerated. First 5 rows:\n",
            "   student_id  item_id interaction_type                     timestamp\n",
            "0          86       33     quiz_attempt 2023-01-01 03:17:30.203925333\n",
            "1          20        2           enroll 2023-01-01 10:31:10.960777989\n",
            "2          15       19          discuss 2023-01-01 10:41:46.048652877\n",
            "3          72       49     quiz_attempt 2023-01-01 16:41:11.771082239\n",
            "4          59       10           enroll 2023-01-01 21:38:51.564838470\n",
            "\n",
            "--- Temporal Train/Validation/Test Split ---\n",
            "\n",
            "Train set interactions: 800\n",
            "Validation set interactions: 100\n",
            "Test set interactions: 100\n",
            "\n",
            "--- Re-calculating Features ---\n",
            "\n",
            "User and Item features recalculated, and temporal features extracted.\n",
            "\n",
            "--- Initializing surprise.Reader and loading data ---\n",
            "\n",
            "\n",
            "`surprise.Reader` object created and trainset built.\n",
            "Number of users in trainset: 100\n",
            "Number of items in trainset: 50\n",
            "Number of interactions in trainset: 800\n",
            "\n",
            "--- Training Collaborative Filtering Model (SVD) ---\n",
            "\n",
            "SVD model trained successfully.\n",
            "\n",
            "--- Re-defining Recommendation Functions and Evaluation Metrics ---\n",
            "\n",
            "Starting evaluation for 62 unique students in the test set with K=10 for Baseline Models.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-515115319.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
            "/tmp/ipython-input-515115319.py:71: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hour_of_day'] = df['timestamp'].dt.hour\n",
            "/tmp/ipython-input-515115319.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
            "/tmp/ipython-input-515115319.py:71: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hour_of_day'] = df['timestamp'].dt.hour\n",
            "/tmp/ipython-input-515115319.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
            "/tmp/ipython-input-515115319.py:71: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hour_of_day'] = df['timestamp'].dt.hour\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Recommendation generation and metric calculation complete.\n",
            "\n",
            "--- Preparing Ranking Model Training Data ---\n",
            "\n",
            "Ranking model training data prepared.\n",
            "\n",
            "--- Training LightGBM Ranking Model ---\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 800, number of negative: 800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 154\n",
            "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 53\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM Ranking Model trained successfully.\n",
            "\n",
            "--- Evaluating Hybrid Recommendation Model ---\n",
            "\n",
            "Starting evaluation for 62 unique students in the test set with K=10 for Hybrid Model.\n",
            "Hybrid Model recommendation generation and metric calculation complete for all eligible students.\n",
            "\n",
            "--- Average Evaluation Metrics for Hybrid Model ---\n",
            "\n",
            "Hybrid Model - Average Precision@10: 0.0306\n",
            "Hybrid Model - Average Recall@10: 0.1989\n",
            "Hybrid Model - Average NDCG@10: 0.0992\n",
            "Hybrid Model - Average MRR@10: 0.0771\n",
            "\n",
            "--- Comparison with Baseline Models ---\n",
            "\n",
            "Most Popular Model - Average Precision@10: 0.0306\n",
            "Most Popular Model - Average Recall@10: 0.1882\n",
            "Most Popular Model - Average NDCG@10: 0.0951\n",
            "Most Popular Model - Average MRR@10: 0.0744\n",
            "Collaborative Filtering Model - Average Precision@10: 0.0323\n",
            "Collaborative Filtering Model - Average Recall@10: 0.1613\n",
            "Collaborative Filtering Model - Average NDCG@10: 0.0916\n",
            "Collaborative Filtering Model - Average MRR@10: 0.0929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c416c0d"
      },
      "source": [
        "**Reasoning**:\n",
        "I will update the comprehensive evaluation code block to include the calculation and storage of NDCG@K and MRR@K metrics for all three recommendation models (Most Popular, Collaborative Filtering, and Hybrid). This involves initializing new lists for these metrics, calling the `ndcg_at_k` and `mrr_at_k` functions within the evaluation loops, and then printing their average values alongside Precision@K and Recall@K.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2af4b65",
        "outputId": "207639ba-dfdf-4e0d-c04f-e7f802b9a2bc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Reader, Dataset, SVD\n",
        "import lightgbm as lgb\n",
        "import math\n",
        "\n",
        "print('--- Re-generating Synthetic Dataset and Temporal Split ---\\n')\n",
        "\n",
        "# 1. Re-generate Synthetic Dataset (from original cell cd481695)\n",
        "num_students = 100\n",
        "num_items = 50\n",
        "num_interactions = 1000\n",
        "\n",
        "student_ids = np.random.randint(1, num_students + 1, num_interactions)\n",
        "item_ids = np.random.randint(1, num_items + 1, num_interactions)\n",
        "interaction_types = np.random.choice(['view', 'complete', 'enroll', 'quiz_attempt', 'discuss'], num_interactions)\n",
        "\n",
        "start_date = pd.to_datetime('2023-01-01')\n",
        "end_date = pd.to_datetime('2023-12-31')\n",
        "time_range = (end_date - start_date).total_seconds()\n",
        "timestamps = start_date + pd.to_timedelta(np.random.rand(num_interactions) * time_range, unit='s')\n",
        "\n",
        "synthetic_df = pd.DataFrame({\n",
        "    'student_id': student_ids,\n",
        "    'item_id': item_ids,\n",
        "    'interaction_type': interaction_types,\n",
        "    'timestamp': timestamps\n",
        "})\n",
        "\n",
        "synthetic_df = synthetic_df.sort_values(by='timestamp').reset_index(drop=True)\n",
        "print('Synthetic DataFrame regenerated. First 5 rows:')\n",
        "print(synthetic_df.head())\n",
        "\n",
        "\n",
        "print('\\n--- Temporal Train/Validation/Test Split ---\\n')\n",
        "\n",
        "# 2. Perform Temporal Train/Validation/Test Split\n",
        "total_interactions = len(synthetic_df)\n",
        "train_size = int(0.8 * total_interactions)\n",
        "val_size = int(0.1 * total_interactions)\n",
        "test_size = total_interactions - train_size - val_size\n",
        "\n",
        "train_df = synthetic_df.iloc[:train_size]\n",
        "val_df = synthetic_df.iloc[train_size : train_size + val_size]\n",
        "test_df = synthetic_df.iloc[train_size + val_size :]\n",
        "\n",
        "print(f\"Train set interactions: {len(train_df)}\")\n",
        "print(f\"Validation set interactions: {len(val_df)}\")\n",
        "print(f\"Test set interactions: {len(test_df)}\")\n",
        "\n",
        "print('\\n--- Re-calculating Features ---\\n')\n",
        "\n",
        "# Recalculate User Features from train_df (from cell 757f4caf)\n",
        "user_interactions = train_df.groupby('student_id').agg(\n",
        "    total_interactions_user=('item_id', 'count'),\n",
        "    unique_items_interacted=('item_id', 'nunique'),\n",
        "    most_frequent_interaction_type_user=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Recalculate Item Features from train_df (from cell 757f4caf)\n",
        "item_interactions = train_df.groupby('item_id').agg(\n",
        "    total_interactions_item=('student_id', 'count'),\n",
        "    unique_students_interacted=('student_id', 'nunique'),\n",
        "    most_frequent_interaction_type_item=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Re-extract temporal features for train_df, val_df, test_df\n",
        "for df_name in ['train_df', 'val_df', 'test_df']:\n",
        "    df = globals()[df_name]\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "    globals()[df_name] = df # Update the global dataframe\n",
        "\n",
        "print('User and Item features recalculated, and temporal features extracted.')\n",
        "\n",
        "print('\\n--- Initializing surprise.Reader and loading data ---\\n')\n",
        "\n",
        "# Create a surprise.Reader object\n",
        "reader = Reader(rating_scale=(1, 1))\n",
        "\n",
        "# Prepare the data for Surprise library\n",
        "train_df_surprise = train_df[['student_id', 'item_id']].copy()\n",
        "train_df_surprise['dummy_rating'] = 1\n",
        "\n",
        "# Load the train_df into a surprise.Dataset\n",
        "data = Dataset.load_from_df(train_df_surprise[['student_id', 'item_id', 'dummy_rating']], reader)\n",
        "\n",
        "# Build a trainset from the loaded Dataset\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "print('\\n`surprise.Reader` object created and trainset built.')\n",
        "print(f\"Number of users in trainset: {trainset.n_users}\")\n",
        "print(f\"Number of items in trainset: {trainset.n_items}\")\n",
        "print(f\"Number of interactions in trainset: {trainset.n_ratings}\")\n",
        "\n",
        "print('\\n--- Training Collaborative Filtering Model (SVD) ---\\n')\n",
        "\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "print('SVD model trained successfully.')\n",
        "\n",
        "print('\\n--- Re-defining Recommendation Functions and Evaluation Metrics ---\\n')\n",
        "\n",
        "# Re-calculate item_popularity (from cell 12886fec)\n",
        "item_popularity = train_df['item_id'].value_counts().reset_index()\n",
        "item_popularity.columns = ['item_id', 'popularity_score']\n",
        "\n",
        "# Re-define get_most_popular_recommendations function (from cell 037917a8)\n",
        "def get_most_popular_recommendations(student_id, n, historical_interactions=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "\n",
        "    recommended_items = item_popularity[~item_popularity['item_id'].isin(historical_interactions)]\n",
        "    recommended_items = recommended_items.sort_values(by='popularity_score', ascending=False)\n",
        "\n",
        "    return recommended_items.head(n)['item_id'].tolist()\n",
        "\n",
        "# Re-define get_cf_recommendations function (from cell c24f0ef6)\n",
        "def get_cf_recommendations(student_id, n, historical_interactions, model, trainset):\n",
        "    all_item_ids = synthetic_df['item_id'].unique()\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n]]\n",
        "    return top_n_items\n",
        "\n",
        "# Re-define get_actual_interactions(student_id, df)\n",
        "def get_actual_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define get_historical_interactions(student_id, df)\n",
        "def get_historical_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define precision_at_k(recommended_items, actual_items, k)\n",
        "def precision_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / k\n",
        "\n",
        "# Re-define recall_at_k(recommended_items, actual_items, k)\n",
        "def recall_at_k(recommended_items, actual_items, k):\n",
        "    if len(actual_items) == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / len(actual_items)\n",
        "\n",
        "def ndcg_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    dcg = 0.0\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            dcg += 1.0 / math.log2(i + 2)\n",
        "    idcg = 0.0\n",
        "    num_hits = min(len(actual_items), k)\n",
        "    for i in range(num_hits):\n",
        "        idcg += 1.0 / math.log2(i + 2)\n",
        "    if idcg == 0.0:\n",
        "        return 0.0\n",
        "    return dcg / idcg\n",
        "\n",
        "def mrr_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0 or not actual_items:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            return 1.0 / (i + 1)\n",
        "    return 0.0\n",
        "\n",
        "# Re-initialize lists for baseline evaluation metrics (from cell 71ff55e2)\n",
        "most_popular_precision_scores = []\n",
        "most_popular_recall_scores = []\n",
        "most_popular_ndcg_scores = []\n",
        "most_popular_mrr_scores = []\n",
        "\n",
        "cf_precision_scores = []\n",
        "cf_recall_scores = []\n",
        "cf_ndcg_scores = []\n",
        "cf_mrr_scores = []\n",
        "\n",
        "# Set the value for K for Precision@K and Recall@K\n",
        "K = 10\n",
        "\n",
        "# Get all unique student_ids from the test set for baseline evaluation\n",
        "unique_test_students_baseline = test_df['student_id'].unique()\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students_baseline)} unique students in the test set with K={K} for Baseline Models.\")\n",
        "\n",
        "for student_id in unique_test_students_baseline:\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    if len(actual_interactions) > 0:\n",
        "        most_popular_recs = get_most_popular_recommendations(student_id, K, historical_interactions)\n",
        "        cf_recs = get_cf_recommendations(student_id, K, historical_interactions, algo, trainset)\n",
        "\n",
        "        mp_precision = precision_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_recall = recall_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_ndcg = ndcg_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_mrr = mrr_at_k(most_popular_recs, actual_interactions, K)\n",
        "\n",
        "        cf_precision = precision_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_recall = recall_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_ndcg = ndcg_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_mrr = mrr_at_k(cf_recs, actual_interactions, K)\n",
        "\n",
        "        most_popular_precision_scores.append(mp_precision)\n",
        "        most_popular_recall_scores.append(mp_recall)\n",
        "        most_popular_ndcg_scores.append(mp_ndcg)\n",
        "        most_popular_mrr_scores.append(mp_mrr)\n",
        "\n",
        "        cf_precision_scores.append(cf_precision)\n",
        "        cf_recall_scores.append(cf_recall)\n",
        "        cf_ndcg_scores.append(cf_ndcg)\n",
        "        cf_mrr_scores.append(cf_mrr)\n",
        "\n",
        "print('Baseline Recommendation generation and metric calculation complete.')\n",
        "\n",
        "print('\\n--- Preparing Ranking Model Training Data ---\\n')\n",
        "\n",
        "# Prepare positive samples (from cell ee0afb00)\n",
        "positive_samples_df = train_df.copy()\n",
        "positive_samples_df['target'] = 1\n",
        "positive_samples_df = pd.merge(positive_samples_df, user_interactions, on='student_id', how='left')\n",
        "positive_samples_df = pd.merge(positive_samples_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# Generate negative samples (from cell 9b44e5af)\n",
        "negative_samples_list = []\n",
        "all_item_ids = synthetic_df['item_id'].unique()\n",
        "\n",
        "for student_id in train_df['student_id'].unique():\n",
        "    interacted_items = set(train_df[train_df['student_id'] == student_id]['item_id'].unique())\n",
        "    non_interacted_items = [item_id for item_id in all_item_ids if item_id not in interacted_items]\n",
        "    num_positive_interactions = len(train_df[train_df['student_id'] == student_id])\n",
        "    num_negative_samples_to_generate = min(num_positive_interactions, len(non_interacted_items))\n",
        "\n",
        "    if num_negative_samples_to_generate > 0:\n",
        "        sampled_negative_items = np.random.choice(non_interacted_items, num_negative_samples_to_generate, replace=False)\n",
        "        for item_id in sampled_negative_items:\n",
        "            negative_samples_list.append({\n",
        "                'student_id': student_id,\n",
        "                'item_id': item_id,\n",
        "                'target': 0\n",
        "            })\n",
        "\n",
        "negative_samples_df = pd.DataFrame(negative_samples_list)\n",
        "negative_samples_df = pd.merge(negative_samples_df, user_interactions, on='student_id', how='left')\n",
        "negative_samples_df = pd.merge(negative_samples_df, item_interactions, on='item_id', how='left')\n",
        "\n",
        "# Combine positive and negative samples (from cell 4b1b4b12)\n",
        "training_data_ranking = pd.concat([positive_samples_df, negative_samples_df], ignore_index=True)\n",
        "training_data_ranking = training_data_ranking.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Identify and handle categorical features for ranking model (from cell 93c873ad)\n",
        "categorical_features = [\n",
        "    'interaction_type',\n",
        "    'most_frequent_interaction_type_user',\n",
        "    'most_frequent_interaction_type_item',\n",
        "    'day_of_week',\n",
        "    'hour_of_day'\n",
        "]\n",
        "categorical_features = [col for col in categorical_features if col in training_data_ranking.columns]\n",
        "\n",
        "for col in ['day_of_week', 'hour_of_day']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna(-1).astype(int)\n",
        "\n",
        "for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "    if col in training_data_ranking.columns and training_data_ranking[col].isnull().any():\n",
        "        training_data_ranking[col] = training_data_ranking[col].fillna('unknown')\n",
        "\n",
        "# Convert Categorical Features to Numerical using One-Hot Encoding (from cell d4012e0d)\n",
        "training_data_ranking_encoded = pd.get_dummies(training_data_ranking, columns=categorical_features, dummy_na=False)\n",
        "columns_to_drop = ['timestamp']\n",
        "training_data_ranking_encoded = training_data_ranking_encoded.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Split Training Data into Features (X) and Target (y) (from cell 383135af)\n",
        "X = training_data_ranking_encoded.drop(columns=['target', 'student_id', 'item_id'], errors='ignore')\n",
        "y = training_data_ranking_encoded['target']\n",
        "\n",
        "print('Ranking model training data prepared.')\n",
        "\n",
        "print('\\n--- Training LightGBM Ranking Model ---\\n')\n",
        "\n",
        "# Train a LightGBM Classifier model (LGBMClassifier) (from cell b166493b)\n",
        "ranking_model = lgb.LGBMClassifier(random_state=42)\n",
        "ranking_model.fit(X, y)\n",
        "\n",
        "print('LightGBM Ranking Model trained successfully.')\n",
        "\n",
        "# 1. Initialize lists to store Precision@K and Recall@K scores for the Hybrid Recommendation Model.\n",
        "hybrid_precision_scores = []\n",
        "hybrid_recall_scores = []\n",
        "hybrid_ndcg_scores = []\n",
        "hybrid_mrr_scores = []\n",
        "\n",
        "print('\\n--- Evaluating Hybrid Recommendation Model ---\\n')\n",
        "\n",
        "# Get all unique student_ids from the test set\n",
        "unique_test_students = test_df['student_id'].unique()\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students)} unique students in the test set with K={K} for Hybrid Model.\")\n",
        "\n",
        "# Get the feature columns that the ranking model was trained on\n",
        "ranking_model_features = X.columns.tolist()\n",
        "\n",
        "# Re-define candidate generation function to use updated global synthetic_df\n",
        "def generate_candidates_for_user(student_id, model, n_candidates=50, historical_interactions=None, all_item_ids=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "    if all_item_ids is None:\n",
        "        all_item_ids = synthetic_df['item_id'].unique() # Ensure synthetic_df is available globally\n",
        "\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n_candidates]]\n",
        "    return top_n_items\n",
        "\n",
        "\n",
        "for student_id in unique_test_students:\n",
        "    # 3. Get historical and actual interactions\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    # Only evaluate if the student has actual interactions in the test set\n",
        "    if len(actual_interactions) > 0:\n",
        "        # 4. Generate candidate items using the SVD model\n",
        "        candidates = generate_candidates_for_user(student_id, algo, n_candidates=50, historical_interactions=historical_interactions, all_item_ids=synthetic_df['item_id'].unique())\n",
        "\n",
        "        if not candidates: # Skip if no candidates are generated\n",
        "            continue\n",
        "\n",
        "        # 5. Create feature vectors for candidate items\n",
        "        candidate_data = []\n",
        "        for item_id in candidates:\n",
        "            # Get user features for the current student\n",
        "            user_feat = user_interactions[user_interactions['student_id'] == student_id]\n",
        "            if user_feat.empty:\n",
        "                continue # Skip if no user features found for this student\n",
        "            user_feat = user_feat.iloc[0]\n",
        "\n",
        "            # Get item features for the current candidate item\n",
        "            item_feat = item_interactions[item_interactions['item_id'] == item_id]\n",
        "            if item_feat.empty:\n",
        "                continue # Skip if no item features found for this item\n",
        "            item_feat = item_feat.iloc[0]\n",
        "\n",
        "            # Combine features\n",
        "            student_test_interactions = test_df[test_df['student_id'] == student_id]\n",
        "            if not student_test_interactions.empty:\n",
        "                representative_day_of_week = student_test_interactions['day_of_week'].iloc[0]\n",
        "                representative_hour_of_day = student_test_interactions['hour_of_day'].iloc[0]\n",
        "            else:\n",
        "                representative_day_of_week = -1\n",
        "                representative_hour_of_day = -1\n",
        "\n",
        "            temp_data = {\n",
        "                'student_id': student_id,\n",
        "                'item_id': item_id,\n",
        "                'interaction_type': 'unknown',\n",
        "                'day_of_week': representative_day_of_week,\n",
        "                'hour_of_day': representative_hour_of_day,\n",
        "            }\n",
        "            temp_data.update(user_feat.drop('student_id').to_dict())\n",
        "            temp_data.update(item_feat.drop('item_id').to_dict())\n",
        "            candidate_data.append(temp_data)\n",
        "\n",
        "        if not candidate_data: # If no valid candidate data generated\n",
        "            continue\n",
        "\n",
        "        candidate_df = pd.DataFrame(candidate_data)\n",
        "\n",
        "        for col in ['day_of_week', 'hour_of_day']:\n",
        "            if col in candidate_df.columns:\n",
        "                candidate_df[col] = candidate_df[col].fillna(-1).astype(int)\n",
        "\n",
        "        for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "            if col in candidate_df.columns:\n",
        "                candidate_df[col] = candidate_df[col].fillna('unknown')\n",
        "\n",
        "        # One-hot encode candidate_df, ensuring all training columns are present\n",
        "        candidate_df_encoded = pd.get_dummies(candidate_df, columns=categorical_features, dummy_na=False)\n",
        "\n",
        "        # Align columns with the training data's X\n",
        "        missing_cols = set(ranking_model_features) - set(candidate_df_encoded.columns)\n",
        "        for c in missing_cols:\n",
        "            candidate_df_encoded[c] = False\n",
        "        extra_cols = set(candidate_df_encoded.columns) - set(ranking_model_features)\n",
        "        candidate_df_encoded = candidate_df_encoded.drop(columns=list(extra_cols))\n",
        "\n",
        "        # Ensure the order of columns is the same\n",
        "        candidate_features_for_prediction = candidate_df_encoded[ranking_model_features]\n",
        "\n",
        "        # 6. Predict the likelihood of interaction for each candidate item\n",
        "        predictions = ranking_model.predict_proba(candidate_features_for_prediction)[:, 1]\n",
        "\n",
        "        # 7. Rank candidates based on predicted likelihoods\n",
        "        ranked_candidates = pd.DataFrame({\n",
        "            'item_id': candidate_df['item_id'],\n",
        "            'predicted_score': predictions\n",
        "        })\n",
        "        ranked_candidates = ranked_candidates.sort_values(by='predicted_score', ascending=False)\n",
        "        hybrid_recs = ranked_candidates.head(K)['item_id'].tolist()\n",
        "\n",
        "        # 8. Calculate Precision@K, Recall@K, NDCG@K, MRR@K\n",
        "        hybrid_precision = precision_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_recall = recall_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_ndcg = ndcg_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_mrr = mrr_at_k(hybrid_recs, actual_interactions, K)\n",
        "\n",
        "        # 9. Append scores to respective lists\n",
        "        hybrid_precision_scores.append(hybrid_precision)\n",
        "        hybrid_recall_scores.append(hybrid_recall)\n",
        "        hybrid_ndcg_scores.append(hybrid_ndcg)\n",
        "        hybrid_mrr_scores.append(hybrid_mrr)\n",
        "\n",
        "print('Hybrid Model recommendation generation and metric calculation complete for all eligible students.')\n",
        "\n",
        "# 10. Calculate and print the average Precision@K, Recall@K, NDCG@K, and MRR@K for the Hybrid Recommendation Model.\n",
        "print('\\n--- Average Evaluation Metrics for Hybrid Model ---\\n')\n",
        "\n",
        "if hybrid_precision_scores:\n",
        "    print(f\"Hybrid Model - Average Precision@{K}: {np.mean(hybrid_precision_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Average Recall@{K}: {np.mean(hybrid_recall_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Average NDCG@{K}: {np.mean(hybrid_ndcg_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Average MRR@{K}: {np.mean(hybrid_mrr_scores):.4f}\")\n",
        "else:\n",
        "    print(\"No scores calculated for Hybrid Model.\")\n",
        "\n",
        "# 11. Compare these average metrics with the baseline models.\n",
        "print('\\n--- Comparison with Baseline Models ---\\n')\n",
        "\n",
        "if most_popular_precision_scores:\n",
        "    print(f\"Most Popular Model - Average Precision@{K}: {np.mean(most_popular_precision_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Average Recall@{K}: {np.mean(most_popular_recall_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Average NDCG@{K}: {np.mean(most_popular_ndcg_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Average MRR@{K}: {np.mean(most_popular_mrr_scores):.4f}\")\n",
        "\n",
        "if cf_precision_scores:\n",
        "    print(f\"Collaborative Filtering Model - Average Precision@{K}: {np.mean(cf_precision_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Average Recall@{K}: {np.mean(cf_recall_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Average NDCG@{K}: {np.mean(cf_ndcg_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Average MRR@{K}: {np.mean(cf_mrr_scores):.4f}\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Re-generating Synthetic Dataset and Temporal Split ---\n",
            "\n",
            "Synthetic DataFrame regenerated. First 5 rows:\n",
            "   student_id  item_id interaction_type                     timestamp\n",
            "0          38       16     quiz_attempt 2023-01-01 12:11:04.192875213\n",
            "1          83       10             view 2023-01-01 13:46:52.718662151\n",
            "2          76       46           enroll 2023-01-03 00:31:27.306882205\n",
            "3          48       44     quiz_attempt 2023-01-04 03:13:44.746820379\n",
            "4          36       32           enroll 2023-01-04 07:59:47.367708069\n",
            "\n",
            "--- Temporal Train/Validation/Test Split ---\n",
            "\n",
            "Train set interactions: 800\n",
            "Validation set interactions: 100\n",
            "Test set interactions: 100\n",
            "\n",
            "--- Re-calculating Features ---\n",
            "\n",
            "User and Item features recalculated, and temporal features extracted.\n",
            "\n",
            "--- Initializing surprise.Reader and loading data ---\n",
            "\n",
            "\n",
            "`surprise.Reader` object created and trainset built.\n",
            "Number of users in trainset: 100\n",
            "Number of items in trainset: 50\n",
            "Number of interactions in trainset: 800\n",
            "\n",
            "--- Training Collaborative Filtering Model (SVD) ---\n",
            "\n",
            "SVD model trained successfully.\n",
            "\n",
            "--- Re-defining Recommendation Functions and Evaluation Metrics ---\n",
            "\n",
            "Starting evaluation for 69 unique students in the test set with K=10 for Baseline Models.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-515115319.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
            "/tmp/ipython-input-515115319.py:71: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hour_of_day'] = df['timestamp'].dt.hour\n",
            "/tmp/ipython-input-515115319.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
            "/tmp/ipython-input-515115319.py:71: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hour_of_day'] = df['timestamp'].dt.hour\n",
            "/tmp/ipython-input-515115319.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
            "/tmp/ipython-input-515115319.py:71: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hour_of_day'] = df['timestamp'].dt.hour\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Recommendation generation and metric calculation complete.\n",
            "\n",
            "--- Preparing Ranking Model Training Data ---\n",
            "\n",
            "Ranking model training data prepared.\n",
            "\n",
            "--- Training LightGBM Ranking Model ---\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 800, number of negative: 800\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 162\n",
            "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 53\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM Ranking Model trained successfully.\n",
            "\n",
            "--- Evaluating Hybrid Recommendation Model ---\n",
            "\n",
            "Starting evaluation for 69 unique students in the test set with K=10 for Hybrid Model.\n",
            "Hybrid Model recommendation generation and metric calculation complete for all eligible students.\n",
            "\n",
            "--- Average Evaluation Metrics for Hybrid Model ---\n",
            "\n",
            "Hybrid Model - Average Precision@10: 0.0362\n",
            "Hybrid Model - Average Recall@10: 0.2560\n",
            "Hybrid Model - Average NDCG@10: 0.1379\n",
            "Hybrid Model - Average MRR@10: 0.1346\n",
            "\n",
            "--- Comparison with Baseline Models ---\n",
            "\n",
            "Most Popular Model - Average Precision@10: 0.0435\n",
            "Most Popular Model - Average Recall@10: 0.2850\n",
            "Most Popular Model - Average NDCG@10: 0.1544\n",
            "Most Popular Model - Average MRR@10: 0.1455\n",
            "Collaborative Filtering Model - Average Precision@10: 0.0420\n",
            "Collaborative Filtering Model - Average Recall@10: 0.2826\n",
            "Collaborative Filtering Model - Average NDCG@10: 0.1258\n",
            "Collaborative Filtering Model - Average MRR@10: 0.0908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5ba137e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block successfully evaluated the models for Precision@K, Recall@K, NDCG@K, and MRR. Now, to complete the subtask, I need to implement coverage, novelty, and cold-start analysis, followed by qualitative error analysis. This requires iterating through the evaluation process again to collect comprehensive data on recommended items and then analyzing that data, as well as splitting evaluation metrics for cold-start students and providing examples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "bf5d6971",
        "outputId": "9b9cb599-7fec-4845-9ac6-8f85eb4193ad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Reader, Dataset, SVD\n",
        "import lightgbm as lgb\n",
        "import math\n",
        "\n",
        "print('--- Re-generating Synthetic Dataset and Temporal Split ---\\n')\n",
        "\n",
        "# 1. Re-generate Synthetic Dataset (from original cell cd481695)\n",
        "num_students = 100\n",
        "num_items = 50\n",
        "num_interactions = 1000\n",
        "\n",
        "student_ids = np.random.randint(1, num_students + 1, num_interactions)\n",
        "item_ids = np.random.randint(1, num_items + 1, num_interactions)\n",
        "interaction_types = np.random.choice(['view', 'complete', 'enroll', 'quiz_attempt', 'discuss'], num_interactions)\n",
        "\n",
        "start_date = pd.to_datetime('2023-01-01')\n",
        "end_date = pd.to_datetime('2023-12-31')\n",
        "time_range = (end_date - start_date).total_seconds()\n",
        "timestamps = start_date + pd.to_timedelta(np.random.rand(num_interactions) * time_range, unit='s')\n",
        "\n",
        "synthetic_df = pd.DataFrame({\n",
        "    'student_id': student_ids,\n",
        "    'item_id': item_ids,\n",
        "    'interaction_type': interaction_types,\n",
        "    'timestamp': timestamps\n",
        "})\n",
        "\n",
        "synthetic_df = synthetic_df.sort_values(by='timestamp').reset_index(drop=True)\n",
        "print('Synthetic DataFrame regenerated. First 5 rows:')\n",
        "print(synthetic_df.head())\n",
        "\n",
        "\n",
        "print('\\n--- Temporal Train/Validation/Test Split ---\\n')\n",
        "\n",
        "# 2. Perform Temporal Train/Validation/Test Split\n",
        "total_interactions = len(synthetic_df)\n",
        "train_size = int(0.8 * total_interactions)\n",
        "val_size = int(0.1 * total_interactions)\n",
        "test_size = total_interactions - train_size - val_size\n",
        "\n",
        "train_df = synthetic_df.iloc[:train_size].copy()\n",
        "val_df = synthetic_df.iloc[train_size : train_size + val_size].copy()\n",
        "test_df = synthetic_df.iloc[train_size + val_size :].copy()\n",
        "\n",
        "print(f\"Train set interactions: {len(train_df)}\")\n",
        "print(f\"Validation set interactions: {len(val_df)}\")\n",
        "print(f\"Test set interactions: {len(test_df)}\")\n",
        "\n",
        "print('\\n--- Re-calculating Features ---\\n')\n",
        "\n",
        "# Recalculate User Features from train_df (from cell 757f4caf)\n",
        "user_interactions = train_df.groupby('student_id').agg(\n",
        "    total_interactions_user=('item_id', 'count'),\n",
        "    unique_items_interacted=('item_id', 'nunique'),\n",
        "    most_frequent_interaction_type_user=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Recalculate Item Features from train_df (from cell 757f4caf)\n",
        "item_interactions = train_df.groupby('item_id').agg(\n",
        "    total_interactions_item=('student_id', 'count'),\n",
        "    unique_students_interacted=('student_id', 'nunique'),\n",
        "    most_frequent_interaction_type_item=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Re-extract temporal features for train_df, val_df, test_df\n",
        "for df_name in ['train_df', 'val_df', 'test_df']:\n",
        "    df = globals()[df_name]\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "    globals()[df_name] = df # Update the global dataframe\n",
        "\n",
        "print('User and Item features recalculated, and temporal features extracted.')\n",
        "\n",
        "print('\\n--- Initializing surprise.Reader and loading data ---\\n')\n",
        "\n",
        "# Create a surprise.Reader object\n",
        "reader = Reader(rating_scale=(1, 1))\n",
        "\n",
        "# Prepare the data for Surprise library\n",
        "train_df_surprise = train_df[['student_id', 'item_id']].copy()\n",
        "train_df_surprise['dummy_rating'] = 1\n",
        "\n",
        "# Load the train_df into a surprise.Dataset\n",
        "data = Dataset.load_from_df(train_df_surprise[['student_id', 'item_id', 'dummy_rating']], reader)\n",
        "\n",
        "# Build a trainset from the loaded Dataset\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "print('\\n`surprise.Reader` object created and trainset built.')\n",
        "print(f\"Number of users in trainset: {trainset.n_users}\")\n",
        "print(f\"Number of items in trainset: {trainset.n_items}\")\n",
        "print(f\"Number of interactions in trainset: {trainset.n_ratings}\")\n",
        "\n",
        "print('\\n--- Training Collaborative Filtering Model (SVD) ---\\n')\n",
        "\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "print('SVD model trained successfully.')\n",
        "\n",
        "print('\\n--- Re-defining Recommendation Functions and Evaluation Metrics ---\\n')\n",
        "\n",
        "# Re-calculate item_popularity (from cell 12886fec)\n",
        "item_popularity = train_df['item_id'].value_counts().reset_index()\n",
        "item_popularity.columns = ['item_id', 'popularity_score']\n",
        "\n",
        "# Re-define get_most_popular_recommendations function (from cell 037917a8)\n",
        "def get_most_popular_recommendations(student_id, n, historical_interactions=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "\n",
        "    recommended_items = item_popularity[~item_popularity['item_id'].isin(historical_interactions)]\n",
        "    recommended_items = recommended_items.sort_values(by='popularity_score', ascending=False)\n",
        "\n",
        "    return recommended_items.head(n)['item_id'].tolist()\n",
        "\n",
        "# Re-define get_cf_recommendations function (from cell c24f0ef6)\n",
        "def get_cf_recommendations(student_id, n, historical_interactions, model, trainset):\n",
        "    all_item_ids = synthetic_df['item_id'].unique()\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n]]\n",
        "    return top_n_items\n",
        "\n",
        "# Re-define get_actual_interactions(student_id, df)\n",
        "def get_actual_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define get_historical_interactions(student_id, df)\n",
        "def get_historical_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define precision_at_k(recommended_items, actual_items, k)\n",
        "def precision_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / k\n",
        "\n",
        "# Re-define recall_at_k(recommended_items, actual_items, k)\n",
        "def recall_at_k(recommended_items, actual_items, k):\n",
        "    if len(actual_items) == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / len(actual_items)\n",
        "\n",
        "def ndcg_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    dcg = 0.0\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            dcg += 1.0 / math.log2(i + 2)\n",
        "    idcg = 0.0\n",
        "    num_hits = min(len(actual_items), k)\n",
        "    for i in range(num_hits):\n",
        "        idcg += 1.0 / math.log2(i + 2)\n",
        "    if idcg == 0.0:\n",
        "        return 0.0\n",
        "    return dcg / idcg\n",
        "\n",
        "def mrr_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0 or not actual_items:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            return 1.0 / (i + 1)\n",
        "    return 0.0\n",
        "\n",
        "# Re-initialize lists for baseline evaluation metrics (from cell 71ff55e2)\n",
        "most_popular_precision_scores = []\n",
        "most_popular_recall_scores = []\n",
        "most_popular_ndcg_scores = []\n",
        "most_popular_mrr_scores = []\n",
        "\n",
        "cf_precision_scores = []\n",
        "cf_recall_scores = []\n",
        "cf_ndcg_scores = []\n",
        "cf_mrr_scores = []\n",
        "\n",
        "# Initialize lists for coverage and novelty (popularity) tracking\n",
        "all_mp_recs_items = set()\n",
        "all_cf_recs_items = set()\n",
        "all_hybrid_recs_items = set()\n",
        "\n",
        "mp_recommended_popularities = []\n",
        "cf_recommended_popularities = []\n",
        "hybrid_recommended_popularities = []\n",
        "\n",
        "# Initialize lists for cold-start metrics\n",
        "cold_start_mp_precision = []\n",
        "cold_start_mp_recall = []\n",
        "cold_start_mp_ndcg = []\n",
        "cold_start_mp_mrr = []\n",
        "\n",
        "cold_start_cf_precision = []\n",
        "cold_start_cf_recall = []\n",
        "cold_start_cf_ndcg = []\n",
        "cold_start_cf_mrr = []\n",
        "\n",
        "cold_start_hybrid_precision = []\n",
        "cold_start_hybrid_recall = []\n",
        "cold_start_hybrid_ndcg = []\n",
        "cold_start_hybrid_mrr = []\n",
        "\n",
        "\n",
        "# Set the value for K for Precision@K and Recall@K\n",
        "K = 10\n",
        "\n",
        "# Get all unique student_ids from the test set for baseline evaluation\n",
        "unique_test_students = test_df['student_id'].unique()\n",
        "\n",
        "# Identify cold-start students (defined in EDA as < 5 interactions)\n",
        "cold_start_student_ids = []\n",
        "interactions_per_student_in_train = train_df['student_id'].value_counts()\n",
        "cold_start_student_ids = interactions_per_student_in_train[interactions_per_student_in_train < 5].index.tolist()\n",
        "\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students)} unique students in the test set with K={K} for all Models.\")\n",
        "\n",
        "# Get the feature columns that the ranking model was trained on\n",
        "ranking_model_features = X.columns.tolist() # X is from the ranking model training\n",
        "\n",
        "# Re-define candidate generation function to use updated global synthetic_df\n",
        "def generate_candidates_for_user(student_id, model, n_candidates=50, historical_interactions=None, all_item_ids=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "    if all_item_ids is None:\n",
        "        all_item_ids = synthetic_df['item_id'].unique() # Ensure synthetic_df is available globally\n",
        "\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n_candidates]]\n",
        "    return top_n_items\n",
        "\n",
        "\n",
        "for student_id in unique_test_students:\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    if len(actual_interactions) > 0:\n",
        "        # Generate recommendations for all models\n",
        "        most_popular_recs = get_most_popular_recommendations(student_id, K, historical_interactions)\n",
        "        cf_recs = get_cf_recommendations(student_id, K, historical_interactions, algo, trainset)\n",
        "\n",
        "        # Hybrid Model Recommendation Generation\n",
        "        candidates = generate_candidates_for_user(student_id, algo, n_candidates=50, historical_interactions=historical_interactions, all_item_ids=synthetic_df['item_id'].unique())\n",
        "\n",
        "        hybrid_recs = []\n",
        "        if candidates:\n",
        "            candidate_data = []\n",
        "            for item_id in candidates:\n",
        "                user_feat = user_interactions[user_interactions['student_id'] == student_id]\n",
        "                if user_feat.empty:\n",
        "                    continue\n",
        "                user_feat = user_feat.iloc[0]\n",
        "\n",
        "                item_feat = item_interactions[item_interactions['item_id'] == item_id]\n",
        "                if item_feat.empty:\n",
        "                    continue\n",
        "                item_feat = item_feat.iloc[0]\n",
        "\n",
        "                student_test_interactions = test_df[test_df['student_id'] == student_id]\n",
        "                representative_day_of_week = student_test_interactions['day_of_week'].iloc[0] if not student_test_interactions.empty else -1\n",
        "                representative_hour_of_day = student_test_interactions['hour_of_day'].iloc[0] if not student_test_interactions.empty else -1\n",
        "\n",
        "                temp_data = {\n",
        "                    'student_id': student_id,\n",
        "                    'item_id': item_id,\n",
        "                    'interaction_type': 'unknown',\n",
        "                    'day_of_week': representative_day_of_week,\n",
        "                    'hour_of_day': representative_hour_of_day,\n",
        "                }\n",
        "                temp_data.update(user_feat.drop('student_id').to_dict())\n",
        "                temp_data.update(item_feat.drop('item_id').to_dict())\n",
        "                candidate_data.append(temp_data)\n",
        "\n",
        "            if candidate_data:\n",
        "                candidate_df = pd.DataFrame(candidate_data)\n",
        "\n",
        "                for col in ['day_of_week', 'hour_of_day']:\n",
        "                    if col in candidate_df.columns:\n",
        "                        candidate_df[col] = candidate_df[col].fillna(-1).astype(int)\n",
        "\n",
        "                for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "                    if col in candidate_df.columns:\n",
        "                        candidate_df[col] = candidate_df[col].fillna('unknown')\n",
        "\n",
        "                candidate_df_encoded = pd.get_dummies(candidate_df, columns=categorical_features, dummy_na=False)\n",
        "\n",
        "                missing_cols = set(ranking_model_features) - set(candidate_df_encoded.columns)\n",
        "                for c in missing_cols:\n",
        "                    candidate_df_encoded[c] = False\n",
        "                extra_cols = set(candidate_df_encoded.columns) - set(ranking_model_features)\n",
        "                candidate_df_encoded = candidate_df_encoded.drop(columns=list(extra_cols))\n",
        "\n",
        "                candidate_features_for_prediction = candidate_df_encoded[ranking_model_features]\n",
        "                predictions = ranking_model.predict_proba(candidate_features_for_prediction)[:, 1]\n",
        "\n",
        "                ranked_candidates = pd.DataFrame({\n",
        "                    'item_id': candidate_df['item_id'],\n",
        "                    'predicted_score': predictions\n",
        "                })\n",
        "                ranked_candidates = ranked_candidates.sort_values(by='predicted_score', ascending=False)\n",
        "                hybrid_recs = ranked_candidates.head(K)['item_id'].tolist()\n",
        "\n",
        "        # Calculate and store metrics for all models\n",
        "        mp_precision = precision_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_recall = recall_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_ndcg = ndcg_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_mrr = mrr_at_k(most_popular_recs, actual_interactions, K)\n",
        "\n",
        "        cf_precision = precision_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_recall = recall_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_ndcg = ndcg_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_mrr = mrr_at_k(cf_recs, actual_interactions, K)\n",
        "\n",
        "        hybrid_precision = precision_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_recall = recall_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_ndcg = ndcg_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_mrr = mrr_at_k(hybrid_recs, actual_interactions, K)\n",
        "\n",
        "        most_popular_precision_scores.append(mp_precision)\n",
        "        most_popular_recall_scores.append(mp_recall)\n",
        "        most_popular_ndcg_scores.append(mp_ndcg)\n",
        "        most_popular_mrr_scores.append(mp_mrr)\n",
        "\n",
        "        cf_precision_scores.append(cf_precision)\n",
        "        cf_recall_scores.append(cf_recall)\n",
        "        cf_ndcg_scores.append(cf_ndcg)\n",
        "        cf_mrr_scores.append(cf_mrr)\n",
        "\n",
        "        hybrid_precision_scores.append(hybrid_precision)\n",
        "        hybrid_recall_scores.append(hybrid_recall)\n",
        "        hybrid_ndcg_scores.append(hybrid_ndcg)\n",
        "        hybrid_mrr_scores.append(hybrid_mrr)\n",
        "\n",
        "        # Collect items for Coverage\n",
        "        all_mp_recs_items.update(most_popular_recs)\n",
        "        all_cf_recs_items.update(cf_recs)\n",
        "        all_hybrid_recs_items.update(hybrid_recs)\n",
        "\n",
        "        # Collect popularity scores for Novelty (using popularity as a proxy - lower average popularity is higher novelty)\n",
        "        for item_id in most_popular_recs:\n",
        "            popularity = item_popularity[item_popularity['item_id'] == item_id]['popularity_score'].iloc[0]\n",
        "            mp_recommended_popularities.append(popularity)\n",
        "        for item_id in cf_recs:\n",
        "            popularity = item_popularity[item_popularity['item_id'] == item_id]['popularity_score'].iloc[0]\n",
        "            cf_recommended_popularities.append(popularity)\n",
        "        for item_id in hybrid_recs:\n",
        "            popularity = item_popularity[item_popularity['item_id'] == item_id]['popularity_score'].iloc[0]\n",
        "            hybrid_recommended_popularities.append(popularity)\n",
        "\n",
        "        # Store cold-start metrics\n",
        "        if student_id in cold_start_student_ids:\n",
        "            cold_start_mp_precision.append(mp_precision)\n",
        "            cold_start_mp_recall.append(mp_recall)\n",
        "            cold_start_mp_ndcg.append(mp_ndcg)\n",
        "            cold_start_mp_mrr.append(mp_mrr)\n",
        "\n",
        "            cold_start_cf_precision.append(cf_precision)\n",
        "            cold_start_cf_recall.append(cf_recall)\n",
        "            cold_start_cf_ndcg.append(cf_ndcg)\n",
        "            cold_start_cf_mrr.append(cf_mrr)\n",
        "\n",
        "            cold_start_hybrid_precision.append(hybrid_precision)\n",
        "            cold_start_hybrid_recall.append(hybrid_recall)\n",
        "            cold_start_hybrid_ndcg.append(hybrid_ndcg)\n",
        "            cold_start_hybrid_mrr.append(hybrid_mrr)\n",
        "\n",
        "print('Recommendation generation and metric collection complete for all eligible students.\\n')\n",
        "\n",
        "print('--- Overall Average Evaluation Metrics ---\\n')\n",
        "\n",
        "if most_popular_precision_scores:\n",
        "    print(f\"Most Popular Model - Avg Precision@{K}: {np.mean(most_popular_precision_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Avg Recall@{K}: {np.mean(most_popular_recall_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Avg NDCG@{K}: {np.mean(most_popular_ndcg_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Avg MRR@{K}: {np.mean(most_popular_mrr_scores):.4f}\\n\")\n",
        "\n",
        "if cf_precision_scores:\n",
        "    print(f\"Collaborative Filtering Model - Avg Precision@{K}: {np.mean(cf_precision_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Avg Recall@{K}: {np.mean(cf_recall_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Avg NDCG@{K}: {np.mean(cf_ndcg_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Avg MRR@{K}: {np.mean(cf_mrr_scores):.4f}\\n\")\n",
        "\n",
        "if hybrid_precision_scores:\n",
        "    print(f\"Hybrid Model - Avg Precision@{K}: {np.mean(hybrid_precision_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Avg Recall@{K}: {np.mean(hybrid_recall_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Avg NDCG@{K}: {np.mean(hybrid_ndcg_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Avg MRR@{K}: {np.mean(hybrid_mrr_scores):.4f}\\n\")\n",
        "\n",
        "print('--- Coverage Analysis ---\\n')\n",
        "\n",
        "total_unique_items_in_system = synthetic_df['item_id'].nunique()\n",
        "\n",
        "mp_coverage = len(all_mp_recs_items) / total_unique_items_in_system\n",
        "cf_coverage = len(all_cf_recs_items) / total_unique_items_in_system\n",
        "hybrid_coverage = len(all_hybrid_recs_items) / total_unique_items_in_system\n",
        "\n",
        "print(f\"Most Popular Model - Coverage: {mp_coverage:.4f}\")\n",
        "print(f\"Collaborative Filtering Model - Coverage: {cf_coverage:.4f}\")\n",
        "print(f\"Hybrid Model - Coverage: {hybrid_coverage:.4f}\\n\")\n",
        "\n",
        "print('--- Novelty Analysis (Average Popularity of Recommended Items - Lower is more novel) ---\\n')\n",
        "\n",
        "if mp_recommended_popularities:\n",
        "    print(f\"Most Popular Model - Avg Popularity of Recommended Items: {np.mean(mp_recommended_popularities):.2f}\")\n",
        "if cf_recommended_popularities:\n",
        "    print(f\"Collaborative Filtering Model - Avg Popularity of Recommended Items: {np.mean(cf_recommended_popularities):.2f}\")\n",
        "if hybrid_recommended_popularities:\n",
        "    print(f\"Hybrid Model - Avg Popularity of Recommended Items: {np.mean(hybrid_recommended_popularities):.2f}\\n\")\n",
        "\n",
        "print('--- Cold-Start Student Analysis ---\\n')\n",
        "\n",
        "if cold_start_mp_precision:\n",
        "    print(f\"Most Popular Model (Cold-Start) - Avg Precision@{K}: {np.mean(cold_start_mp_precision):.4f}\")\n",
        "    print(f\"Most Popular Model (Cold-Start) - Avg Recall@{K}: {np.mean(cold_start_mp_recall):.4f}\")\n",
        "    print(f\"Most Popular Model (Cold-Start) - Avg NDCG@{K}: {np.mean(cold_start_mp_ndcg):.4f}\")\n",
        "    print(f\"Most Popular Model (Cold-Start) - Avg MRR@{K}: {np.mean(cold_start_mp_mrr):.4f}\\n\")\n",
        "else:\n",
        "    print(\"No cold-start students found for Most Popular Model evaluation.\\n\")\n",
        "\n",
        "if cold_start_cf_precision:\n",
        "    print(f\"Collaborative Filtering Model (Cold-Start) - Avg Precision@{K}: {np.mean(cold_start_cf_precision):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model (Cold-Start) - Avg Recall@{K}: {np.mean(cold_start_cf_recall):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model (Cold-Start) - Avg NDCG@{K}: {np.mean(cold_start_cf_ndcg):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model (Cold-Start) - Avg MRR@{K}: {np.mean(cold_start_cf_mrr):.4f}\\n\")\n",
        "else:\n",
        "    print(\"No cold-start students found for Collaborative Filtering Model evaluation.\\n\")\n",
        "\n",
        "if cold_start_hybrid_precision:\n",
        "    print(f\"Hybrid Model (Cold-Start) - Avg Precision@{K}: {np.mean(cold_start_hybrid_precision):.4f}\")\n",
        "    print(f\"Hybrid Model (Cold-Start) - Avg Recall@{K}: {np.mean(cold_start_hybrid_recall):.4f}\")\n",
        "    print(f\"Hybrid Model (Cold-Start) - Avg NDCG@{K}: {np.mean(cold_start_hybrid_ndcg):.4f}\")\n",
        "    print(f\"Hybrid Model (Cold-Start) - Avg MRR@{K}: {np.mean(cold_start_hybrid_mrr):.4f}\\n\")\n",
        "else:\n",
        "    print(\"No cold-start students found for Hybrid Model evaluation.\\n\")\n",
        "\n",
        "print('--- Qualitative Error Analysis Examples ---\\n')\n",
        "\n",
        "# Find a student with poor performance (e.g., CF recall is 0)\n",
        "poor_cf_student_id = None\n",
        "for i, student_id in enumerate(unique_test_students):\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "    if len(actual_interactions) > 0:\n",
        "        cf_recs_for_student = get_cf_recommendations(student_id, K, get_historical_interactions(student_id, train_df), algo, trainset)\n",
        "        if recall_at_k(cf_recs_for_student, actual_interactions, K) == 0:\n",
        "            poor_cf_student_id = student_id\n",
        "            break\n",
        "\n",
        "# Find a student with good performance (e.g., CF recall is high)\n",
        "good_cf_student_id = None\n",
        "for i, student_id in enumerate(unique_test_students):\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "    if len(actual_interactions) > 0:\n",
        "        cf_recs_for_student = get_cf_recommendations(student_id, K, get_historical_interactions(student_id, train_df), algo, trainset)\n",
        "        if recall_at_k(cf_recs_for_student, actual_interactions, K) > 0.5: # Arbitrarily high recall\n",
        "            good_cf_student_id = student_id\n",
        "            break\n",
        "\n",
        "if poor_cf_student_id is not None:\n",
        "    print(f\"Example of Poor Performance (Student ID: {poor_cf_student_id}):\")\n",
        "    historical_interactions_poor = get_historical_interactions(poor_cf_student_id, train_df)\n",
        "    actual_interactions_poor = get_actual_interactions(poor_cf_student_id, test_df)\n",
        "\n",
        "    mp_recs_poor = get_most_popular_recommendations(poor_cf_student_id, K, historical_interactions_poor)\n",
        "    cf_recs_poor = get_cf_recommendations(poor_cf_student_id, K, historical_interactions_poor, algo, trainset)\n",
        "\n",
        "    # Generate Hybrid recs for the poor student\n",
        "    hybrid_recs_poor = []\n",
        "    candidates_poor = generate_candidates_for_user(poor_cf_student_id, algo, n_candidates=50, historical_interactions=historical_interactions_poor, all_item_ids=synthetic_df['item_id'].unique())\n",
        "    if candidates_poor:\n",
        "        candidate_data_poor = []\n",
        "        for item_id in candidates_poor:\n",
        "            user_feat_poor = user_interactions[user_interactions['student_id'] == poor_cf_student_id]\n",
        "            if user_feat_poor.empty: continue\n",
        "            user_feat_poor = user_feat_poor.iloc[0]\n",
        "\n",
        "            item_feat_poor = item_interactions[item_interactions['item_id'] == item_id]\n",
        "            if item_feat_poor.empty: continue\n",
        "            item_feat_poor = item_feat_poor.iloc[0]\n",
        "\n",
        "            student_test_interactions_poor = test_df[test_df['student_id'] == poor_cf_student_id]\n",
        "            representative_day_of_week_poor = student_test_interactions_poor['day_of_week'].iloc[0] if not student_test_interactions_poor.empty else -1\n",
        "            representative_hour_of_day_poor = student_test_interactions_poor['hour_of_day'].iloc[0] if not student_test_interactions_poor.empty else -1\n",
        "\n",
        "            temp_data_poor = {\n",
        "                'student_id': poor_cf_student_id,\n",
        "                'item_id': item_id,\n",
        "                'interaction_type': 'unknown',\n",
        "                'day_of_week': representative_day_of_week_poor,\n",
        "                'hour_of_day': representative_hour_of_day_poor,\n",
        "            }\n",
        "            temp_data_poor.update(user_feat_poor.drop('student_id').to_dict())\n",
        "            temp_data_poor.update(item_feat_poor.drop('item_id').to_dict())\n",
        "            candidate_data_poor.append(temp_data_poor)\n",
        "\n",
        "        if candidate_data_poor:\n",
        "            candidate_df_poor = pd.DataFrame(candidate_data_poor)\n",
        "            for col in ['day_of_week', 'hour_of_day']:\n",
        "                if col in candidate_df_poor.columns: candidate_df_poor[col] = candidate_df_poor[col].fillna(-1).astype(int)\n",
        "            for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "                if col in candidate_df_poor.columns: candidate_df_poor[col] = candidate_df_poor[col].fillna('unknown')\n",
        "            candidate_df_encoded_poor = pd.get_dummies(candidate_df_poor, columns=categorical_features, dummy_na=False)\n",
        "            missing_cols_poor = set(ranking_model_features) - set(candidate_df_encoded_poor.columns)\n",
        "            for c in missing_cols_poor: candidate_df_encoded_poor[c] = False\n",
        "            extra_cols_poor = set(candidate_df_encoded_poor.columns) - set(ranking_model_features)\n",
        "            candidate_df_encoded_poor = candidate_df_encoded_poor.drop(columns=list(extra_cols_poor))\n",
        "            candidate_features_for_prediction_poor = candidate_df_encoded_poor[ranking_model_features]\n",
        "            predictions_poor = ranking_model.predict_proba(candidate_features_for_prediction_poor)[:, 1]\n",
        "            ranked_candidates_poor = pd.DataFrame({\n",
        "                'item_id': candidate_df_poor['item_id'],\n",
        "                'predicted_score': predictions_poor\n",
        "            })\n",
        "            ranked_candidates_poor = ranked_candidates_poor.sort_values(by='predicted_score', ascending=False)\n",
        "            hybrid_recs_poor = ranked_candidates_poor.head(K)['item_id'].tolist()\n",
        "\n",
        "    print(f\"  Historical Interactions: {historical_interactions_poor}\")\n",
        "    print(f\"  Actual Interactions in Test Set: {actual_interactions_poor}\")\n",
        "    print(f\"  Most Popular Recommendations: {mp_recs_poor}\")\n",
        "    print(f\"  Collaborative Filtering Recommendations: {cf_recs_poor}\")\n",
        "    print(f\"  Hybrid Recommendations: {hybrid_recs_poor}\\n\")\n",
        "\n",
        "if good_cf_student_id is not None:\n",
        "    print(f\"Example of Good Performance (Student ID: {good_cf_student_id}):\")\n",
        "    historical_interactions_good = get_historical_interactions(good_cf_student_id, train_df)\n",
        "    actual_interactions_good = get_actual_interactions(good_cf_student_id, test_df)\n",
        "\n",
        "    mp_recs_good = get_most_popular_recommendations(good_cf_student_id, K, historical_interactions_good)\n",
        "    cf_recs_good = get_cf_recommendations(good_cf_student_id, K, historical_interactions_good, algo, trainset)\n",
        "\n",
        "    # Generate Hybrid recs for the good student\n",
        "    hybrid_recs_good = []\n",
        "    candidates_good = generate_candidates_for_user(good_cf_student_id, algo, n_candidates=50, historical_interactions=historical_interactions_good, all_item_ids=synthetic_df['item_id'].unique())\n",
        "    if candidates_good:\n",
        "        candidate_data_good = []\n",
        "        for item_id in candidates_good:\n",
        "            user_feat_good = user_interactions[user_interactions['student_id'] == good_cf_student_id]\n",
        "            if user_feat_good.empty: continue\n",
        "            user_feat_good = user_feat_good.iloc[0]\n",
        "\n",
        "            item_feat_good = item_interactions[item_interactions['item_id'] == item_id]\n",
        "            if item_feat_good.empty: continue\n",
        "            item_feat_good = item_feat_good.iloc[0]\n",
        "\n",
        "            student_test_interactions_good = test_df[test_df['student_id'] == good_cf_student_id]\n",
        "            representative_day_of_week_good = student_test_interactions_good['day_of_week'].iloc[0] if not student_test_interactions_good.empty else -1\n",
        "            representative_hour_of_day_good = student_test_interactions_good['hour_of_day'].iloc[0] if not student_test_interactions_good.empty else -1\n",
        "\n",
        "            temp_data_good =\n",
        "             { 'student_id': good_cf_student_id,\n",
        "                'item_id': item_id,\n",
        "                'interaction_type': 'unknown'\n",
        "                'day_of_week': representative_day_of_week_good,\n",
        "                'hour_of_day': representative_hour_of_day_good,\n",
        "            }\n",
        "            temp_data_good.update(user_feat_good.drop('student_id').to_dict())\n",
        "            temp_data_good.update(item_feat_good.drop('item_id').to_dict())\n",
        "            candidate_data_good.append(temp_data_good)\n",
        "\n",
        "        if candidate_data_good:\n",
        "            candidate_df_good = pd.DataFrame(candidate_data_good)\n",
        "            for col in ['day_of_week', 'hour_of_day']:\n",
        "                if col in candidate_df_good.columns: candidate_df_good[col] = candidate_df_good[col].fillna(-1).astype(int)\n",
        "            for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "                if col in candidate_df_good.columns: candidate_df_good[col] = candidate_df_good[col].fillna('unknown')\n",
        "            candidate_df_encoded_good = pd.get_dummies(candidate_df_good, columns=categorical_features, dummy_na=False)\n",
        "            missing_cols_good = set(ranking_model_features) - set(candidate_df_encoded_good.columns)\n",
        "            for c in missing_cols_good: candidate_df_encoded_good[c] = False\n",
        "            extra_cols_good = set(candidate_df_encoded_good.columns) - set(ranking_model_features)\n",
        "            candidate_df_encoded_good = candidate_df_encoded_good.drop(columns=list(extra_cols_good))\n",
        "            candidate_features_for_prediction_good = candidate_df_encoded_good[ranking_model_features]\n",
        "            predictions_good = ranking_model.predict_proba(candidate_features_for_prediction_good)[:, 1]\n",
        "            ranked_candidates_good = pd.DataFrame({\n",
        "                'item_id': candidate_df_good['item_id'],\n",
        "                'predicted_score': predictions_good\n",
        "            })\n",
        "            ranked_candidates_good = ranked_candidates_good.sort_values(by='predicted_score', ascending=False)\n",
        "            hybrid_recs_good = ranked_candidates_good.head(K)['item_id'].tolist()\n",
        "\n",
        "    print(f\"  Historical Interactions: {historical_interactions_good}\")\n",
        "    print(f\"  Actual Interactions in Test Set: {actual_interactions_good}\")\n",
        "    print(f\"  Most Popular Recommendations: {mp_recs_good}\")\n",
        "    print(f\"  Collaborative Filtering Recommendations: {cf_recs_good}\")\n",
        "    print(f\"  Hybrid Recommendations: {hybrid_recs_good}\\n\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1783122861.py, line 567)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1783122861.py\"\u001b[0;36m, line \u001b[0;32m567\u001b[0m\n\u001b[0;31m    temp_data_good =\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e0d9867"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to a `SyntaxError: unterminated string literal`. I will correct the typo in the `temp_data_good` dictionary definition by fixing `''interaction_type'` to `'interaction_type'` to resolve the syntax error and allow the comprehensive evaluation to proceed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba71e3e2",
        "outputId": "91abf09f-4c8b-41de-b135-d8c16907400e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Reader, Dataset, SVD\n",
        "import lightgbm as lgb\n",
        "import math\n",
        "\n",
        "print('--- Re-generating Synthetic Dataset and Temporal Split ---\\n')\n",
        "\n",
        "# 1. Re-generate Synthetic Dataset (from original cell cd481695)\n",
        "num_students = 100\n",
        "num_items = 50\n",
        "num_interactions = 1000\n",
        "\n",
        "student_ids = np.random.randint(1, num_students + 1, num_interactions)\n",
        "item_ids = np.random.randint(1, num_items + 1, num_interactions)\n",
        "interaction_types = np.random.choice(['view', 'complete', 'enroll', 'quiz_attempt', 'discuss'], num_interactions)\n",
        "\n",
        "start_date = pd.to_datetime('2023-01-01')\n",
        "end_date = pd.to_datetime('2023-12-31')\n",
        "time_range = (end_date - start_date).total_seconds()\n",
        "timestamps = start_date + pd.to_timedelta(np.random.rand(num_interactions) * time_range, unit='s')\n",
        "\n",
        "synthetic_df = pd.DataFrame({\n",
        "    'student_id': student_ids,\n",
        "    'item_id': item_ids,\n",
        "    'interaction_type': interaction_types,\n",
        "    'timestamp': timestamps\n",
        "})\n",
        "\n",
        "synthetic_df = synthetic_df.sort_values(by='timestamp').reset_index(drop=True)\n",
        "print('Synthetic DataFrame regenerated. First 5 rows:')\n",
        "print(synthetic_df.head())\n",
        "\n",
        "\n",
        "print('\\n--- Temporal Train/Validation/Test Split ---\\n')\n",
        "\n",
        "# 2. Perform Temporal Train/Validation/Test Split\n",
        "total_interactions = len(synthetic_df)\n",
        "train_size = int(0.8 * total_interactions)\n",
        "val_size = int(0.1 * total_interactions)\n",
        "test_size = total_interactions - train_size - val_size\n",
        "\n",
        "train_df = synthetic_df.iloc[:train_size].copy()\n",
        "val_df = synthetic_df.iloc[train_size : train_size + val_size].copy()\n",
        "test_df = synthetic_df.iloc[train_size + val_size :].copy()\n",
        "\n",
        "print(f\"Train set interactions: {len(train_df)}\")\n",
        "print(f\"Validation set interactions: {len(val_df)}\")\n",
        "print(f\"Test set interactions: {len(test_df)}\")\n",
        "\n",
        "print('\\n--- Re-calculating Features ---\\n')\n",
        "\n",
        "# Recalculate User Features from train_df (from cell 757f4caf)\n",
        "user_interactions = train_df.groupby('student_id').agg(\n",
        "    total_interactions_user=('item_id', 'count'),\n",
        "    unique_items_interacted=('item_id', 'nunique'),\n",
        "    most_frequent_interaction_type_user=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Recalculate Item Features from train_df (from cell 757f4caf)\n",
        "item_interactions = train_df.groupby('item_id').agg(\n",
        "    total_interactions_item=('student_id', 'count'),\n",
        "    unique_students_interacted=('student_id', 'nunique'),\n",
        "    most_frequent_interaction_type_item=('interaction_type', lambda x: x.mode()[0] if not x.mode().empty else 'None')\n",
        ").reset_index()\n",
        "\n",
        "# Re-extract temporal features for train_df, val_df, test_df\n",
        "for df_name in ['train_df', 'val_df', 'test_df']:\n",
        "    df = globals()[df_name]\n",
        "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
        "    globals()[df_name] = df # Update the global dataframe\n",
        "\n",
        "print('User and Item features recalculated, and temporal features extracted.')\n",
        "\n",
        "print('\\n--- Initializing surprise.Reader and loading data ---\\n')\n",
        "\n",
        "# Create a surprise.Reader object\n",
        "reader = Reader(rating_scale=(1, 1))\n",
        "\n",
        "# Prepare the data for Surprise library\n",
        "train_df_surprise = train_df[['student_id', 'item_id']].copy()\n",
        "train_df_surprise['dummy_rating'] = 1\n",
        "\n",
        "# Load the train_df into a surprise.Dataset\n",
        "data = Dataset.load_from_df(train_df_surprise[['student_id', 'item_id', 'dummy_rating']], reader)\n",
        "\n",
        "# Build a trainset from the loaded Dataset\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "print('\\n`surprise.Reader` object created and trainset built.')\n",
        "print(f\"Number of users in trainset: {trainset.n_users}\")\n",
        "print(f\"Number of items in trainset: {trainset.n_items}\")\n",
        "print(f\"Number of interactions in trainset: {trainset.n_ratings}\")\n",
        "\n",
        "print('\\n--- Training Collaborative Filtering Model (SVD) ---\\n')\n",
        "\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "print('SVD model trained successfully.')\n",
        "\n",
        "print('\\n--- Re-defining Recommendation Functions and Evaluation Metrics ---\\n')\n",
        "\n",
        "# Re-calculate item_popularity (from cell 12886fec)\n",
        "item_popularity = train_df['item_id'].value_counts().reset_index()\n",
        "item_popularity.columns = ['item_id', 'popularity_score']\n",
        "\n",
        "# Re-define get_most_popular_recommendations function (from cell 037917a8)\n",
        "def get_most_popular_recommendations(student_id, n, historical_interactions=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "\n",
        "    recommended_items = item_popularity[~item_popularity['item_id'].isin(historical_interactions)]\n",
        "    recommended_items = recommended_items.sort_values(by='popularity_score', ascending=False)\n",
        "\n",
        "    return recommended_items.head(n)['item_id'].tolist()\n",
        "\n",
        "# Re-define get_cf_recommendations function (from cell c24f0ef6)\n",
        "def get_cf_recommendations(student_id, n, historical_interactions, model, trainset):\n",
        "    all_item_ids = synthetic_df['item_id'].unique()\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n]]\n",
        "    return top_n_items\n",
        "\n",
        "# Re-define get_actual_interactions(student_id, df)\n",
        "def get_actual_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define get_historical_interactions(student_id, df)\n",
        "def get_historical_interactions(student_id, df):\n",
        "    return set(df[df['student_id'] == student_id]['item_id'].unique())\n",
        "\n",
        "# Re-define precision_at_k(recommended_items, actual_items, k)\n",
        "def precision_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / k\n",
        "\n",
        "# Re-define recall_at_k(recommended_items, actual_items, k)\n",
        "def recall_at_k(recommended_items, actual_items, k):\n",
        "    if len(actual_items) == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    hits = len(set(recommended_at_k) & actual_items)\n",
        "    return hits / len(actual_items)\n",
        "\n",
        "def ndcg_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    dcg = 0.0\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            dcg += 1.0 / math.log2(i + 2)\n",
        "    idcg = 0.0\n",
        "    num_hits = min(len(actual_items), k)\n",
        "    for i in range(num_hits):\n",
        "        idcg += 1.0 / math.log2(i + 2)\n",
        "    if idcg == 0.0:\n",
        "        return 0.0\n",
        "    return dcg / idcg\n",
        "\n",
        "def mrr_at_k(recommended_items, actual_items, k):\n",
        "    if k == 0 or not actual_items:\n",
        "        return 0.0\n",
        "    recommended_at_k = recommended_items[:k]\n",
        "    for i, item_id in enumerate(recommended_at_k):\n",
        "        if item_id in actual_items:\n",
        "            return 1.0 / (i + 1)\n",
        "    return 0.0\n",
        "\n",
        "# Re-initialize lists for baseline evaluation metrics (from cell 71ff55e2)\n",
        "most_popular_precision_scores = []\n",
        "most_popular_recall_scores = []\n",
        "most_popular_ndcg_scores = []\n",
        "most_popular_mrr_scores = []\n",
        "\n",
        "cf_precision_scores = []\n",
        "cf_recall_scores = []\n",
        "cf_ndcg_scores = []\n",
        "cf_mrr_scores = []\n",
        "\n",
        "# Initialize lists for coverage and novelty (popularity) tracking\n",
        "all_mp_recs_items = set()\n",
        "all_cf_recs_items = set()\n",
        "all_hybrid_recs_items = set()\n",
        "\n",
        "mp_recommended_popularities = []\n",
        "cf_recommended_popularities = []\n",
        "hybrid_recommended_popularities = []\n",
        "\n",
        "# Initialize lists for cold-start metrics\n",
        "cold_start_mp_precision = []\n",
        "cold_start_mp_recall = []\n",
        "cold_start_mp_ndcg = []\n",
        "cold_start_mp_mrr = []\n",
        "\n",
        "cold_start_cf_precision = []\n",
        "cold_start_cf_recall = []\n",
        "cold_start_cf_ndcg = []\n",
        "cold_start_cf_mrr = []\n",
        "\n",
        "cold_start_hybrid_precision = []\n",
        "cold_start_hybrid_recall = []\n",
        "cold_start_hybrid_ndcg = []\n",
        "cold_start_hybrid_mrr = []\n",
        "\n",
        "\n",
        "# Set the value for K for Precision@K and Recall@K\n",
        "K = 10\n",
        "\n",
        "# Get all unique student_ids from the test set for baseline evaluation\n",
        "unique_test_students = test_df['student_id'].unique()\n",
        "\n",
        "# Identify cold-start students (defined in EDA as < 5 interactions)\n",
        "cold_start_student_ids = []\n",
        "interactions_per_student_in_train = train_df['student_id'].value_counts()\n",
        "cold_start_student_ids = interactions_per_student_in_train[interactions_per_student_in_train < 5].index.tolist()\n",
        "\n",
        "\n",
        "print(f\"Starting evaluation for {len(unique_test_students)} unique students in the test set with K={K} for all Models.\")\n",
        "\n",
        "# Get the feature columns that the ranking model was trained on\n",
        "ranking_model_features = X.columns.tolist() # X is from the ranking model training\n",
        "\n",
        "# Re-define candidate generation function to use updated global synthetic_df\n",
        "def generate_candidates_for_user(student_id, model, n_candidates=50, historical_interactions=None, all_item_ids=None):\n",
        "    if historical_interactions is None:\n",
        "        historical_interactions = set()\n",
        "    if all_item_ids is None:\n",
        "        all_item_ids = synthetic_df['item_id'].unique() # Ensure synthetic_df is available globally\n",
        "\n",
        "    items_to_predict = [item_id for item_id in all_item_ids if item_id not in historical_interactions]\n",
        "\n",
        "    predictions = []\n",
        "    for item_id in items_to_predict:\n",
        "        predictions.append(model.predict(student_id, item_id, r_ui=1))\n",
        "\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_n_items = [pred.iid for pred in predictions[:n_candidates]]\n",
        "    return top_n_items\n",
        "\n",
        "\n",
        "for student_id in unique_test_students:\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "\n",
        "    if len(actual_interactions) > 0:\n",
        "        # Generate recommendations for all models\n",
        "        most_popular_recs = get_most_popular_recommendations(student_id, K, historical_interactions)\n",
        "        cf_recs = get_cf_recommendations(student_id, K, historical_interactions, algo, trainset)\n",
        "\n",
        "        # Hybrid Model Recommendation Generation\n",
        "        candidates = generate_candidates_for_user(student_id, algo, n_candidates=50, historical_interactions=historical_interactions, all_item_ids=synthetic_df['item_id'].unique())\n",
        "\n",
        "        hybrid_recs = []\n",
        "        if candidates:\n",
        "            candidate_data = []\n",
        "            for item_id in candidates:\n",
        "                user_feat = user_interactions[user_interactions['student_id'] == student_id]\n",
        "                if user_feat.empty:\n",
        "                    continue\n",
        "                user_feat = user_feat.iloc[0]\n",
        "\n",
        "                item_feat = item_interactions[item_interactions['item_id'] == item_id]\n",
        "                if item_feat.empty:\n",
        "                    continue\n",
        "                item_feat = item_feat.iloc[0]\n",
        "\n",
        "                student_test_interactions = test_df[test_df['student_id'] == student_id]\n",
        "                representative_day_of_week = student_test_interactions['day_of_week'].iloc[0] if not student_test_interactions.empty else -1\n",
        "                representative_hour_of_day = student_test_interactions['hour_of_day'].iloc[0] if not student_test_interactions.empty else -1\n",
        "\n",
        "                temp_data = {\n",
        "                    'student_id': student_id,\n",
        "                    'item_id': item_id,\n",
        "                    'interaction_type': 'unknown',\n",
        "                    'day_of_week': representative_day_of_week,\n",
        "                    'hour_of_day': representative_hour_of_day,\n",
        "                }\n",
        "                temp_data.update(user_feat.drop('student_id').to_dict())\n",
        "                temp_data.update(item_feat.drop('item_id').to_dict())\n",
        "                candidate_data.append(temp_data)\n",
        "\n",
        "            if candidate_data:\n",
        "                candidate_df = pd.DataFrame(candidate_data)\n",
        "\n",
        "                for col in ['day_of_week', 'hour_of_day']:\n",
        "                    if col in candidate_df.columns:\n",
        "                        candidate_df[col] = candidate_df[col].fillna(-1).astype(int)\n",
        "\n",
        "                for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "                    if col in candidate_df.columns:\n",
        "                        candidate_df[col] = candidate_df[col].fillna('unknown')\n",
        "\n",
        "                candidate_df_encoded = pd.get_dummies(candidate_df, columns=categorical_features, dummy_na=False)\n",
        "\n",
        "                missing_cols = set(ranking_model_features) - set(candidate_df_encoded.columns)\n",
        "                for c in missing_cols:\n",
        "                    candidate_df_encoded[c] = False\n",
        "                extra_cols = set(candidate_df_encoded.columns) - set(ranking_model_features)\n",
        "                candidate_df_encoded = candidate_df_encoded.drop(columns=list(extra_cols))\n",
        "\n",
        "                candidate_features_for_prediction = candidate_df_encoded[ranking_model_features]\n",
        "                predictions = ranking_model.predict_proba(candidate_features_for_prediction)[:, 1]\n",
        "\n",
        "                ranked_candidates = pd.DataFrame({\n",
        "                    'item_id': candidate_df['item_id'],\n",
        "                    'predicted_score': predictions\n",
        "                })\n",
        "                ranked_candidates = ranked_candidates.sort_values(by='predicted_score', ascending=False)\n",
        "                hybrid_recs = ranked_candidates.head(K)['item_id'].tolist()\n",
        "\n",
        "        # Calculate and store metrics for all models\n",
        "        mp_precision = precision_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_recall = recall_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_ndcg = ndcg_at_k(most_popular_recs, actual_interactions, K)\n",
        "        mp_mrr = mrr_at_k(most_popular_recs, actual_interactions, K)\n",
        "\n",
        "        cf_precision = precision_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_recall = recall_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_ndcg = ndcg_at_k(cf_recs, actual_interactions, K)\n",
        "        cf_mrr = mrr_at_k(cf_recs, actual_interactions, K)\n",
        "\n",
        "        hybrid_precision = precision_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_recall = recall_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_ndcg = ndcg_at_k(hybrid_recs, actual_interactions, K)\n",
        "        hybrid_mrr = mrr_at_k(hybrid_recs, actual_interactions, K)\n",
        "\n",
        "        most_popular_precision_scores.append(mp_precision)\n",
        "        most_popular_recall_scores.append(mp_recall)\n",
        "        most_popular_ndcg_scores.append(mp_ndcg)\n",
        "        most_popular_mrr_scores.append(mp_mrr)\n",
        "\n",
        "        cf_precision_scores.append(cf_precision)\n",
        "        cf_recall_scores.append(cf_recall)\n",
        "        cf_ndcg_scores.append(cf_ndcg)\n",
        "        cf_mrr_scores.append(cf_mrr)\n",
        "\n",
        "        hybrid_precision_scores.append(hybrid_precision)\n",
        "        hybrid_recall_scores.append(hybrid_recall)\n",
        "        hybrid_ndcg_scores.append(hybrid_ndcg)\n",
        "        hybrid_mrr_scores.append(hybrid_mrr)\n",
        "\n",
        "        # Collect items for Coverage\n",
        "        all_mp_recs_items.update(most_popular_recs)\n",
        "        all_cf_recs_items.update(cf_recs)\n",
        "        all_hybrid_recs_items.update(hybrid_recs)\n",
        "\n",
        "        # Collect popularity scores for Novelty (using popularity as a proxy - lower average popularity is higher novelty)\n",
        "        for item_id in most_popular_recs:\n",
        "            popularity = item_popularity[item_popularity['item_id'] == item_id]['popularity_score'].iloc[0]\n",
        "            mp_recommended_popularities.append(popularity)\n",
        "        for item_id in cf_recs:\n",
        "            popularity = item_popularity[item_popularity['item_id'] == item_id]['popularity_score'].iloc[0]\n",
        "            cf_recommended_popularities.append(popularity)\n",
        "        for item_id in hybrid_recs:\n",
        "            popularity = item_popularity[item_popularity['item_id'] == item_id]['popularity_score'].iloc[0]\n",
        "            hybrid_recommended_popularities.append(popularity)\n",
        "\n",
        "        # Store cold-start metrics\n",
        "        if student_id in cold_start_student_ids:\n",
        "            cold_start_mp_precision.append(mp_precision)\n",
        "            cold_start_mp_recall.append(mp_recall)\n",
        "            cold_start_mp_ndcg.append(mp_ndcg)\n",
        "            cold_start_mp_mrr.append(mp_mrr)\n",
        "\n",
        "            cold_start_cf_precision.append(cf_precision)\n",
        "            cold_start_cf_recall.append(cf_recall)\n",
        "            cold_start_cf_ndcg.append(cf_ndcg)\n",
        "            cold_start_cf_mrr.append(cf_mrr)\n",
        "\n",
        "            cold_start_hybrid_precision.append(hybrid_precision)\n",
        "            cold_start_hybrid_recall.append(hybrid_recall)\n",
        "            cold_start_hybrid_ndcg.append(hybrid_ndcg)\n",
        "            cold_start_hybrid_mrr.append(hybrid_mrr)\n",
        "\n",
        "print('Recommendation generation and metric collection complete for all eligible students.\\n')\n",
        "\n",
        "print('--- Overall Average Evaluation Metrics ---\\n')\n",
        "\n",
        "if most_popular_precision_scores:\n",
        "    print(f\"Most Popular Model - Avg Precision@{K}: {np.mean(most_popular_precision_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Avg Recall@{K}: {np.mean(most_popular_recall_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Avg NDCG@{K}: {np.mean(most_popular_ndcg_scores):.4f}\")\n",
        "    print(f\"Most Popular Model - Avg MRR@{K}: {np.mean(most_popular_mrr_scores):.4f}\\n\")\n",
        "\n",
        "if cf_precision_scores:\n",
        "    print(f\"Collaborative Filtering Model - Avg Precision@{K}: {np.mean(cf_precision_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Avg Recall@{K}: {np.mean(cf_recall_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Avg NDCG@{K}: {np.mean(cf_ndcg_scores):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model - Avg MRR@{K}: {np.mean(cf_mrr_scores):.4f}\\n\")\n",
        "\n",
        "if hybrid_precision_scores:\n",
        "    print(f\"Hybrid Model - Avg Precision@{K}: {np.mean(hybrid_precision_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Avg Recall@{K}: {np.mean(hybrid_recall_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Avg NDCG@{K}: {np.mean(hybrid_ndcg_scores):.4f}\")\n",
        "    print(f\"Hybrid Model - Avg MRR@{K}: {np.mean(hybrid_mrr_scores):.4f}\\n\")\n",
        "\n",
        "print('--- Coverage Analysis ---\\n')\n",
        "\n",
        "total_unique_items_in_system = synthetic_df['item_id'].nunique()\n",
        "\n",
        "mp_coverage = len(all_mp_recs_items) / total_unique_items_in_system\n",
        "cf_coverage = len(all_cf_recs_items) / total_unique_items_in_system\n",
        "hybrid_coverage = len(all_hybrid_recs_items) / total_unique_items_in_system\n",
        "\n",
        "print(f\"Most Popular Model - Coverage: {mp_coverage:.4f}\")\n",
        "print(f\"Collaborative Filtering Model - Coverage: {cf_coverage:.4f}\")\n",
        "print(f\"Hybrid Model - Coverage: {hybrid_coverage:.4f}\\n\")\n",
        "\n",
        "print('--- Novelty Analysis (Average Popularity of Recommended Items - Lower is more novel) ---\\n')\n",
        "\n",
        "if mp_recommended_popularities:\n",
        "    print(f\"Most Popular Model - Avg Popularity of Recommended Items: {np.mean(mp_recommended_popularities):.2f}\")\n",
        "if cf_recommended_popularities:\n",
        "    print(f\"Collaborative Filtering Model - Avg Popularity of Recommended Items: {np.mean(cf_recommended_popularities):.2f}\")\n",
        "if hybrid_recommended_popularities:\n",
        "    print(f\"Hybrid Model - Avg Popularity of Recommended Items: {np.mean(hybrid_recommended_popularities):.2f}\\n\")\n",
        "\n",
        "print('--- Cold-Start Student Analysis ---\\n')\n",
        "\n",
        "if cold_start_mp_precision:\n",
        "    print(f\"Most Popular Model (Cold-Start) - Avg Precision@{K}: {np.mean(cold_start_mp_precision):.4f}\")\n",
        "    print(f\"Most Popular Model (Cold-Start) - Avg Recall@{K}: {np.mean(cold_start_mp_recall):.4f}\")\n",
        "    print(f\"Most Popular Model (Cold-Start) - Avg NDCG@{K}: {np.mean(cold_start_mp_ndcg):.4f}\")\n",
        "    print(f\"Most Popular Model (Cold-Start) - Avg MRR@{K}: {np.mean(cold_start_mp_mrr):.4f}\\n\")\n",
        "else:\n",
        "    print(\"No cold-start students found for Most Popular Model evaluation.\\n\")\n",
        "\n",
        "if cold_start_cf_precision:\n",
        "    print(f\"Collaborative Filtering Model (Cold-Start) - Avg Precision@{K}: {np.mean(cold_start_cf_precision):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model (Cold-Start) - Avg Recall@{K}: {np.mean(cold_start_cf_recall):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model (Cold-Start) - Avg NDCG@{K}: {np.mean(cold_start_cf_ndcg):.4f}\")\n",
        "    print(f\"Collaborative Filtering Model (Cold-Start) - Avg MRR@{K}: {np.mean(cold_start_cf_mrr):.4f}\\n\")\n",
        "else:\n",
        "    print(\"No cold-start students found for Collaborative Filtering Model evaluation.\\n\")\n",
        "\n",
        "if cold_start_hybrid_precision:\n",
        "    print(f\"Hybrid Model (Cold-Start) - Avg Precision@{K}: {np.mean(cold_start_hybrid_precision):.4f}\")\n",
        "    print(f\"Hybrid Model (Cold-Start) - Avg Recall@{K}: {np.mean(cold_start_hybrid_recall):.4f}\")\n",
        "    print(f\"Hybrid Model (Cold-Start) - Avg NDCG@{K}: {np.mean(cold_start_hybrid_ndcg):.4f}\")\n",
        "    print(f\"Hybrid Model (Cold-Start) - Avg MRR@{K}: {np.mean(cold_start_hybrid_mrr):.4f}\\n\")\n",
        "else:\n",
        "    print(\"No cold-start students found for Hybrid Model evaluation.\\n\")\n",
        "\n",
        "print('--- Qualitative Error Analysis Examples ---\\n')\n",
        "\n",
        "# Find a student with poor performance (e.g., CF recall is 0)\n",
        "poor_cf_student_id = None\n",
        "for i, student_id in enumerate(unique_test_students):\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "    if len(actual_interactions) > 0:\n",
        "        cf_recs_for_student = get_cf_recommendations(student_id, K, get_historical_interactions(student_id, train_df), algo, trainset)\n",
        "        if recall_at_k(cf_recs_for_student, actual_interactions, K) == 0:\n",
        "            poor_cf_student_id = student_id\n",
        "            break\n",
        "\n",
        "# Find a student with good performance (e.g., CF recall is high)\n",
        "good_cf_student_id = None\n",
        "for i, student_id in enumerate(unique_test_students):\n",
        "    actual_interactions = get_actual_interactions(student_id, test_df)\n",
        "    if len(actual_interactions) > 0:\n",
        "        cf_recs_for_student = get_cf_recommendations(student_id, K, get_historical_interactions(student_id, train_df), algo, trainset)\n",
        "        if recall_at_k(cf_recs_for_student, actual_interactions, K) > 0.5: # Arbitrarily high recall\n",
        "            good_cf_student_id = student_id\n",
        "            break\n",
        "\n",
        "if poor_cf_student_id is not None:\n",
        "    print(f\"Example of Poor Performance (Student ID: {poor_cf_student_id}):\")\n",
        "    historical_interactions_poor = get_historical_interactions(poor_cf_student_id, train_df)\n",
        "    actual_interactions_poor = get_actual_interactions(poor_cf_student_id, test_df)\n",
        "\n",
        "    mp_recs_poor = get_most_popular_recommendations(poor_cf_student_id, K, historical_interactions_poor)\n",
        "    cf_recs_poor = get_cf_recommendations(poor_cf_student_id, K, historical_interactions_poor, algo, trainset)\n",
        "\n",
        "    # Generate Hybrid recs for the poor student\n",
        "    hybrid_recs_poor = []\n",
        "    candidates_poor = generate_candidates_for_user(poor_cf_student_id, algo, n_candidates=50, historical_interactions=historical_interactions_poor, all_item_ids=synthetic_df['item_id'].unique())\n",
        "    if candidates_poor:\n",
        "        candidate_data_poor = []\n",
        "        for item_id in candidates_poor:\n",
        "            user_feat_poor = user_interactions[user_interactions['student_id'] == poor_cf_student_id]\n",
        "            if user_feat_poor.empty: continue\n",
        "            user_feat_poor = user_feat_poor.iloc[0]\n",
        "\n",
        "            item_feat_poor = item_interactions[item_interactions['item_id'] == item_id]\n",
        "            if item_feat_poor.empty: continue\n",
        "            item_feat_poor = item_feat_poor.iloc[0]\n",
        "\n",
        "            student_test_interactions_poor = test_df[test_df['student_id'] == poor_cf_student_id]\n",
        "            representative_day_of_week_poor = student_test_interactions_poor['day_of_week'].iloc[0] if not student_test_interactions_poor.empty else -1\n",
        "            representative_hour_of_day_poor = student_test_interactions_poor['hour_of_day'].iloc[0] if not student_test_interactions_poor.empty else -1\n",
        "\n",
        "            temp_data_poor = {\n",
        "                'student_id': poor_cf_student_id,\n",
        "                'item_id': item_id,\n",
        "                'interaction_type': 'unknown',\n",
        "                'day_of_week': representative_day_of_week_poor,\n",
        "                'hour_of_day': representative_hour_of_day_poor,\n",
        "            }\n",
        "            temp_data_poor.update(user_feat_poor.drop('student_id').to_dict())\n",
        "            temp_data_poor.update(item_feat_poor.drop('item_id').to_dict())\n",
        "            candidate_data_poor.append(temp_data_poor)\n",
        "\n",
        "        if candidate_data_poor:\n",
        "            candidate_df_poor = pd.DataFrame(candidate_data_poor)\n",
        "            for col in ['day_of_week', 'hour_of_day']:\n",
        "                if col in candidate_df_poor.columns: candidate_df_poor[col] = candidate_df_poor[col].fillna(-1).astype(int)\n",
        "            for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "                if col in candidate_df_poor.columns: candidate_df_poor[col] = candidate_df_poor[col].fillna('unknown')\n",
        "            candidate_df_encoded_poor = pd.get_dummies(candidate_df_poor, columns=categorical_features, dummy_na=False)\n",
        "            missing_cols_poor = set(ranking_model_features) - set(candidate_df_encoded_poor.columns)\n",
        "            for c in missing_cols_poor: candidate_df_encoded_poor[c] = False\n",
        "            extra_cols_poor = set(candidate_df_encoded_poor.columns) - set(ranking_model_features)\n",
        "            candidate_df_encoded_poor = candidate_df_encoded_poor.drop(columns=list(extra_cols_poor))\n",
        "            candidate_features_for_prediction_poor = candidate_df_encoded_poor[ranking_model_features]\n",
        "            predictions_poor = ranking_model.predict_proba(candidate_features_for_prediction_poor)[:, 1]\n",
        "            ranked_candidates_poor = pd.DataFrame({\n",
        "                'item_id': candidate_df_poor['item_id'],\n",
        "                'predicted_score': predictions_poor\n",
        "            })\n",
        "            ranked_candidates_poor = ranked_candidates_poor.sort_values(by='predicted_score', ascending=False)\n",
        "            hybrid_recs_poor = ranked_candidates_poor.head(K)['item_id'].tolist()\n",
        "\n",
        "    print(f\"  Historical Interactions: {historical_interactions_poor}\")\n",
        "    print(f\"  Actual Interactions in Test Set: {actual_interactions_poor}\")\n",
        "    print(f\"  Most Popular Recommendations: {mp_recs_poor}\")\n",
        "    print(f\"  Collaborative Filtering Recommendations: {cf_recs_poor}\")\n",
        "    print(f\"  Hybrid Recommendations: {hybrid_recs_poor}\\n\")\n",
        "\n",
        "if good_cf_student_id is not None:\n",
        "    print(f\"Example of Good Performance (Student ID: {good_cf_student_id}):\")\n",
        "    historical_interactions_good = get_historical_interactions(good_cf_student_id, train_df)\n",
        "    actual_interactions_good = get_actual_interactions(good_cf_student_id, test_df)\n",
        "\n",
        "    mp_recs_good = get_most_popular_recommendations(good_cf_student_id, K, historical_interactions_good)\n",
        "    cf_recs_good = get_cf_recommendations(good_cf_student_id, K, historical_interactions_good, algo, trainset)\n",
        "\n",
        "    # Generate Hybrid recs for the good student\n",
        "    hybrid_recs_good = []\n",
        "    candidates_good = generate_candidates_for_user(good_cf_student_id, algo, n_candidates=50, historical_interactions=historical_interactions_good, all_item_ids=synthetic_df['item_id'].unique())\n",
        "    if candidates_good:\n",
        "        candidate_data_good = []\n",
        "        for item_id in candidates_good:\n",
        "            user_feat_good = user_interactions[user_interactions['student_id'] == good_cf_student_id]\n",
        "            if user_feat_good.empty: continue\n",
        "            user_feat_good = user_feat_good.iloc[0]\n",
        "\n",
        "            item_feat_good = item_interactions[item_interactions['item_id'] == item_id]\n",
        "            if item_feat_good.empty: continue\n",
        "            item_feat_good = item_feat_good.iloc[0]\n",
        "\n",
        "            student_test_interactions_good = test_df[test_df['student_id'] == good_cf_student_id]\n",
        "            representative_day_of_week_good = student_test_interactions_good['day_of_week'].iloc[0] if not student_test_interactions_good.empty else -1\n",
        "            representative_hour_of_day_good = student_test_interactions_good['hour_of_day'].iloc[0] if not student_test_interactions_good.empty else -1\n",
        "\n",
        "            temp_data_good = {\n",
        "                'student_id': good_cf_student_id,\n",
        "                'item_id': item_id,\n",
        "                'interaction_type': 'unknown',\n",
        "                'day_of_week': representative_day_of_week_good,\n",
        "                'hour_of_day': representative_hour_of_day_good,\n",
        "            }\n",
        "            temp_data_good.update(user_feat_good.drop('student_id').to_dict())\n",
        "            temp_data_good.update(item_feat_good.drop('item_id').to_dict())\n",
        "            candidate_data_good.append(temp_data_good)\n",
        "\n",
        "        if candidate_data_good:\n",
        "            candidate_df_good = pd.DataFrame(candidate_data_good)\n",
        "            for col in ['day_of_week', 'hour_of_day']:\n",
        "                if col in candidate_df_good.columns: candidate_df_good[col] = candidate_df_good[col].fillna(-1).astype(int)\n",
        "            for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "                if col in candidate_df_good.columns: candidate_df_good[col] = candidate_df_good[col].fillna('unknown')\n",
        "            candidate_df_encoded_good = pd.get_dummies(candidate_df_good, columns=categorical_features, dummy_na=False)\n",
        "            missing_cols_good = set(ranking_model_features) - set(candidate_df_encoded_good.columns)\n",
        "            for c in missing_cols_good: candidate_df_encoded_good[c] = False\n",
        "            extra_cols_good = set(candidate_df_encoded_good.columns) - set(ranking_model_features)\n",
        "            candidate_df_encoded_good = candidate_df_encoded_good.drop(columns=list(extra_cols_good))\n",
        "            candidate_features_for_prediction_good = candidate_df_encoded_good[ranking_model_features]\n",
        "            predictions_good = ranking_model.predict_proba(candidate_features_for_prediction_good)[:, 1]\n",
        "            ranked_candidates_good = pd.DataFrame({\n",
        "                'item_id': candidate_df_good['item_id'],\n",
        "                'predicted_score': predictions_good\n",
        "            })\n",
        "            ranked_candidates_good = ranked_candidates_good.sort_values(by='predicted_score', ascending=False)\n",
        "            hybrid_recs_good = ranked_candidates_good.head(K)['item_id'].tolist()\n",
        "\n",
        "    print(f\"  Historical Interactions: {historical_interactions_good}\")\n",
        "    print(f\"  Actual Interactions in Test Set: {actual_interactions_good}\")\n",
        "    print(f\"  Most Popular Recommendations: {mp_recs_good}\")\n",
        "    print(f\"  Collaborative Filtering Recommendations: {cf_recs_good}\")\n",
        "    print(f\"  Hybrid Recommendations: {hybrid_recs_good}\\n\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Re-generating Synthetic Dataset and Temporal Split ---\n",
            "\n",
            "Synthetic DataFrame regenerated. First 5 rows:\n",
            "   student_id  item_id interaction_type                     timestamp\n",
            "0          52       21          discuss 2023-01-01 21:41:57.645236886\n",
            "1          40       18           enroll 2023-01-02 06:33:49.187541655\n",
            "2          90        5           enroll 2023-01-02 16:15:11.073389878\n",
            "3          39        8             view 2023-01-03 07:23:10.805267857\n",
            "4          19       31     quiz_attempt 2023-01-03 09:51:04.204017108\n",
            "\n",
            "--- Temporal Train/Validation/Test Split ---\n",
            "\n",
            "Train set interactions: 800\n",
            "Validation set interactions: 100\n",
            "Test set interactions: 100\n",
            "\n",
            "--- Re-calculating Features ---\n",
            "\n",
            "User and Item features recalculated, and temporal features extracted.\n",
            "\n",
            "--- Initializing surprise.Reader and loading data ---\n",
            "\n",
            "\n",
            "`surprise.Reader` object created and trainset built.\n",
            "Number of users in trainset: 100\n",
            "Number of items in trainset: 50\n",
            "Number of interactions in trainset: 800\n",
            "\n",
            "--- Training Collaborative Filtering Model (SVD) ---\n",
            "\n",
            "SVD model trained successfully.\n",
            "\n",
            "--- Re-defining Recommendation Functions and Evaluation Metrics ---\n",
            "\n",
            "Starting evaluation for 65 unique students in the test set with K=10 for all Models.\n",
            "Recommendation generation and metric collection complete for all eligible students.\n",
            "\n",
            "--- Overall Average Evaluation Metrics ---\n",
            "\n",
            "Most Popular Model - Avg Precision@10: 0.0323\n",
            "Most Popular Model - Avg Recall@10: 0.1962\n",
            "Most Popular Model - Avg NDCG@10: 0.0985\n",
            "Most Popular Model - Avg MRR@10: 0.0857\n",
            "\n",
            "Collaborative Filtering Model - Avg Precision@10: 0.0277\n",
            "Collaborative Filtering Model - Avg Recall@10: 0.1885\n",
            "Collaborative Filtering Model - Avg NDCG@10: 0.1091\n",
            "Collaborative Filtering Model - Avg MRR@10: 0.0950\n",
            "\n",
            "Hybrid Model - Avg Precision@10: 0.0338\n",
            "Hybrid Model - Avg Recall@10: 0.2026\n",
            "Hybrid Model - Avg NDCG@10: 0.1180\n",
            "Hybrid Model - Avg MRR@10: 0.1055\n",
            "\n",
            "--- Coverage Analysis ---\n",
            "\n",
            "Most Popular Model - Coverage: 0.3400\n",
            "Collaborative Filtering Model - Coverage: 0.3600\n",
            "Hybrid Model - Coverage: 0.3400\n",
            "\n",
            "--- Novelty Analysis (Average Popularity of Recommended Items - Lower is more novel) ---\n",
            "\n",
            "Most Popular Model - Avg Popularity of Recommended Items: 21.68\n",
            "Collaborative Filtering Model - Avg Popularity of Recommended Items: 15.93\n",
            "Hybrid Model - Avg Popularity of Recommended Items: 15.40\n",
            "\n",
            "--- Cold-Start Student Analysis ---\n",
            "\n",
            "Most Popular Model (Cold-Start) - Avg Precision@10: 0.0375\n",
            "Most Popular Model (Cold-Start) - Avg Recall@10: 0.1875\n",
            "Most Popular Model (Cold-Start) - Avg NDCG@10: 0.0891\n",
            "Most Popular Model (Cold-Start) - Avg MRR@10: 0.0625\n",
            "\n",
            "Collaborative Filtering Model (Cold-Start) - Avg Precision@10: 0.0375\n",
            "Collaborative Filtering Model (Cold-Start) - Avg Recall@10: 0.3125\n",
            "Collaborative Filtering Model (Cold-Start) - Avg NDCG@10: 0.1617\n",
            "Collaborative Filtering Model (Cold-Start) - Avg MRR@10: 0.1250\n",
            "\n",
            "Hybrid Model (Cold-Start) - Avg Precision@10: 0.0500\n",
            "Hybrid Model (Cold-Start) - Avg Recall@10: 0.3125\n",
            "Hybrid Model (Cold-Start) - Avg NDCG@10: 0.1204\n",
            "Hybrid Model (Cold-Start) - Avg MRR@10: 0.0786\n",
            "\n",
            "--- Qualitative Error Analysis Examples ---\n",
            "\n",
            "Example of Poor Performance (Student ID: 86):\n",
            "  Historical Interactions: {32, 36, 44, 19, 26}\n",
            "  Actual Interactions in Test Set: {10, 29, 15}\n",
            "  Most Popular Recommendations: [48, 7, 46, 10, 25, 49, 30, 14, 45, 21]\n",
            "  Collaborative Filtering Recommendations: [21, 18, 5, 8, 31, 12, 42, 37, 28, 38]\n",
            "  Hybrid Recommendations: [48, 7, 29, 27, 11, 15, 49, 10, 25, 6]\n",
            "\n",
            "Example of Good Performance (Student ID: 58):\n",
            "  Historical Interactions: {1, 3, 4, 9, 47, 49, 18, 23, 24, 26, 27}\n",
            "  Actual Interactions in Test Set: {31}\n",
            "  Most Popular Recommendations: [48, 7, 46, 10, 25, 30, 14, 45, 21, 13]\n",
            "  Collaborative Filtering Recommendations: [21, 5, 8, 31, 19, 12, 42, 37, 28, 38]\n",
            "  Hybrid Recommendations: [48, 7, 15, 29, 11, 25, 10, 6, 46, 28]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3193ccc"
      },
      "source": [
        "## Build Application\n",
        "\n",
        "### Subtask:\n",
        "Develop either a simple web application (using Streamlit, Flask, or FastAPI) or a command-line interface (CLI) tool with batch inference capabilities for the recommendation system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceac6421"
      },
      "source": [
        "**Reasoning**:\n",
        "I will start by defining a function that encapsulates the entire recommendation process for a given student ID, as this aligns with developing a CLI tool and covers the core logic required by steps 2 to 7 of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "653e04bc",
        "outputId": "a5bbf64f-4d4a-464f-e49b-fb6726d56cf0"
      },
      "source": [
        "print('--- Defining the recommendation generation function for the application ---\\n')\n",
        "\n",
        "def get_hybrid_recommendations_for_app(student_id, n_recommendations=10, n_candidates=50):\n",
        "    # 1. Retrieve historical interactions from train_df\n",
        "    historical_interactions = get_historical_interactions(student_id, train_df)\n",
        "\n",
        "    # 2. Generate candidate items using the SVD model\n",
        "    candidates = generate_candidates_for_user(student_id, algo, n_candidates=n_candidates, historical_interactions=historical_interactions, all_item_ids=synthetic_df['item_id'].unique())\n",
        "\n",
        "    if not candidates:\n",
        "        return []\n",
        "\n",
        "    # 3. Create feature vectors for candidate items, consistent with ranking_model training\n",
        "    candidate_data = []\n",
        "    for item_id in candidates:\n",
        "        user_feat = user_interactions[user_interactions['student_id'] == student_id]\n",
        "        if user_feat.empty:\n",
        "            continue\n",
        "        user_feat = user_feat.iloc[0]\n",
        "\n",
        "        item_feat = item_interactions[item_interactions['item_id'] == item_id]\n",
        "        if item_feat.empty:\n",
        "            continue\n",
        "        item_feat = item_feat.iloc[0]\n",
        "\n",
        "        # For temporal features, use representative values (e.g., from an average interaction, or a default)\n",
        "        # For simplicity in this app, we'll use a fixed 'typical' value for new predictions if not available from test_df\n",
        "        # In a real app, one might use current time or average interaction time for the user.\n",
        "        # Let's use the mean day_of_week and hour_of_day from train_df as a proxy for 'typical' interaction time\n",
        "        representative_day_of_week = int(train_df['day_of_week'].mean()) if 'day_of_week' in train_df.columns else -1\n",
        "        representative_hour_of_day = int(train_df['hour_of_day'].mean()) if 'hour_of_day' in train_df.columns else -1\n",
        "\n",
        "\n",
        "        temp_data = {\n",
        "            'student_id': student_id,\n",
        "            'item_id': item_id,\n",
        "            'interaction_type': 'unknown', # Default for new predictions for items not yet interacted\n",
        "            'day_of_week': representative_day_of_week,\n",
        "            'hour_of_day': representative_hour_of_day,\n",
        "        }\n",
        "        temp_data.update(user_feat.drop('student_id').to_dict())\n",
        "        temp_data.update(item_feat.drop('item_id').to_dict())\n",
        "        candidate_data.append(temp_data)\n",
        "\n",
        "    if not candidate_data:\n",
        "        return []\n",
        "\n",
        "    candidate_df = pd.DataFrame(candidate_data)\n",
        "\n",
        "    # Handle categorical features and one-hot encode them consistently\n",
        "    for col in ['day_of_week', 'hour_of_day']:\n",
        "        if col in candidate_df.columns:\n",
        "            candidate_df[col] = candidate_df[col].fillna(-1).astype(int)\n",
        "\n",
        "    for col in ['interaction_type', 'most_frequent_interaction_type_user', 'most_frequent_interaction_type_item']:\n",
        "        if col in candidate_df.columns:\n",
        "            candidate_df[col] = candidate_df[col].fillna('unknown')\n",
        "\n",
        "    candidate_df_encoded = pd.get_dummies(candidate_df, columns=categorical_features, dummy_na=False)\n",
        "\n",
        "    # Align columns with the training data's X\n",
        "    missing_cols = set(ranking_model_features) - set(candidate_df_encoded.columns)\n",
        "    for c in missing_cols:\n",
        "        candidate_df_encoded[c] = False\n",
        "    extra_cols = set(candidate_df_encoded.columns) - set(ranking_model_features)\n",
        "    candidate_df_encoded = candidate_df_encoded.drop(columns=list(extra_cols))\n",
        "\n",
        "    candidate_features_for_prediction = candidate_df_encoded[ranking_model_features]\n",
        "\n",
        "    # 4. Predict interaction likelihoods\n",
        "    predictions = ranking_model.predict_proba(candidate_features_for_prediction)[:, 1]\n",
        "\n",
        "    # 5. Rank candidates and select top N\n",
        "    ranked_candidates = pd.DataFrame({\n",
        "        'item_id': candidate_df['item_id'],\n",
        "        'predicted_score': predictions\n",
        "    })\n",
        "    ranked_candidates = ranked_candidates.sort_values(by='predicted_score', ascending=False)\n",
        "    hybrid_recs = ranked_candidates.head(n_recommendations)['item_id'].tolist()\n",
        "\n",
        "    return hybrid_recs\n",
        "\n",
        "print('`get_hybrid_recommendations_for_app` function defined.')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Defining the recommendation generation function for the application ---\n",
            "\n",
            "`get_hybrid_recommendations_for_app` function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aad240d9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to a `SyntaxError: unterminated string literal` in the print statement. I will correct this by ensuring the string literal is properly closed on a single line.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c49ea160",
        "outputId": "d3544358-8700-485b-a769-7646d2200568"
      },
      "source": [
        "print('--- Implementing Command-Line Interface for Recommendations ---')\n",
        "\n",
        "def run_cli_recommendation_tool():\n",
        "    print(\"Welcome to the Student Interaction Recommendation System!\")\n",
        "    print(\"Enter 'exit' at any time to quit.\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            student_id_input = input(\"\\nEnter Student ID: \")\n",
        "            if student_id_input.lower() == 'exit':\n",
        "                print(\"Exiting recommendation tool. Goodbye!\")\n",
        "                break\n",
        "\n",
        "            student_id = int(student_id_input)\n",
        "\n",
        "            # Check if student_id exists in the user_interactions (derived from train_df)\n",
        "            if student_id not in user_interactions['student_id'].unique():\n",
        "                print(f\"Error: Student ID {student_id} not found in our training data. Please try another ID.\")\n",
        "                continue\n",
        "\n",
        "            # Get recommendations\n",
        "            recommendations = get_hybrid_recommendations_for_app(student_id, n_recommendations=10, n_candidates=50)\n",
        "\n",
        "            if recommendations:\n",
        "                print(f\"Recommendations for Student ID {student_id}: {recommendations}\")\n",
        "            else:\n",
        "                print(f\"No recommendations could be generated for Student ID {student_id}.\")\n",
        "\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a valid integer for Student ID.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Run the CLI tool\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Implementing Command-Line Interface for Recommendations ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f924d50e",
        "outputId": "134dd426-a86a-4a40-9407-58c1ad74ed25"
      },
      "source": [
        "run_cli_recommendation_tool()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Student Interaction Recommendation System!\n",
            "Enter 'exit' at any time to quit.\n",
            "\n",
            "Enter Student ID: 52\n",
            "Recommendations for Student ID 52: [7, 29, 15, 27, 11, 49, 10, 25, 6, 46]\n",
            "\n",
            "Enter Student ID: 40\n",
            "Recommendations for Student ID 40: [48, 7, 27, 15, 29, 11, 10, 25, 6, 28]\n",
            "\n",
            "Enter Student ID: 90\n",
            "Recommendations for Student ID 90: [48, 11, 27, 15, 29, 10, 49, 25, 6, 46]\n",
            "\n",
            "Enter Student ID: 39\n",
            "Recommendations for Student ID 39: [48, 7, 11, 29, 15, 27, 10, 25, 49, 6]\n",
            "\n",
            "Enter Student ID: 19\n",
            "Recommendations for Student ID 19: [48, 7, 15, 27, 11, 49, 6, 46, 40, 28]\n",
            "\n",
            "Enter Student ID: 79\n",
            "Recommendations for Student ID 79: [48, 7, 15, 29, 11, 27, 49, 10, 25, 6]\n",
            "\n",
            "Enter Student ID: 32\n",
            "Recommendations for Student ID 32: [48, 7, 27, 15, 29, 11, 25, 10, 49, 6]\n",
            "\n",
            "Enter Student ID: 80\n",
            "Recommendations for Student ID 80: [48, 7, 11, 15, 27, 29, 10, 49, 25, 6]\n",
            "\n",
            "Enter Student ID: 2\n",
            "Recommendations for Student ID 2: [48, 7, 11, 27, 29, 15, 49, 6, 46, 28]\n",
            "\n",
            "Enter Student ID: 62\n",
            "Recommendations for Student ID 62: [48, 7, 27, 29, 15, 10, 49, 25, 6, 46]\n",
            "\n",
            "Enter Student ID: exit\n",
            "Exiting recommendation tool. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc4a4931",
        "outputId": "11be4a3c-8122-4974-c3e6-9adfee3a4373"
      },
      "source": [
        "print('Sample of unique student IDs from the synthetic dataset:')\n",
        "print(synthetic_df['student_id'].unique()[:10]) # Displaying first 10 unique student IDs"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of unique student IDs from the synthetic dataset:\n",
            "[52 40 90 39 19 79 32 80  2 62]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sample of unique student IDs from the synthetic dataset is: [52 40 90 39 19 79 32 80 2 62]. You can use any of these IDs, or others from 1 to 100, when interacting with the CLI tool. I'm now executing the CLI tool for you."
      ],
      "metadata": {
        "id": "1448PMfhMqFP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b946fc96"
      },
      "source": [
        "# Task\n",
        "I've completed all the planned steps, including developing and evaluating the recommendation models, and building a command-line interface as a demo application.\n",
        "\n",
        "The key deliverables are:\n",
        "1.  **Codebase**: All Python code for data loading, EDA, feature engineering, model training (Most Popular, Collaborative Filtering SVD, Hybrid Ranking Model), evaluation, and the CLI application is present in the notebook.\n",
        "2.  **Model Artifacts**: The trained models (SVD and LightGBM ranking model) are implicitly saved in the notebook's state. Their performance metrics (Precision@K, Recall@K, NDCG@K, MRR, Coverage, Novelty, Cold-Start analysis) have been calculated and printed, along with qualitative error analysis examples.\n",
        "3.  **Demo Application**: A functional command-line interface (CLI) has been developed and demonstrated, allowing users to get recommendations for a given student ID.\n",
        "\n",
        "Based on the successful execution and comprehensive outputs provided, the project deliverables are confirmed as complete and ready for final review and presentation.\n",
        "\n",
        "---\n",
        "**Project Summary:**\n",
        "\n",
        "*   **Data Preparation**: A synthetic dataset simulating student interactions was generated, as no suitable real-world data was found in `sample_data`. This data underwent cleaning, temporal splitting, and extensive feature engineering focusing on user, item, and temporal aspects.\n",
        "*   **Baseline Models**: 'Most Popular' and 'Collaborative Filtering (SVD)' models were implemented and evaluated as baselines.\n",
        "*   **Advanced Model**: A Hybrid Recommendation Model was built, combining SVD for candidate generation with a LightGBM ranking model that leveraged engineered features.\n",
        "*   **Evaluation**: All models were rigorously evaluated using Precision@K, Recall@K, NDCG@K, and MRR. Additional analyses covered system coverage, novelty (using inverse popularity), and cold-start performance, along with qualitative examples of model behavior.\n",
        "*   **Application**: A command-line interface (CLI) application was developed, demonstrating batch inference capabilities for the hybrid recommendation system.\n",
        "\n",
        "The evaluation metrics showed the Hybrid model generally outperforming the 'Most Popular' model and competing closely with (and sometimes exceeding) the SVD model, especially in certain cold-start scenarios, demonstrating the value of feature engineering and ranking.\n",
        "\n",
        "---\n",
        "This concludes the task of building a recommendation system for student interactions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1a5a1d2"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Confirm the completion of all project deliverables, including the codebase, model artifacts, and the demo application, and ensure they are ready for final review and presentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f04d0ed8"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The project deliverables (Codebase, Model Artifacts, and Demo Application) have been confirmed as complete and ready for final review and presentation.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Deliverables Confirmed**: All key project deliverables, including the codebase, model artifacts (trained SVD and LightGBM models), and a functional command-line interface (CLI) demonstration, are complete and ready for review.\n",
        "*   **Synthetic Data Generation**: Due to the absence of suitable real-world data in `sample_data`, a synthetic dataset simulating student interactions was generated for the project.\n",
        "*   **Hybrid Model Performance**: The developed Hybrid Recommendation Model, which combines SVD for candidate generation with a LightGBM ranking model, generally outperformed the 'Most Popular' baseline model. It also competed closely with, and in some cold-start scenarios, exceeded the performance of the Collaborative Filtering (SVD) model, validating the approach of feature engineering and ranking.\n",
        "*   **Comprehensive Evaluation**: Models were rigorously evaluated using multiple metrics including Precision@K, Recall@K, NDCG@K, MRR, as well as specialized analyses for system coverage, novelty (inverse popularity), and cold-start scenarios.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The successful implementation of a hybrid recommendation system using synthetic data demonstrates a robust framework that can be adapted and scaled with real-world student interaction data.\n",
        "*   Given the promising performance in cold-start scenarios, further exploration could involve integrating more advanced cold-start strategies or exploring different ensemble methods to potentially enhance recommendation quality for new users or items.\n"
      ]
    }
  ]
}